{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 This is the documentation page of Skipper . Skipper is an HTTP router and reverse proxy for service composition. It\u2019s designed to handle large amounts of dynamically configured HTTP route definitions (>800000 routes) with detailed lookup conditions, and flexible augmentation of the request flow with filters. It can be used out of the box or extended with custom lookup, filter logic and configuration sources. HTTP Proxy \u00b6 Skipper identifies routes based on the requests\u2019 properties, such as path, method, host and headers using the predicates . It allows the modification of the requests and responses with filters that are independently configured for each route. Learn here more about how it works. Kubernetes Ingress \u00b6 Skipper can be used to run as a Kubernetes Ingress controller. Details with examples of Skipper\u2019s capabilities and an overview you will can be found in the ingress-controller deployment docs .","title":"Introduction"},{"location":"#introduction","text":"This is the documentation page of Skipper . Skipper is an HTTP router and reverse proxy for service composition. It\u2019s designed to handle large amounts of dynamically configured HTTP route definitions (>800000 routes) with detailed lookup conditions, and flexible augmentation of the request flow with filters. It can be used out of the box or extended with custom lookup, filter logic and configuration sources.","title":"Introduction"},{"location":"#http-proxy","text":"Skipper identifies routes based on the requests\u2019 properties, such as path, method, host and headers using the predicates . It allows the modification of the requests and responses with filters that are independently configured for each route. Learn here more about how it works.","title":"HTTP Proxy"},{"location":"#kubernetes-ingress","text":"Skipper can be used to run as a Kubernetes Ingress controller. Details with examples of Skipper\u2019s capabilities and an overview you will can be found in the ingress-controller deployment docs .","title":"Kubernetes Ingress"},{"location":"data-clients/eskip-file/","text":"Eskip File \u00b6 Eskip file dataclient can be used to serve static defined routes, read from an eskip file. The file format eskip shows your route definitions in a clear way: % cat example.eskip hello : Path ( \" / hello \" ) -> \" https : // www . example . org \" ' The Skipper project has two binaries, one is skipper , the other is eskip . Eskip can be used to validate the syntax of your routes file before reloading a production server: % eskip check example.eskip To run Skipper serving routes from an eskip file you have to use -routes-file <file> parameter: % skipper -routes-file example.eskip A more complicated example with different routes, matches, predicates and filters shows that you can name your route and use preconditions and create, change, delete HTTP headers as you like: % cat complicated_example.eskip hostHeaderMatch : Host ( \"^ skipper . teapot . org $\" ) -> setRequestHeader ( \" Authorization \" , \" Basic YWRtaW46YWRtaW5zcGFzc3dvcmQK \" ) -> \" https : // target - to . auth - with . basic - auth . enterprise . com \" ; baiduPathMatch : Path ( \" / baidu \" ) -> setRequestHeader ( \" Host \" , \" www . baidu . com \" ) -> setPath ( \" / s \" ) -> setQuery ( \" wd \" , \" godoc skipper \" ) -> \" http : // www . baidu . com \" ; googleWildcardMatch : * -> setPath ( \" / search \" ) -> setQuery ( \" q \" , \" godoc skipper \" ) -> \" https : // www . google . com \" ; yandexWildacardIfCookie : * && Cookie ( \" yandex \" , \" true \" ) -> setPath ( \" / search / \" ) -> setQuery ( \" text \" , \" godoc skipper \" ) -> tee ( \" http : // 127.0 . 0.1 : 12345 / \" ) -> \" https : // yandex . ru \" ; The former example shows 4 routes: hostHeaderMatch, baiduPathMatch, googleWildcardMatch and yandexWildcardIfCookie. hostHeaderMatch: used if HTTP host header is exactly: \u201cskipper.teapot.org\u201d, sets a Basic Authorization header and sends the modified request to https://target-to.auth-with.basic-auth.enterprise.com baiduPathMatch: used in case the request patch matches /baidu it will set the Host header to the proxy request it will set the path from /baidu to /s it will set the querystring to \u201cws=godoc skipper\u201d and sends the modified request to http://baidu.com googleWildcardMatch: used as default if no other route matches it will set the path to /search it will set the querystring to \u201cq=godoc skipper\u201d and sends the modified request to https://www.google.com yandexWildcardIfCookie: used as default if a Cookie named \u201cyandex\u201d has the value \u201ctrue\u201d it will set the path to /search/ it will set the querystring to \u201ctext=godoc skipper\u201d it will send a copy of the modified request to http://127.0.0.1:12345/ (similar to unix tee ) and drop the response and sends the modified request to https://yandex.ru More examples you find in eskip file format description, in filters and in predicates . Eskip file format is also used if you print your current routes in skipper, for example (metrics listener required): % curl localhost:9911/routes * -> setResponseHeader ( \" Content - Type \" , \" application / json ; charset = utf - 8 \" ) -> inlineContent ( \" { \\ \" foo \\ \" : 3 } \" ) -> < shunt >","title":"Eskip File"},{"location":"data-clients/eskip-file/#eskip-file","text":"Eskip file dataclient can be used to serve static defined routes, read from an eskip file. The file format eskip shows your route definitions in a clear way: % cat example.eskip hello : Path ( \" / hello \" ) -> \" https : // www . example . org \" ' The Skipper project has two binaries, one is skipper , the other is eskip . Eskip can be used to validate the syntax of your routes file before reloading a production server: % eskip check example.eskip To run Skipper serving routes from an eskip file you have to use -routes-file <file> parameter: % skipper -routes-file example.eskip A more complicated example with different routes, matches, predicates and filters shows that you can name your route and use preconditions and create, change, delete HTTP headers as you like: % cat complicated_example.eskip hostHeaderMatch : Host ( \"^ skipper . teapot . org $\" ) -> setRequestHeader ( \" Authorization \" , \" Basic YWRtaW46YWRtaW5zcGFzc3dvcmQK \" ) -> \" https : // target - to . auth - with . basic - auth . enterprise . com \" ; baiduPathMatch : Path ( \" / baidu \" ) -> setRequestHeader ( \" Host \" , \" www . baidu . com \" ) -> setPath ( \" / s \" ) -> setQuery ( \" wd \" , \" godoc skipper \" ) -> \" http : // www . baidu . com \" ; googleWildcardMatch : * -> setPath ( \" / search \" ) -> setQuery ( \" q \" , \" godoc skipper \" ) -> \" https : // www . google . com \" ; yandexWildacardIfCookie : * && Cookie ( \" yandex \" , \" true \" ) -> setPath ( \" / search / \" ) -> setQuery ( \" text \" , \" godoc skipper \" ) -> tee ( \" http : // 127.0 . 0.1 : 12345 / \" ) -> \" https : // yandex . ru \" ; The former example shows 4 routes: hostHeaderMatch, baiduPathMatch, googleWildcardMatch and yandexWildcardIfCookie. hostHeaderMatch: used if HTTP host header is exactly: \u201cskipper.teapot.org\u201d, sets a Basic Authorization header and sends the modified request to https://target-to.auth-with.basic-auth.enterprise.com baiduPathMatch: used in case the request patch matches /baidu it will set the Host header to the proxy request it will set the path from /baidu to /s it will set the querystring to \u201cws=godoc skipper\u201d and sends the modified request to http://baidu.com googleWildcardMatch: used as default if no other route matches it will set the path to /search it will set the querystring to \u201cq=godoc skipper\u201d and sends the modified request to https://www.google.com yandexWildcardIfCookie: used as default if a Cookie named \u201cyandex\u201d has the value \u201ctrue\u201d it will set the path to /search/ it will set the querystring to \u201ctext=godoc skipper\u201d it will send a copy of the modified request to http://127.0.0.1:12345/ (similar to unix tee ) and drop the response and sends the modified request to https://yandex.ru More examples you find in eskip file format description, in filters and in predicates . Eskip file format is also used if you print your current routes in skipper, for example (metrics listener required): % curl localhost:9911/routes * -> setResponseHeader ( \" Content - Type \" , \" application / json ; charset = utf - 8 \" ) -> inlineContent ( \" { \\ \" foo \\ \" : 3 } \" ) -> < shunt >","title":"Eskip File"},{"location":"data-clients/etcd/","text":"etcd \u00b6 etcd is an open-source distributed key value store: https://github.com/etcd-io/etcd . Skipper can use it as a route configuration storage and continuously synchronize the routing from etcd. Why storing Skipper routes in etcd? \u00b6 When running multiple Skipper instances, changing the configuration of each instance by accessing the instances directly on the fly can be complex and error-prone. With etcd, we need to update the routes only in etcd and each Skipper instance will synchronize its routing from the new version. Further benefits of using etcd are improved resiliency and the usage of a standard configuration storage for various system components of a distributed system, not only Skipper. Note : in case of Kubernetes, the standard recommended way is to use the Kubernetes Ingress API . Starting Skipper with etcd \u00b6 Example: skipper -etcd-urls http://localhost:2379,http://localhost:4001 An additional startup option is the -etcd-prefix . When using multiple Skipper deployments with different purpose, this option allows us to store separate configuration sets for them in the same etcd cluster. Example: skipper -etcd-urls https://cluster-config -etcd-prefix skipper1 Note : when the etcd URL points to an etcd proxy , Skipper will internally use the proxy only to resolve the URLs of the etcd replicas, and access them for the route configuration directly. etcd version \u00b6 Skipper uses currently the V2 API of etcd. Storage schema \u00b6 Skipper expects to find the route configuration by default at the /v2/keys/skipper/routes path. In this path, the \u2018skipper\u2019 segment can be optionally overridden by the -etcd-prefix startup option. The /v2/keys/skipper/routes node is a directory that contains the routes as individual child nodes, accessed by the path /v2/keys/skipper/routes/<routeID> . The value of the route nodes is the route expression without the route ID in eskip format . Maintaining route configuration in etcd \u00b6 etcd (v2) allows generic access to its API via the HTTP protocol. It also provides a supporting client tool: etcdctl. Following the above described schema, both of them can be used to maintain Skipper routes. In addition, Skipper also provides a supporting client tool: eskip , which can provide more convenient access to the routes in etcd. Getting all routes, a single route, insert or update and delete via HTTP: curl http://localhost:2379/v2/keys/skipper/routes curl http://localhost:2379/v2/keys/skipper/routes/hello curl -X PUT -d 'value=* -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' http://localhost:2379/v2/keys/skipper/routes/hello curl -X DELETE http://localhost:2379/v2/keys/skipper/routes/hello Getting all route IDs, a route expression stored with an ID, insert or update and delete with etcdctl: etcdctl --endpoints http://localhost:2379,http://localhost:4001 ls /skipper/routes etcdctl --endpoints http://localhost:2379,http://localhost:4001 get /skipper/routes/hello etcdctl --endpoints http://localhost:2379,http://localhost:4001 set -- /skipper/routes/hello '* -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' etcdctl --endpoints http://localhost:2379,http://localhost:4001 rm /skipper/routes/bello We use the name \u2018eskip\u2019 for two related concepts: the eskip syntax of route configuration and the eskip command line tool. The command line tool can be used to check the syntax of skipper routes, format route files, prepend or append filters to multiple routes, and also to access etcd. Getting all routes, a single route, insert or update and delete with eskip: eskip print -etcd-urls http://localhost:2379,http://localhost:4001 eskip print -etcd-urls http://localhost:2379,http://localhost:4001 | grep hello eskip upsert -etcd-urls http://localhost:2379,http://localhost:4001 -routes 'hello: * -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' eskip delete -etcd-urls http://localhost:2379,http://localhost:4001 -ids hello When storing multiple configuration sets in etcd, we can use the -etcd-prefix to distinguish between them. Instead of using routes inline, it may be more convenient to edit them in a file and store them in etcd directly from the file. Contents of example.eskip: hello : * - > status ( 200 ) - > inlineContent ( \"Hello, world!\" ) - > < shunt >; helloTest : Path ( \"/test\" ) - > status ( 200 ) - > inlineContent ( \"Hello, test!\" ) - > < shunt >; Updating those routes in etcd that are defined in the file, or inserting them from the file in case they don\u2019t exist in etcd, yet: eskip upsert -etcd-urls http://localhost:2379,http://localhost:4001 example.eskip The above command won\u2019t modify or delete those routes, whose ID is missing from example.eskip. To fully sync a set of routes from a file to etcd, use the reset subcommand: eskip reset -etcd-urls http://localhost:2379,http://localhost:4001 example.eskip For more information see the documentation or eskip -help .","title":"Etcd"},{"location":"data-clients/etcd/#etcd","text":"etcd is an open-source distributed key value store: https://github.com/etcd-io/etcd . Skipper can use it as a route configuration storage and continuously synchronize the routing from etcd.","title":"etcd"},{"location":"data-clients/etcd/#why-storing-skipper-routes-in-etcd","text":"When running multiple Skipper instances, changing the configuration of each instance by accessing the instances directly on the fly can be complex and error-prone. With etcd, we need to update the routes only in etcd and each Skipper instance will synchronize its routing from the new version. Further benefits of using etcd are improved resiliency and the usage of a standard configuration storage for various system components of a distributed system, not only Skipper. Note : in case of Kubernetes, the standard recommended way is to use the Kubernetes Ingress API .","title":"Why storing Skipper routes in etcd?"},{"location":"data-clients/etcd/#starting-skipper-with-etcd","text":"Example: skipper -etcd-urls http://localhost:2379,http://localhost:4001 An additional startup option is the -etcd-prefix . When using multiple Skipper deployments with different purpose, this option allows us to store separate configuration sets for them in the same etcd cluster. Example: skipper -etcd-urls https://cluster-config -etcd-prefix skipper1 Note : when the etcd URL points to an etcd proxy , Skipper will internally use the proxy only to resolve the URLs of the etcd replicas, and access them for the route configuration directly.","title":"Starting Skipper with etcd"},{"location":"data-clients/etcd/#etcd-version","text":"Skipper uses currently the V2 API of etcd.","title":"etcd version"},{"location":"data-clients/etcd/#storage-schema","text":"Skipper expects to find the route configuration by default at the /v2/keys/skipper/routes path. In this path, the \u2018skipper\u2019 segment can be optionally overridden by the -etcd-prefix startup option. The /v2/keys/skipper/routes node is a directory that contains the routes as individual child nodes, accessed by the path /v2/keys/skipper/routes/<routeID> . The value of the route nodes is the route expression without the route ID in eskip format .","title":"Storage schema"},{"location":"data-clients/etcd/#maintaining-route-configuration-in-etcd","text":"etcd (v2) allows generic access to its API via the HTTP protocol. It also provides a supporting client tool: etcdctl. Following the above described schema, both of them can be used to maintain Skipper routes. In addition, Skipper also provides a supporting client tool: eskip , which can provide more convenient access to the routes in etcd. Getting all routes, a single route, insert or update and delete via HTTP: curl http://localhost:2379/v2/keys/skipper/routes curl http://localhost:2379/v2/keys/skipper/routes/hello curl -X PUT -d 'value=* -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' http://localhost:2379/v2/keys/skipper/routes/hello curl -X DELETE http://localhost:2379/v2/keys/skipper/routes/hello Getting all route IDs, a route expression stored with an ID, insert or update and delete with etcdctl: etcdctl --endpoints http://localhost:2379,http://localhost:4001 ls /skipper/routes etcdctl --endpoints http://localhost:2379,http://localhost:4001 get /skipper/routes/hello etcdctl --endpoints http://localhost:2379,http://localhost:4001 set -- /skipper/routes/hello '* -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' etcdctl --endpoints http://localhost:2379,http://localhost:4001 rm /skipper/routes/bello We use the name \u2018eskip\u2019 for two related concepts: the eskip syntax of route configuration and the eskip command line tool. The command line tool can be used to check the syntax of skipper routes, format route files, prepend or append filters to multiple routes, and also to access etcd. Getting all routes, a single route, insert or update and delete with eskip: eskip print -etcd-urls http://localhost:2379,http://localhost:4001 eskip print -etcd-urls http://localhost:2379,http://localhost:4001 | grep hello eskip upsert -etcd-urls http://localhost:2379,http://localhost:4001 -routes 'hello: * -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' eskip delete -etcd-urls http://localhost:2379,http://localhost:4001 -ids hello When storing multiple configuration sets in etcd, we can use the -etcd-prefix to distinguish between them. Instead of using routes inline, it may be more convenient to edit them in a file and store them in etcd directly from the file. Contents of example.eskip: hello : * - > status ( 200 ) - > inlineContent ( \"Hello, world!\" ) - > < shunt >; helloTest : Path ( \"/test\" ) - > status ( 200 ) - > inlineContent ( \"Hello, test!\" ) - > < shunt >; Updating those routes in etcd that are defined in the file, or inserting them from the file in case they don\u2019t exist in etcd, yet: eskip upsert -etcd-urls http://localhost:2379,http://localhost:4001 example.eskip The above command won\u2019t modify or delete those routes, whose ID is missing from example.eskip. To fully sync a set of routes from a file to etcd, use the reset subcommand: eskip reset -etcd-urls http://localhost:2379,http://localhost:4001 example.eskip For more information see the documentation or eskip -help .","title":"Maintaining route configuration in etcd"},{"location":"data-clients/kubernetes/","text":"Kubernetes \u00b6 Skipper\u2019s Kubernetes dataclient can be used, if you want to run Skipper as kubernetes-ingress-controller . It will get it\u2019s route information from provisioned Ingress Objects . Detailed information you find in our godoc for dataclient kubernetes . Kubernetes Ingress Controller deployment \u00b6 How to install Skipper ingress-controller for cluster operators. Kubernetes Ingress Usage \u00b6 Find out more how to use Skipper ingress features for deployers. Why to choose Skipper? \u00b6 Kubernetes is a fast changing environment and traditional http routers are not made for frequently changing routing tables. Skipper is a http proxy made to apply updates very often. Skipper is used in production with more than 200.000 routing table entries. Skipper has Filters to change http data and Predicates to change the matching rules, both can combined and chained. You can set these in ingress.yaml files to build resiliency patterns like ratelimit or circuitbreaker. You can also use them to build more highlevel deployment patterns, for example feature toggles, shadow traffic or blue-green deployments. Skipper\u2019s main features: Filters - create, update, delete all kind of HTTP data collection of base http manipulations : for example manipulating Path, Querystring, ResponseHeader, RequestHeader and redirect handling cookie handling circuitbreakers : consecutiveBreaker or rateBreaker ratelimit : based on client or backend data Shadow traffic: tee() Predicates - advanced matching capability URL Path match: Path(\"/foo\") Host header match: Host(\"^www.example.org$\") Querystring : QueryParam(\"featureX\") Cookie based : Cookie(\"alpha\", /^enabled$/) source whitelist : Source(\"1.2.3.4/24\") time based interval traffic by percentage supports also sticky sessions Kubernetes integration All Filters and Predicates can be used with 2 annotations Predicates: zalando.org/skipper-predicate Filters: zalando.org/skipper-filter Custom routes can be defined with the annotation zalando.org/skipper-routes metrics access logs Blue-Green deployments, with another Ingress annotation zalando.org/backend-weights","title":"Kubernetes"},{"location":"data-clients/kubernetes/#kubernetes","text":"Skipper\u2019s Kubernetes dataclient can be used, if you want to run Skipper as kubernetes-ingress-controller . It will get it\u2019s route information from provisioned Ingress Objects . Detailed information you find in our godoc for dataclient kubernetes .","title":"Kubernetes"},{"location":"data-clients/kubernetes/#kubernetes-ingress-controller-deployment","text":"How to install Skipper ingress-controller for cluster operators.","title":"Kubernetes Ingress Controller deployment"},{"location":"data-clients/kubernetes/#kubernetes-ingress-usage","text":"Find out more how to use Skipper ingress features for deployers.","title":"Kubernetes Ingress Usage"},{"location":"data-clients/kubernetes/#why-to-choose-skipper","text":"Kubernetes is a fast changing environment and traditional http routers are not made for frequently changing routing tables. Skipper is a http proxy made to apply updates very often. Skipper is used in production with more than 200.000 routing table entries. Skipper has Filters to change http data and Predicates to change the matching rules, both can combined and chained. You can set these in ingress.yaml files to build resiliency patterns like ratelimit or circuitbreaker. You can also use them to build more highlevel deployment patterns, for example feature toggles, shadow traffic or blue-green deployments. Skipper\u2019s main features: Filters - create, update, delete all kind of HTTP data collection of base http manipulations : for example manipulating Path, Querystring, ResponseHeader, RequestHeader and redirect handling cookie handling circuitbreakers : consecutiveBreaker or rateBreaker ratelimit : based on client or backend data Shadow traffic: tee() Predicates - advanced matching capability URL Path match: Path(\"/foo\") Host header match: Host(\"^www.example.org$\") Querystring : QueryParam(\"featureX\") Cookie based : Cookie(\"alpha\", /^enabled$/) source whitelist : Source(\"1.2.3.4/24\") time based interval traffic by percentage supports also sticky sessions Kubernetes integration All Filters and Predicates can be used with 2 annotations Predicates: zalando.org/skipper-predicate Filters: zalando.org/skipper-filter Custom routes can be defined with the annotation zalando.org/skipper-routes metrics access logs Blue-Green deployments, with another Ingress annotation zalando.org/backend-weights","title":"Why to choose Skipper?"},{"location":"data-clients/route-string/","text":"Route String \u00b6 Route string dataclient can be used to create simple demo applications, for example if you want to show traffic switching or ratelimiting or just need to serve some json in your demo. Serve text \u00b6 Serve with Content-Type: text/plain; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\"Hello, world!\") -> <shunt>' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090:9090 -it registry.opensource.zalan.do/pathfinder/skipper:latest skipper -inline-routes '* -> inlineContent(\"Hello, world!\") -> <shunt>' Serve HTML with CSS \u00b6 Serve with Content-Type: text/html; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\" <html><body style= \\\"background-color: orange;\\\" ></body></html> \") -> <shunt> ' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090:9090 -it registry.opensource.zalan.do/pathfinder/skipper:latest skipper -inline-routes '* -> inlineContent(\" <html><body style= \\\"background-color: orange;\\\" ></body></html> \") -> <shunt> ' Serve JSON \u00b6 Serve with Content-Type: application/json; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> setResponseHeader(\"Content-Type\", \"application/json; charset=utf-8\") -> inlineContent(\"{\\\"foo\\\": 3}\") -> <shunt>' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090 : 9090 -it registry . opensource . zalan . do / pathfinder / skipper : latest skipper -inline-routes '* -> setResponseHeader(\"Content-Type\", \"application/json; charset=utf-8\") -> inlineContent(\"{\\\"foo\\\": 3}\") -> <shunt>' Proxy to a given URL \u00b6 If you just have to build a workaround and you do not want to use socat to do a tcp proxy, but proxy http, you can do: % skipper -inline-routes '* -> \"https://my-new-backend.example.org/\"'","title":"Route String"},{"location":"data-clients/route-string/#route-string","text":"Route string dataclient can be used to create simple demo applications, for example if you want to show traffic switching or ratelimiting or just need to serve some json in your demo.","title":"Route String"},{"location":"data-clients/route-string/#serve-text","text":"Serve with Content-Type: text/plain; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\"Hello, world!\") -> <shunt>' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090:9090 -it registry.opensource.zalan.do/pathfinder/skipper:latest skipper -inline-routes '* -> inlineContent(\"Hello, world!\") -> <shunt>'","title":"Serve text"},{"location":"data-clients/route-string/#serve-html-with-css","text":"Serve with Content-Type: text/html; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\" <html><body style= \\\"background-color: orange;\\\" ></body></html> \") -> <shunt> ' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090:9090 -it registry.opensource.zalan.do/pathfinder/skipper:latest skipper -inline-routes '* -> inlineContent(\" <html><body style= \\\"background-color: orange;\\\" ></body></html> \") -> <shunt> '","title":"Serve HTML with CSS"},{"location":"data-clients/route-string/#serve-json","text":"Serve with Content-Type: application/json; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> setResponseHeader(\"Content-Type\", \"application/json; charset=utf-8\") -> inlineContent(\"{\\\"foo\\\": 3}\") -> <shunt>' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090 : 9090 -it registry . opensource . zalan . do / pathfinder / skipper : latest skipper -inline-routes '* -> setResponseHeader(\"Content-Type\", \"application/json; charset=utf-8\") -> inlineContent(\"{\\\"foo\\\": 3}\") -> <shunt>'","title":"Serve JSON"},{"location":"data-clients/route-string/#proxy-to-a-given-url","text":"If you just have to build a workaround and you do not want to use socat to do a tcp proxy, but proxy http, you can do: % skipper -inline-routes '* -> \"https://my-new-backend.example.org/\"'","title":"Proxy to a given URL"},{"location":"kubernetes/east-west-usage/","text":"East-West Usage \u00b6 If you run Skipper with an East-West setup , you can use the configured ingress also to do service-to-service calls, bypassing your ingress loadbalancer and stay inside the cluster. It depends on the configuration, but the default is that you can connect via HTTP to <name>.<namespace>.skipper.cluster.local to your application based on the ingress configuration. Example: apiVersion : extensions / v1beta1 kind : Ingress metadata : name : demo namespace : default spec : rules : - host : demo . example . org http : paths : - backend : serviceName : example servicePort : 80 Your clients inside the cluster should call this example with demo.default.skipper.cluster.local in their host header. Example from inside a container: curl http://demo.default.skipper.cluster.local/ Metrics will change, because skipper stores metrics per HTTP Host header, which changes with cluster internal calls from demo.example.org to demo.default.skipper.cluster.local . You can use all features as defined in Ingress Usage , Filters , Predicates via annotations as before and also custom-routes .","title":"East-West aka svc-to-svc"},{"location":"kubernetes/east-west-usage/#east-west-usage","text":"If you run Skipper with an East-West setup , you can use the configured ingress also to do service-to-service calls, bypassing your ingress loadbalancer and stay inside the cluster. It depends on the configuration, but the default is that you can connect via HTTP to <name>.<namespace>.skipper.cluster.local to your application based on the ingress configuration. Example: apiVersion : extensions / v1beta1 kind : Ingress metadata : name : demo namespace : default spec : rules : - host : demo . example . org http : paths : - backend : serviceName : example servicePort : 80 Your clients inside the cluster should call this example with demo.default.skipper.cluster.local in their host header. Example from inside a container: curl http://demo.default.skipper.cluster.local/ Metrics will change, because skipper stores metrics per HTTP Host header, which changes with cluster internal calls from demo.example.org to demo.default.skipper.cluster.local . You can use all features as defined in Ingress Usage , Filters , Predicates via annotations as before and also custom-routes .","title":"East-West Usage"},{"location":"kubernetes/ingress-backends/","text":"Kubernetes Backend Deployments \u00b6 Kubernetes Race Condition problem \u00b6 As described in #652 , there is a problem that exists in Kubernetes, while terminating Pods. Terminating Pods could be graceful, but the nature of distributed environments will show failures, because not all components in the distributed system changed already their state. When a Pod terminates, the controller-manager has to update the endpoints of the Kubernetes service . Additionally Skipper has to get this endpoints list. Skipper polls the kube-apiserver every -source-poll-timeout=<ms> , which defaults to 3000. Reducing this interval or implementing watch will only reduce the timeframe, but not fix the underlying race condition. Mitigation strategies can be different and the next section document strategies for application developers to mitigate the problem. Teardown strategies \u00b6 An application that is target of an ingress can circumvent HTTP code 504s Gateway Timeouts with these strategies: use Pod lifecycle hooks use a SIGTERM handler to switch readinessProbe to unhealthy and exit later, or just wait for SIGKILL terminating the process. Pod Lifecycle Hooks \u00b6 Kubernetes Pod Lifecycle Hooks in the Pod spec can have a preStop command which executes for example a binary. The following will execute the binary sleep with argument 20 to wait 20 seconds before terminating the containers within the Pod: lifecycle : preStop : exec : command : [ \"sleep\" , \"20\" ] 20 seconds should be enough to fade your Pod out of the endpoints list and Skipper\u2019s routing table. SIGTERM handling in Containers \u00b6 An application can implement a SIGTERM handler, that changes the readinessProbe target to unhealthy for the application instance. This will make sure it will be deleted from the endpoints list and from Skipper\u2019s routing table. Similar to Pod Lifecycle Hooks you could sleep 20 seconds and after that terminate your application or you just wait until SIGKILL will cleanup the instance after 60s. go func () { var sigs chan os . Signal sigs = make ( chan os . Signal , 1 ) signal . Notify ( sigs , syscall . SIGTERM ) for { select { case <- sigs : healthCheck = unhealthy time . Sleep ( 20 * time . Second ) os . Exit ( 0 ) } } }()","title":"Ingress Backends"},{"location":"kubernetes/ingress-backends/#kubernetes-backend-deployments","text":"","title":"Kubernetes Backend Deployments"},{"location":"kubernetes/ingress-backends/#kubernetes-race-condition-problem","text":"As described in #652 , there is a problem that exists in Kubernetes, while terminating Pods. Terminating Pods could be graceful, but the nature of distributed environments will show failures, because not all components in the distributed system changed already their state. When a Pod terminates, the controller-manager has to update the endpoints of the Kubernetes service . Additionally Skipper has to get this endpoints list. Skipper polls the kube-apiserver every -source-poll-timeout=<ms> , which defaults to 3000. Reducing this interval or implementing watch will only reduce the timeframe, but not fix the underlying race condition. Mitigation strategies can be different and the next section document strategies for application developers to mitigate the problem.","title":"Kubernetes Race Condition problem"},{"location":"kubernetes/ingress-backends/#teardown-strategies","text":"An application that is target of an ingress can circumvent HTTP code 504s Gateway Timeouts with these strategies: use Pod lifecycle hooks use a SIGTERM handler to switch readinessProbe to unhealthy and exit later, or just wait for SIGKILL terminating the process.","title":"Teardown strategies"},{"location":"kubernetes/ingress-backends/#pod-lifecycle-hooks","text":"Kubernetes Pod Lifecycle Hooks in the Pod spec can have a preStop command which executes for example a binary. The following will execute the binary sleep with argument 20 to wait 20 seconds before terminating the containers within the Pod: lifecycle : preStop : exec : command : [ \"sleep\" , \"20\" ] 20 seconds should be enough to fade your Pod out of the endpoints list and Skipper\u2019s routing table.","title":"Pod Lifecycle Hooks"},{"location":"kubernetes/ingress-backends/#sigterm-handling-in-containers","text":"An application can implement a SIGTERM handler, that changes the readinessProbe target to unhealthy for the application instance. This will make sure it will be deleted from the endpoints list and from Skipper\u2019s routing table. Similar to Pod Lifecycle Hooks you could sleep 20 seconds and after that terminate your application or you just wait until SIGKILL will cleanup the instance after 60s. go func () { var sigs chan os . Signal sigs = make ( chan os . Signal , 1 ) signal . Notify ( sigs , syscall . SIGTERM ) for { select { case <- sigs : healthCheck = unhealthy time . Sleep ( 20 * time . Second ) os . Exit ( 0 ) } } }()","title":"SIGTERM handling in Containers"},{"location":"kubernetes/ingress-controller/","text":"Skipper Ingress Controller \u00b6 This documentation is meant for cluster operators and describes how to install Skipper as Ingress-Controller in your Kubernetes Cluster. Why you should use Skipper as ingress controller? \u00b6 Baremetal loadbalancers perform really well, but their configuration is not updated frequently and most of the installations are not meant for rapid change. With the introduction of Kubernetes this assumption is no longer valid and there was a need for a HTTP router which supported backend routes which changed very frequently. Skipper was initially designed for a rapidly changing routing tree and subsequently used to implement an ingress controller in Kubernetes. Cloud loadbalancers scale well and can be updated frequently, but do not provide many features. Skipper has advanced resiliency and deployment features, which you can use to enhance your environment. For example, ratelimiters, circuitbreakers, blue-green deployments, shadow traffic and more . Comparison with other Ingress Controllers \u00b6 At Zalando we chose to run kube-ingress-aws-controller with skipper ingress as the target group. While AWS loadbalancers gives us features like TLS termination, automated certificate rotation, possible WAF , and Security Groups , the HTTP routing capabilities are very limited. Skipper\u2019s main advantage compared to other HTTP routers is matching and changing HTTP. Another advantage for us and for skipper users in general is that defaults with kube-ingress-aws-controller , just work as you would expect. There are a number of other ingress controllers including traefik , nginx , haproxy or aws-alb-ingress-controller . Why not one of these? HAproxy and Nginx are well understood and good TCP/HTTP proxies, that were built before Kubernetes. As a result, the first drawback is their reliance on static configuration files which comes from a time when routes and their configurations were relatively static. Secondly, the list of annotations to implement even basic features are already quite a big list for users. Skipper was built to support dynamically changing route configurations, which happens quite often in Kubernetes. Other advantage of using Skipper is that we are able to easily implement automated canary deployments, automated blue-green deployments or shadow traffic . However there are some features that have better support in aws-alb-ingress-controller , HAproxy and nginx . For instance the sendfile() operation. If you need to stream a large file or large amount of files, then you may want to go for one of these options. aws-alb-ingress-controller directly routes traffic to your Kubernetes services, which is both good and bad, because it can reduce latency, but comes with the risk of depending on kube-proxy routing. kube-proxy routing can take up to 30 seconds, ETCD ttl, for finding pods from dead nodes. In Skipper we passively observe errors from endpoints and are able to drop these from the loadbalancer members. We add these to an actively checked member pool, which will enable endpoints if these are healthy again from skipper point of view. Additionally the aws-alb-ingress-controller does not support features like ALB sharing, or Server Name Indication which can reduce costs. Features like path rewriting are also not currently supported. Traefik has a good community and support for Kubernetes. Skipper originates from Project Mosaic which was started in 2015. Back then Traefik was not yet a mature project and still had time to go before the v1.0.0 release. Traefik also does not currently support our Opentracing provider. It also did not support traffic splitting when we started stackset-controller for automated traffic switching. We have also recently done significant work on running Skipper as API gateway within Kubernetes, which could potentially help many teams that run a many small services on Kubernetes. Skipper predicates and filters are a powerful abstraction which can enhance the system easily. Comparison with service mesh \u00b6 Why run Skipper and not Istio , Linkerd or other service-mesh solutions? Skipper has a Kubernetes native integration, which is reliable, proven in production since end of 2015 as of March 2019 run in 112 Kubernetes clusters at Zalando. Skipper already has most of the features provided by service meshes: Authentication/Authorization in Kubernetes ingress , and can also integrate a custom service with webhook Diagnosis tools that support latency, bandwidth throttling, random content and more. Rich Metrics which you can enable and disable in the Prometheus format. Support for different Opentracing providers including jaeger, lightstep and instana Ratelimits support with cluster ratelimits as an pending solution, which enables you to stop login attacks easily Connects to endpoints directly, instead of using Kubernetes services Retries requests, if the request can be safely retried, which is only the case if the error happens on the TCP/IP connection establishment or a backend whose requests are defined as idempotent. Simple East-West Communication which enables proper communication paths without the need of yet another tool to do service discovery. See how to run skipper as API Gateway with East-West setup , if you want to run this powerful setup. Kubernetes, Skipper and DNS are the service discovery in this case. Blue-green deployments with automation if you like to use stackset-controller shadow-traffic to determine if the new version is able to handle the traffic the same as the old one A simple way to do A/B tests You are free to use cloud providers TLS terminations and certificate rotation, which is reliable and secure. Employees cannot download private keys and certificates are certified by a public CA. Many mTLS setups rely on insecure CA handling and are hard to debug in case of failure. We are happy to receive issues and pull requests in our repository, but if you need a feature which can not be implemented upstream, you are also free to use skipper as a library and create internal features to do whatever you want. With Skipper you do not need to choose to go all-in and you are able to add features as soon as you need or are comfortable. What is an Ingress-Controller? \u00b6 Ingress-controllers are serving http requests into a Kubernetes cluster. Most of the time traffic will pass ingress and go to a Kubernetes endpoints of the respective pods. For having a successful ingress, you need to have a DNS name pointing to some stable IP addresses that act as a loadbalancer. Skipper as ingress-controller: cloud: deploy behind the cloud loadbalancer baremetal: deploy behind your hardware/software loadbalancer and have all skipper as members in one pool. You would point your DNS entries to the loadbalancer in front of skipper, for example automated using external-dns . Why skipper uses endpoints and not services? \u00b6 Skipper does not use Kubernetes Services to route traffic to the pods. Instead it uses the Endpoints API to bypass kube-proxy created iptables to remove overhead like conntrack entries for iptables DNAT. Skipper can also reuse connections to Pods, such that you have no overhead in establishing connections all the time. To prevent errors on node failures, Skipper also does automatically retries to another endpoint in case it gets a connection refused or TLS handshake error to the endpoint. Other reasons are future support of features like session affinity, different loadbalancer algorithms or distributed loadbalancing also known as service mesh. AWS deployment \u00b6 In AWS, this could be an ALB with DNS pointing to the ALB. The ALB can then point to an ingress-controller running on an EC2 node and uses Kubernetes hostnetwork port specification in the Pod spec. A logical overview of the traffic flow in AWS is shown in this picture: We described that Skipper bypasses Kubernetes Service and use directly endpoints for good reasons , therefore the real traffic flow is shown in the next picture. Baremetal deployment \u00b6 In datacenter, baremetal environments, you probably have a hardware loadbalancer or some haproxy or nginx setup, that serves most of your production traffic and DNS points to these endpoints. For example *.ingress.example.com could point to your virtual server IPs in front of ingress. Skippers could be used as pool members, which do the http routing. Your loadbalancer of choice could have a wildcard certificate for *.ingress.example.com and DNS for this would point to your loadbalancer. You can also automate DNS records with external-dns , if you for example use PowerDNS as provider and have a loadbalancer controller that modifies the status field in ingress to your loadbalancer virtual IP. Requirements \u00b6 In general for one endpoint you need, a DNS A/AAAA record pointing to one or more loadbalancer IPs. Skipper is best used behind this layer 4 loadbalancer to route and manipulate HTTP data. minimal example: layer 4 loadbalancer has 1.2.3.4:80 as socket for a virtual server pointing to all skipper ingress *.ingress.example.com points to 1.2.3.4 ingress object with host entry for myapp.ingress.example.com targets a service type ClusterIP service type ClusterIP has a selector that targets your Pods of your myapp deployment TLS example: same as before, but you would terminate TLS on your layer 4 loadbalancer layer 4 loadbalancer has 1.2.3.4:443 as socket for a virtual server you can use an automated redirect for all port 80 requests to https with -kubernetes-https-redirect and change the default redirect code with -kubernetes-https-redirect-code Install Skipper as ingress-controller \u00b6 You should have a base understanding of Kubernetes and Ingress . Prerequisites: First you have to install skipper-ingress as for example daemonset, create a deployment and a service. We start to deploy skipper-ingress as a daemonset, use hostNetwork and expose the TCP port 9999 on each Kubernetes worker node for incoming ingress traffic. # cat skipper-ingress-ds.yaml apiVersion : extensions/v1beta1 kind : DaemonSet metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress version : v0.10.180 component : ingress spec : selector : matchLabels : application : skipper-ingress updateStrategy : type : RollingUpdate template : metadata : name : skipper-ingress labels : application : skipper-ingress version : v0.10.180 component : ingress annotations : scheduler.alpha.kubernetes.io/critical-pod : '' spec : priorityClassName : system-node-critical tolerations : - key : dedicated operator : Exists nodeSelector : kubernetes.io/role : worker hostNetwork : true containers : - name : skipper-ingress image : registry.opensource.zalan.do/pathfinder/skipper:v0.10.180 ports : - name : ingress-port containerPort : 9999 hostPort : 9999 - name : metrics-port containerPort : 9911 args : - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-serve-host-metrics\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-metrics-exp-decay-sample\" - \"-reverse-source-predicate\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=codahale,prometheus\" - \"-enable-connection-metrics\" - \"-max-audit-body=0\" - \"-histogram-metric-buckets=.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" resources : requests : cpu : 150m memory : 150Mi readinessProbe : httpGet : path : /kube-system/healthz port : 9999 initialDelaySeconds : 5 timeoutSeconds : 5 securityContext : readOnlyRootFilesystem : true runAsNonRoot : true runAsUser : 1000 Please check, that you are using the latest release , we do not maintain the latest tag. We now deploy a simple demo application serving html: # cat demo-deployment.yaml apiVersion : apps/v1beta1 kind : Deployment metadata : name : skipper-demo spec : replicas : 2 template : metadata : labels : application : skipper-demo spec : containers : - name : skipper-demo image : registry.opensource.zalan.do/pathfinder/skipper:v0.10.180 args : - \"skipper\" - \"-inline-routes\" - \"* -> inlineContent(\\\"<body style='color: white; background-color: green;'><h1>Hello!</h1>\\\") -> <shunt>\" ports : - containerPort : 9090 We deploy a service type ClusterIP that we will select from ingress: # cat demo-svc.yaml apiVersion : v1 kind : Service metadata : name : skipper-demo labels : application : skipper-demo spec : type : ClusterIP ports : - port : 80 protocol : TCP targetPort : 9090 name : external selector : application : skipper-demo To deploy both, you have to run: kubectl create -f demo-deployment.yaml kubectl create -f demo-svc.yaml Now we have a skipper-ingress running as daemonset exposing the TCP port 9999 on each worker node, a backend application running with 2 replicas that serves some html on TCP port 9090, and we expose a cluster service on TCP port 80. Besides skipper-ingress, deployment and service can not be reached from outside the cluster. Now we expose the application with Ingress to the external network: # cat demo-ing.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: skipper-demo spec: rules: - host: skipper-demo.<mydomain.org> http: paths: - backend: serviceName: skipper-demo servicePort: 80 To deploy this ingress, you have to run: kubectl create -f demo-ing.yaml Skipper will configure itself for the given ingress, such that you can test doing: curl -v -H \"Host: skipper-demo.<mydomain.org>\" http://<nodeip>:9999/ The next question you may ask is: how to expose this to your customers? The answer depends on your setup and complexity requirements. In the simplest case you could add one A record in your DNS *.<mydomain.org> to your frontend loadbalancer IP that directs all traffic from *.<mydomain.org> to all Kubernetes worker nodes on TCP port 9999. A more complex setup we use in production and can be done with something that configures your frontend loadbalancer, for example kube-aws-ingress-controller , and your DNS, external-dns automatically. Multiple skipper deployments \u00b6 If you want to split for example internal and public traffic, it might be a good choice to split your ingress deployments. Skipper has the flag --kubernetes-ingress-class=<string> to only select ingress objects that have the annotation kubernetes.io/ingress.class set to <string> . Skipper will only create routes for ingress objects with it\u2019s annotation or ingress objects that do not have this annotation. The default ingress class is skipper , if not set. You have to create your ingress objects with the annotation kubernetes.io/ingress.class: skipper to make sure only skipper will serve the traffic. Example ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : kubernetes.io/ingress.class : skipper name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Scoping Skipper Deployments to a Single Namespace \u00b6 In some instances you might want skipper to only watch for ingress objects created in a single namespace. This can be achieved by using kubernetes-namespace=<string> where <string> is the Kubernetes namespace. Specifying this option forces Skipper to look at the namespace ingresses endpoint rather than the cluster-wide ingresses endpoint. By default this value is an empty string ( \"\" ) and will scope the skipper instance to be cluster-wide, watching all Ingress objects across all namespaces. Install Skipper with enabled RBAC \u00b6 If Role-Based Access Control (\u201cRBAC\u201d) is enabled you have to create some additional resources to enable Skipper to query the Kubernetes API. This guide describes all necessary resources to get Skipper up and running in a Kubernetes cluster with RBAC enabled but it\u2019s highly recommended to read the RBAC docs to get a better understanding which permissions are delegated to Skipper within your Kubernetes cluster. First create a new ServiceAccount which will be assigned to the Skipper pods: apiVersion : v1 kind : ServiceAccount metadata : name : skipper-ingress namespace : kube-system the required permissions are defined within a ClusterRole resource. Note: It\u2019s important to use a ClusterRole instead of normal Role because otherwise Skipper could only access resources in the namespace the Role was created! ClusterRole: apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRole metadata : name : skipper-ingress rules : - apiGroups : [ \"extensions\" ] resources : [ \"ingresses\" , ] verbs : [ \"get\" , \"list\" ] - apiGroups : [ \"\" ] resources : [ \"namespaces\" , \"services\" , \"endpoints\" , \"pods\" ] verbs : [ \"get\" , \"list\" ] This ClusterRole defines access to get and list all created ingresses, namespaces, services and endpoints. To assign the defined ClusterRole to the previously created ServiceAccount a ClusterRoleBinding has to be created: ClusterRoleBinding: apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRoleBinding metadata : name : skipper-ingress roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : skipper-ingress subjects : - kind : ServiceAccount name : skipper-ingress namespace : kube-system Last but not least the ServiceAccount has to be assigned to the Skipper daemonset. daemonset: apiVersion : extensions/v1beta1 kind : DaemonSet metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress version : v0.10.180 component : ingress spec : selector : matchLabels : application : skipper-ingress updateStrategy : type : RollingUpdate template : metadata : name : skipper-ingress labels : application : skipper-ingress version : v0.10.180 component : ingress annotations : scheduler.alpha.kubernetes.io/critical-pod : '' spec : priorityClassName : system-node-critical tolerations : - key : dedicated operator : Exists nodeSelector : kubernetes.io/role : worker hostNetwork : true serviceAccountName : skipper-ingress containers : - name : skipper-ingress image : registry.opensource.zalan.do/pathfinder/skipper:v0.10.180 ports : - name : ingress-port containerPort : 9999 hostPort : 9999 - name : metrics-port containerPort : 9911 args : - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-serve-host-metrics\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-metrics-exp-decay-sample\" - \"-reverse-source-predicate\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=codahale,prometheus\" - \"-enable-connection-metrics\" - \"-max-audit-body=0\" - \"-histogram-metric-buckets=.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" resources : requests : cpu : 150m memory : 150Mi readinessProbe : httpGet : path : /kube-system/healthz port : 9999 initialDelaySeconds : 5 timeoutSeconds : 5 securityContext : readOnlyRootFilesystem : true runAsNonRoot : true runAsUser : 1000 Please check, that you are using the latest release , we do not maintain the latest tag. Helm-based deployment \u00b6 Helm calls itself the package manager for Kubernetes and therefore take cares of the deployment of whole applications including resources like services, configurations and so on. Skipper is also available as community contributed Helm chart in the public quay.io registry. The latest packaged release can be found here . The source code is available at GitHub . The chart includes resource definitions for the following use cases: RBAC CoreOS Prometheus-Operator As this chart is not maintained by the Skipper developers and is still under development only the basic deployment workflow is covered here. Check the GitHub repository for all details. To be able to deploy the chart you will need the following components: helm CLI (Install guide here ) Helm registry plugin (available here ) If your environment is setup correctly you should be able to run helm version --client and helm registry version quay.io and get some information about your tooling without any error. It is possible to deploy the chart without any further configuration like this: helm registry upgrade quay.io/baez/skipper -- \\ --install \\ --wait \\ \"your release name e.g. skipper\" The --wait switch can be omitted as it only takes care that Helm is waiting until the chart is completely deployed (meaning all resources are created). To update the deployment to a newer version the same command can be used. If you have RBAC enabled in your Kubernetes instance you don\u2019t have to create all the previously described resources on your own but you can let Helm create them by simply adding one more switch: helm registry upgrade quay.io/baez/skipper -- \\ --install \\ --wait \\ --set rbac.create=true \\ \"your release name e.g. skipper\" There are some more options available for customization of the chart. Check the repository if you need more configuration possibilities. Run as API Gateway with East-West setup \u00b6 East-West means cluster internal service-to-service communication. For this you need to resolve DNS to skipper for an additional domain .skipper.cluster.local we introduce and add HTTP routes to route to the specified backend from your normal ingress object. Skipper \u00b6 To enable the East-West in skipper, you need to run skipper with -enable-kubernetes-east-west enabled. Skipper will duplicate all routes with a Host() predicate and change it to match the host header scheme: <name>.<namespace>.skipper.cluster.local . You need also to have a kubernetes service type ClusterIP and write down the IP (p.e. 10.3.11.28 ), which you will need in CoreDNS setup. CoreDNS \u00b6 You can create the DNS records with the template plugin from CoreDNS. Corefile example: .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa } template IN A skipper.cluster.local { match \"^.*[.]skipper[.]cluster[.]local\" answer \" {{ .Name }} 60 IN A 10.3.11.28\" fallthrough } prometheus :9153 proxy . /etc/resolv.conf cache 30 reload } Usage \u00b6 If the setup was done correctly, the following ingress example will create an internal route with Host(/^demo[.]default[.]skipper[.]cluster[.]local) predicate: apiVersion : extensions / v1beta1 kind : Ingress metadata : name : demo namespace : default spec : rules : - host : demo . example . org http : paths : - backend : serviceName : example servicePort : 80 Your clients inside the cluster should call this example with demo.default.skipper.cluster.local in their host header. Example from inside a container: curl demo.default.skipper.cluster.local Running with Cluster Ratelimits \u00b6 Cluster ratelimits require a communication exchange method to build a skipper swarm to have a shared knowledge about the requests passing all skipper instances. To enable this feature you need to add command line option -enable-swarm and -enable-ratelimits . The rest depends on the implementation, that can be: Redis SWIM Redis based \u00b6 Additionally you have to add -swarm-redis-urls to skipper args: . For example: -swarm-redis-urls=skipper-redis-0.skipper-redis.kube-system.svc.cluster.local:6379,skipper-redis-1.skipper-redis.kube-system.svc.cluster.local:6379 . Running skipper with hostNetwork in kubernetes will not be able to resolve redis hostnames as shown in the example, if skipper does not have dnsPolicy: ClusterFirstWithHostNet in it\u2019s Pod spec, see also DNS policy in the official Kubernetes documentation . This setup is considered experimental and should be carefully tested before running it in production. Example redis statefulset with headless service: apiVersion : apps/v1 kind : StatefulSet metadata : labels : application : skipper-redis version : v4.0.9 name : skipper-redis namespace : kube-system spec : replicas : 2 selector : matchLabels : application : skipper-redis serviceName : skipper-redis template : metadata : labels : application : skipper-redis version : v4.0.9 spec : containers : - image : registry.opensource.zalan.do/zmon/redis:4.0.9-master-6 name : skipper-redis ports : - containerPort : 6379 protocol : TCP readinessProbe : exec : command : - redis-cli - ping failureThreshold : 3 initialDelaySeconds : 10 periodSeconds : 60 successThreshold : 1 timeoutSeconds : 1 resources : limits : cpu : 100m memory : 100Mi dnsPolicy : ClusterFirst restartPolicy : Always schedulerName : default-scheduler --- apiVersion : v1 kind : Service metadata : labels : application : skipper-redis name : skipper-redis namespace : kube-system spec : clusterIP : None ports : - port : 6379 protocol : TCP targetPort : 6379 selector : application : skipper-redis type : ClusterIP SWIM based \u00b6 SWIM is a \u201cScalable Weakly-consistent Infection-style Process Group Membership Protocol\u201d, which is very interesting for example to use for cluster ratelimits. This setup is not considered stable enough to run production, yet. Additionally you have to add the following command line flags to skipper\u2019s container spec args: : -swarm-port=9990 -swarm-label-selector-key=application -swarm-label-selector-value=skipper-ingress -swarm-leave-timeout=5s -swarm-max-msg-buffer=4194304 -swarm-namespace=kube-system and open another port in Kubernetes and your Firewall settings to make the communication work with TCP and UDP to the specified swarm-port : - containerPort : 9990 hostPort : 9990 name : swarm-port protocol : TCP","title":"Ingress Controller Deployment"},{"location":"kubernetes/ingress-controller/#skipper-ingress-controller","text":"This documentation is meant for cluster operators and describes how to install Skipper as Ingress-Controller in your Kubernetes Cluster.","title":"Skipper Ingress Controller"},{"location":"kubernetes/ingress-controller/#why-you-should-use-skipper-as-ingress-controller","text":"Baremetal loadbalancers perform really well, but their configuration is not updated frequently and most of the installations are not meant for rapid change. With the introduction of Kubernetes this assumption is no longer valid and there was a need for a HTTP router which supported backend routes which changed very frequently. Skipper was initially designed for a rapidly changing routing tree and subsequently used to implement an ingress controller in Kubernetes. Cloud loadbalancers scale well and can be updated frequently, but do not provide many features. Skipper has advanced resiliency and deployment features, which you can use to enhance your environment. For example, ratelimiters, circuitbreakers, blue-green deployments, shadow traffic and more .","title":"Why you should use Skipper as ingress controller?"},{"location":"kubernetes/ingress-controller/#comparison-with-other-ingress-controllers","text":"At Zalando we chose to run kube-ingress-aws-controller with skipper ingress as the target group. While AWS loadbalancers gives us features like TLS termination, automated certificate rotation, possible WAF , and Security Groups , the HTTP routing capabilities are very limited. Skipper\u2019s main advantage compared to other HTTP routers is matching and changing HTTP. Another advantage for us and for skipper users in general is that defaults with kube-ingress-aws-controller , just work as you would expect. There are a number of other ingress controllers including traefik , nginx , haproxy or aws-alb-ingress-controller . Why not one of these? HAproxy and Nginx are well understood and good TCP/HTTP proxies, that were built before Kubernetes. As a result, the first drawback is their reliance on static configuration files which comes from a time when routes and their configurations were relatively static. Secondly, the list of annotations to implement even basic features are already quite a big list for users. Skipper was built to support dynamically changing route configurations, which happens quite often in Kubernetes. Other advantage of using Skipper is that we are able to easily implement automated canary deployments, automated blue-green deployments or shadow traffic . However there are some features that have better support in aws-alb-ingress-controller , HAproxy and nginx . For instance the sendfile() operation. If you need to stream a large file or large amount of files, then you may want to go for one of these options. aws-alb-ingress-controller directly routes traffic to your Kubernetes services, which is both good and bad, because it can reduce latency, but comes with the risk of depending on kube-proxy routing. kube-proxy routing can take up to 30 seconds, ETCD ttl, for finding pods from dead nodes. In Skipper we passively observe errors from endpoints and are able to drop these from the loadbalancer members. We add these to an actively checked member pool, which will enable endpoints if these are healthy again from skipper point of view. Additionally the aws-alb-ingress-controller does not support features like ALB sharing, or Server Name Indication which can reduce costs. Features like path rewriting are also not currently supported. Traefik has a good community and support for Kubernetes. Skipper originates from Project Mosaic which was started in 2015. Back then Traefik was not yet a mature project and still had time to go before the v1.0.0 release. Traefik also does not currently support our Opentracing provider. It also did not support traffic splitting when we started stackset-controller for automated traffic switching. We have also recently done significant work on running Skipper as API gateway within Kubernetes, which could potentially help many teams that run a many small services on Kubernetes. Skipper predicates and filters are a powerful abstraction which can enhance the system easily.","title":"Comparison with other Ingress Controllers"},{"location":"kubernetes/ingress-controller/#comparison-with-service-mesh","text":"Why run Skipper and not Istio , Linkerd or other service-mesh solutions? Skipper has a Kubernetes native integration, which is reliable, proven in production since end of 2015 as of March 2019 run in 112 Kubernetes clusters at Zalando. Skipper already has most of the features provided by service meshes: Authentication/Authorization in Kubernetes ingress , and can also integrate a custom service with webhook Diagnosis tools that support latency, bandwidth throttling, random content and more. Rich Metrics which you can enable and disable in the Prometheus format. Support for different Opentracing providers including jaeger, lightstep and instana Ratelimits support with cluster ratelimits as an pending solution, which enables you to stop login attacks easily Connects to endpoints directly, instead of using Kubernetes services Retries requests, if the request can be safely retried, which is only the case if the error happens on the TCP/IP connection establishment or a backend whose requests are defined as idempotent. Simple East-West Communication which enables proper communication paths without the need of yet another tool to do service discovery. See how to run skipper as API Gateway with East-West setup , if you want to run this powerful setup. Kubernetes, Skipper and DNS are the service discovery in this case. Blue-green deployments with automation if you like to use stackset-controller shadow-traffic to determine if the new version is able to handle the traffic the same as the old one A simple way to do A/B tests You are free to use cloud providers TLS terminations and certificate rotation, which is reliable and secure. Employees cannot download private keys and certificates are certified by a public CA. Many mTLS setups rely on insecure CA handling and are hard to debug in case of failure. We are happy to receive issues and pull requests in our repository, but if you need a feature which can not be implemented upstream, you are also free to use skipper as a library and create internal features to do whatever you want. With Skipper you do not need to choose to go all-in and you are able to add features as soon as you need or are comfortable.","title":"Comparison with service mesh"},{"location":"kubernetes/ingress-controller/#what-is-an-ingress-controller","text":"Ingress-controllers are serving http requests into a Kubernetes cluster. Most of the time traffic will pass ingress and go to a Kubernetes endpoints of the respective pods. For having a successful ingress, you need to have a DNS name pointing to some stable IP addresses that act as a loadbalancer. Skipper as ingress-controller: cloud: deploy behind the cloud loadbalancer baremetal: deploy behind your hardware/software loadbalancer and have all skipper as members in one pool. You would point your DNS entries to the loadbalancer in front of skipper, for example automated using external-dns .","title":"What is an Ingress-Controller?"},{"location":"kubernetes/ingress-controller/#why-skipper-uses-endpoints-and-not-services","text":"Skipper does not use Kubernetes Services to route traffic to the pods. Instead it uses the Endpoints API to bypass kube-proxy created iptables to remove overhead like conntrack entries for iptables DNAT. Skipper can also reuse connections to Pods, such that you have no overhead in establishing connections all the time. To prevent errors on node failures, Skipper also does automatically retries to another endpoint in case it gets a connection refused or TLS handshake error to the endpoint. Other reasons are future support of features like session affinity, different loadbalancer algorithms or distributed loadbalancing also known as service mesh.","title":"Why skipper uses endpoints and not services?"},{"location":"kubernetes/ingress-controller/#aws-deployment","text":"In AWS, this could be an ALB with DNS pointing to the ALB. The ALB can then point to an ingress-controller running on an EC2 node and uses Kubernetes hostnetwork port specification in the Pod spec. A logical overview of the traffic flow in AWS is shown in this picture: We described that Skipper bypasses Kubernetes Service and use directly endpoints for good reasons , therefore the real traffic flow is shown in the next picture.","title":"AWS deployment"},{"location":"kubernetes/ingress-controller/#baremetal-deployment","text":"In datacenter, baremetal environments, you probably have a hardware loadbalancer or some haproxy or nginx setup, that serves most of your production traffic and DNS points to these endpoints. For example *.ingress.example.com could point to your virtual server IPs in front of ingress. Skippers could be used as pool members, which do the http routing. Your loadbalancer of choice could have a wildcard certificate for *.ingress.example.com and DNS for this would point to your loadbalancer. You can also automate DNS records with external-dns , if you for example use PowerDNS as provider and have a loadbalancer controller that modifies the status field in ingress to your loadbalancer virtual IP.","title":"Baremetal deployment"},{"location":"kubernetes/ingress-controller/#requirements","text":"In general for one endpoint you need, a DNS A/AAAA record pointing to one or more loadbalancer IPs. Skipper is best used behind this layer 4 loadbalancer to route and manipulate HTTP data. minimal example: layer 4 loadbalancer has 1.2.3.4:80 as socket for a virtual server pointing to all skipper ingress *.ingress.example.com points to 1.2.3.4 ingress object with host entry for myapp.ingress.example.com targets a service type ClusterIP service type ClusterIP has a selector that targets your Pods of your myapp deployment TLS example: same as before, but you would terminate TLS on your layer 4 loadbalancer layer 4 loadbalancer has 1.2.3.4:443 as socket for a virtual server you can use an automated redirect for all port 80 requests to https with -kubernetes-https-redirect and change the default redirect code with -kubernetes-https-redirect-code","title":"Requirements"},{"location":"kubernetes/ingress-controller/#install-skipper-as-ingress-controller","text":"You should have a base understanding of Kubernetes and Ingress . Prerequisites: First you have to install skipper-ingress as for example daemonset, create a deployment and a service. We start to deploy skipper-ingress as a daemonset, use hostNetwork and expose the TCP port 9999 on each Kubernetes worker node for incoming ingress traffic. # cat skipper-ingress-ds.yaml apiVersion : extensions/v1beta1 kind : DaemonSet metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress version : v0.10.180 component : ingress spec : selector : matchLabels : application : skipper-ingress updateStrategy : type : RollingUpdate template : metadata : name : skipper-ingress labels : application : skipper-ingress version : v0.10.180 component : ingress annotations : scheduler.alpha.kubernetes.io/critical-pod : '' spec : priorityClassName : system-node-critical tolerations : - key : dedicated operator : Exists nodeSelector : kubernetes.io/role : worker hostNetwork : true containers : - name : skipper-ingress image : registry.opensource.zalan.do/pathfinder/skipper:v0.10.180 ports : - name : ingress-port containerPort : 9999 hostPort : 9999 - name : metrics-port containerPort : 9911 args : - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-serve-host-metrics\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-metrics-exp-decay-sample\" - \"-reverse-source-predicate\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=codahale,prometheus\" - \"-enable-connection-metrics\" - \"-max-audit-body=0\" - \"-histogram-metric-buckets=.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" resources : requests : cpu : 150m memory : 150Mi readinessProbe : httpGet : path : /kube-system/healthz port : 9999 initialDelaySeconds : 5 timeoutSeconds : 5 securityContext : readOnlyRootFilesystem : true runAsNonRoot : true runAsUser : 1000 Please check, that you are using the latest release , we do not maintain the latest tag. We now deploy a simple demo application serving html: # cat demo-deployment.yaml apiVersion : apps/v1beta1 kind : Deployment metadata : name : skipper-demo spec : replicas : 2 template : metadata : labels : application : skipper-demo spec : containers : - name : skipper-demo image : registry.opensource.zalan.do/pathfinder/skipper:v0.10.180 args : - \"skipper\" - \"-inline-routes\" - \"* -> inlineContent(\\\"<body style='color: white; background-color: green;'><h1>Hello!</h1>\\\") -> <shunt>\" ports : - containerPort : 9090 We deploy a service type ClusterIP that we will select from ingress: # cat demo-svc.yaml apiVersion : v1 kind : Service metadata : name : skipper-demo labels : application : skipper-demo spec : type : ClusterIP ports : - port : 80 protocol : TCP targetPort : 9090 name : external selector : application : skipper-demo To deploy both, you have to run: kubectl create -f demo-deployment.yaml kubectl create -f demo-svc.yaml Now we have a skipper-ingress running as daemonset exposing the TCP port 9999 on each worker node, a backend application running with 2 replicas that serves some html on TCP port 9090, and we expose a cluster service on TCP port 80. Besides skipper-ingress, deployment and service can not be reached from outside the cluster. Now we expose the application with Ingress to the external network: # cat demo-ing.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: skipper-demo spec: rules: - host: skipper-demo.<mydomain.org> http: paths: - backend: serviceName: skipper-demo servicePort: 80 To deploy this ingress, you have to run: kubectl create -f demo-ing.yaml Skipper will configure itself for the given ingress, such that you can test doing: curl -v -H \"Host: skipper-demo.<mydomain.org>\" http://<nodeip>:9999/ The next question you may ask is: how to expose this to your customers? The answer depends on your setup and complexity requirements. In the simplest case you could add one A record in your DNS *.<mydomain.org> to your frontend loadbalancer IP that directs all traffic from *.<mydomain.org> to all Kubernetes worker nodes on TCP port 9999. A more complex setup we use in production and can be done with something that configures your frontend loadbalancer, for example kube-aws-ingress-controller , and your DNS, external-dns automatically.","title":"Install Skipper as ingress-controller"},{"location":"kubernetes/ingress-controller/#multiple-skipper-deployments","text":"If you want to split for example internal and public traffic, it might be a good choice to split your ingress deployments. Skipper has the flag --kubernetes-ingress-class=<string> to only select ingress objects that have the annotation kubernetes.io/ingress.class set to <string> . Skipper will only create routes for ingress objects with it\u2019s annotation or ingress objects that do not have this annotation. The default ingress class is skipper , if not set. You have to create your ingress objects with the annotation kubernetes.io/ingress.class: skipper to make sure only skipper will serve the traffic. Example ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : kubernetes.io/ingress.class : skipper name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Multiple skipper deployments"},{"location":"kubernetes/ingress-controller/#scoping-skipper-deployments-to-a-single-namespace","text":"In some instances you might want skipper to only watch for ingress objects created in a single namespace. This can be achieved by using kubernetes-namespace=<string> where <string> is the Kubernetes namespace. Specifying this option forces Skipper to look at the namespace ingresses endpoint rather than the cluster-wide ingresses endpoint. By default this value is an empty string ( \"\" ) and will scope the skipper instance to be cluster-wide, watching all Ingress objects across all namespaces.","title":"Scoping Skipper Deployments to a Single Namespace"},{"location":"kubernetes/ingress-controller/#install-skipper-with-enabled-rbac","text":"If Role-Based Access Control (\u201cRBAC\u201d) is enabled you have to create some additional resources to enable Skipper to query the Kubernetes API. This guide describes all necessary resources to get Skipper up and running in a Kubernetes cluster with RBAC enabled but it\u2019s highly recommended to read the RBAC docs to get a better understanding which permissions are delegated to Skipper within your Kubernetes cluster. First create a new ServiceAccount which will be assigned to the Skipper pods: apiVersion : v1 kind : ServiceAccount metadata : name : skipper-ingress namespace : kube-system the required permissions are defined within a ClusterRole resource. Note: It\u2019s important to use a ClusterRole instead of normal Role because otherwise Skipper could only access resources in the namespace the Role was created! ClusterRole: apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRole metadata : name : skipper-ingress rules : - apiGroups : [ \"extensions\" ] resources : [ \"ingresses\" , ] verbs : [ \"get\" , \"list\" ] - apiGroups : [ \"\" ] resources : [ \"namespaces\" , \"services\" , \"endpoints\" , \"pods\" ] verbs : [ \"get\" , \"list\" ] This ClusterRole defines access to get and list all created ingresses, namespaces, services and endpoints. To assign the defined ClusterRole to the previously created ServiceAccount a ClusterRoleBinding has to be created: ClusterRoleBinding: apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRoleBinding metadata : name : skipper-ingress roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : skipper-ingress subjects : - kind : ServiceAccount name : skipper-ingress namespace : kube-system Last but not least the ServiceAccount has to be assigned to the Skipper daemonset. daemonset: apiVersion : extensions/v1beta1 kind : DaemonSet metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress version : v0.10.180 component : ingress spec : selector : matchLabels : application : skipper-ingress updateStrategy : type : RollingUpdate template : metadata : name : skipper-ingress labels : application : skipper-ingress version : v0.10.180 component : ingress annotations : scheduler.alpha.kubernetes.io/critical-pod : '' spec : priorityClassName : system-node-critical tolerations : - key : dedicated operator : Exists nodeSelector : kubernetes.io/role : worker hostNetwork : true serviceAccountName : skipper-ingress containers : - name : skipper-ingress image : registry.opensource.zalan.do/pathfinder/skipper:v0.10.180 ports : - name : ingress-port containerPort : 9999 hostPort : 9999 - name : metrics-port containerPort : 9911 args : - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-serve-host-metrics\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-metrics-exp-decay-sample\" - \"-reverse-source-predicate\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=codahale,prometheus\" - \"-enable-connection-metrics\" - \"-max-audit-body=0\" - \"-histogram-metric-buckets=.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" resources : requests : cpu : 150m memory : 150Mi readinessProbe : httpGet : path : /kube-system/healthz port : 9999 initialDelaySeconds : 5 timeoutSeconds : 5 securityContext : readOnlyRootFilesystem : true runAsNonRoot : true runAsUser : 1000 Please check, that you are using the latest release , we do not maintain the latest tag.","title":"Install Skipper with enabled RBAC"},{"location":"kubernetes/ingress-controller/#helm-based-deployment","text":"Helm calls itself the package manager for Kubernetes and therefore take cares of the deployment of whole applications including resources like services, configurations and so on. Skipper is also available as community contributed Helm chart in the public quay.io registry. The latest packaged release can be found here . The source code is available at GitHub . The chart includes resource definitions for the following use cases: RBAC CoreOS Prometheus-Operator As this chart is not maintained by the Skipper developers and is still under development only the basic deployment workflow is covered here. Check the GitHub repository for all details. To be able to deploy the chart you will need the following components: helm CLI (Install guide here ) Helm registry plugin (available here ) If your environment is setup correctly you should be able to run helm version --client and helm registry version quay.io and get some information about your tooling without any error. It is possible to deploy the chart without any further configuration like this: helm registry upgrade quay.io/baez/skipper -- \\ --install \\ --wait \\ \"your release name e.g. skipper\" The --wait switch can be omitted as it only takes care that Helm is waiting until the chart is completely deployed (meaning all resources are created). To update the deployment to a newer version the same command can be used. If you have RBAC enabled in your Kubernetes instance you don\u2019t have to create all the previously described resources on your own but you can let Helm create them by simply adding one more switch: helm registry upgrade quay.io/baez/skipper -- \\ --install \\ --wait \\ --set rbac.create=true \\ \"your release name e.g. skipper\" There are some more options available for customization of the chart. Check the repository if you need more configuration possibilities.","title":"Helm-based deployment"},{"location":"kubernetes/ingress-controller/#run-as-api-gateway-with-east-west-setup","text":"East-West means cluster internal service-to-service communication. For this you need to resolve DNS to skipper for an additional domain .skipper.cluster.local we introduce and add HTTP routes to route to the specified backend from your normal ingress object.","title":"Run as API Gateway with East-West setup"},{"location":"kubernetes/ingress-controller/#skipper","text":"To enable the East-West in skipper, you need to run skipper with -enable-kubernetes-east-west enabled. Skipper will duplicate all routes with a Host() predicate and change it to match the host header scheme: <name>.<namespace>.skipper.cluster.local . You need also to have a kubernetes service type ClusterIP and write down the IP (p.e. 10.3.11.28 ), which you will need in CoreDNS setup.","title":"Skipper"},{"location":"kubernetes/ingress-controller/#coredns","text":"You can create the DNS records with the template plugin from CoreDNS. Corefile example: .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa } template IN A skipper.cluster.local { match \"^.*[.]skipper[.]cluster[.]local\" answer \" {{ .Name }} 60 IN A 10.3.11.28\" fallthrough } prometheus :9153 proxy . /etc/resolv.conf cache 30 reload }","title":"CoreDNS"},{"location":"kubernetes/ingress-controller/#usage","text":"If the setup was done correctly, the following ingress example will create an internal route with Host(/^demo[.]default[.]skipper[.]cluster[.]local) predicate: apiVersion : extensions / v1beta1 kind : Ingress metadata : name : demo namespace : default spec : rules : - host : demo . example . org http : paths : - backend : serviceName : example servicePort : 80 Your clients inside the cluster should call this example with demo.default.skipper.cluster.local in their host header. Example from inside a container: curl demo.default.skipper.cluster.local","title":"Usage"},{"location":"kubernetes/ingress-controller/#running-with-cluster-ratelimits","text":"Cluster ratelimits require a communication exchange method to build a skipper swarm to have a shared knowledge about the requests passing all skipper instances. To enable this feature you need to add command line option -enable-swarm and -enable-ratelimits . The rest depends on the implementation, that can be: Redis SWIM","title":"Running with Cluster Ratelimits"},{"location":"kubernetes/ingress-controller/#redis-based","text":"Additionally you have to add -swarm-redis-urls to skipper args: . For example: -swarm-redis-urls=skipper-redis-0.skipper-redis.kube-system.svc.cluster.local:6379,skipper-redis-1.skipper-redis.kube-system.svc.cluster.local:6379 . Running skipper with hostNetwork in kubernetes will not be able to resolve redis hostnames as shown in the example, if skipper does not have dnsPolicy: ClusterFirstWithHostNet in it\u2019s Pod spec, see also DNS policy in the official Kubernetes documentation . This setup is considered experimental and should be carefully tested before running it in production. Example redis statefulset with headless service: apiVersion : apps/v1 kind : StatefulSet metadata : labels : application : skipper-redis version : v4.0.9 name : skipper-redis namespace : kube-system spec : replicas : 2 selector : matchLabels : application : skipper-redis serviceName : skipper-redis template : metadata : labels : application : skipper-redis version : v4.0.9 spec : containers : - image : registry.opensource.zalan.do/zmon/redis:4.0.9-master-6 name : skipper-redis ports : - containerPort : 6379 protocol : TCP readinessProbe : exec : command : - redis-cli - ping failureThreshold : 3 initialDelaySeconds : 10 periodSeconds : 60 successThreshold : 1 timeoutSeconds : 1 resources : limits : cpu : 100m memory : 100Mi dnsPolicy : ClusterFirst restartPolicy : Always schedulerName : default-scheduler --- apiVersion : v1 kind : Service metadata : labels : application : skipper-redis name : skipper-redis namespace : kube-system spec : clusterIP : None ports : - port : 6379 protocol : TCP targetPort : 6379 selector : application : skipper-redis type : ClusterIP","title":"Redis based"},{"location":"kubernetes/ingress-controller/#swim-based","text":"SWIM is a \u201cScalable Weakly-consistent Infection-style Process Group Membership Protocol\u201d, which is very interesting for example to use for cluster ratelimits. This setup is not considered stable enough to run production, yet. Additionally you have to add the following command line flags to skipper\u2019s container spec args: : -swarm-port=9990 -swarm-label-selector-key=application -swarm-label-selector-value=skipper-ingress -swarm-leave-timeout=5s -swarm-max-msg-buffer=4194304 -swarm-namespace=kube-system and open another port in Kubernetes and your Firewall settings to make the communication work with TCP and UDP to the specified swarm-port : - containerPort : 9990 hostPort : 9990 name : swarm-port protocol : TCP","title":"SWIM based"},{"location":"kubernetes/ingress-usage/","text":"Skipper Ingress Usage \u00b6 This documentation is meant for people deploying to Kubernetes Clusters and describes to use Ingress and low level and high level features Skipper provides Skipper Ingress Annotations \u00b6 Annotation example data usage zalando.org/backend-weights {\"my-app-1\": 80, \"my-app-2\": 20} blue-green deployments zalando.org/skipper-filter consecutiveBreaker(15) arbitrary filters zalando.org/skipper-predicate QueryParam(\"version\", \"^alpha$\") arbitrary predicates zalando.org/skipper-routes Method(\"OPTIONS\") -> status(200) -> <shunt> extra custom routes zalando.org/ratelimit ratelimit(50, \"1m\") deprecated, use zalando.org/skipper-filter instead zalando.org/skipper-ingress-redirect true change the default HTTPS redirect behavior for specific ingresses (true/false) zalando.org/skipper-ingress-redirect-code 301 change the default HTTPS redirect code for specific ingresses Supported Service types \u00b6 Ingress backend definitions are services, which have different service types . Service type supported workaround ClusterIP yes \u2014 NodePort yes \u2014 ExternalName no, related issue use deployment with routestring LoadBalancer no it should not, because Kubernetes cloud-controller-manager will maintain it HTTP Host header routing \u00b6 HTTP host header is defined within the rules host section and this route will match by http Host: app-default.example.org and route to endpoints selected by the Kubernetes service app-svc on port 80 . apiVersion : extensions / v1beta1 kind : Ingress metadata : name : app spec : rules : - host : app - default . example . org http : paths : - backend : serviceName : app - svc servicePort : 80 To have 2 routes with different Host headers serving the same backends, you have to specify 2 entries in the rules section, as Kubernetes defined the ingress spec. This is often used in cases of migrations from one domain to another one or migrations to or from bare metal datacenters to cloud providers or inter cloud or intra cloud providers migrations. Examples are AWS account migration, AWS to GCP migration, GCP to bare metal migration or bare metal to Alibaba Cloud migration. apiVersion : extensions / v1beta1 kind : Ingress metadata : name : app spec : rules : - host : app - default . example . org http : paths : - backend : serviceName : app - svc servicePort : 80 - host : foo . example . org http : paths : - backend : serviceName : app - svc servicePort : 80 Multiple Ingresses defining the same route \u00b6 Warning If multiple ingresses define the same host and the same predicates, traffic routing may become non-deterministic. Consider the following two ingresses which have the same hostname and therefore overlap. In skipper the routing of this is currently undefined as skipper doesn\u2019t pick one over the other, but just creates routes (possible overlapping) for each of the ingresses. In this example (taken from the issues we saw in production clusters) one ingress points to a service with no endpoints and the other to a service with endpoints. (Most likely service-x was renamed to service-x-live and the old ingress was forgot). apiVersion : extensions / v1beta1 kind : Ingress metadata : name : service - x spec : rules : - host : service - x . example . org http : paths : - backend : serviceName : service - x # this service has 0 endpoints servicePort : 80 \u200b apiVersion : extensions / v1beta1 kind : Ingress metadata : name : service - x - live spec : rules : - host : service - x . example . org http : paths : - backend : serviceName : service - x - live servicePort : 80 Ingress path handling \u00b6 Ingress paths can be interpreted in four different modes: based on the kubernetes ingress specification as plain regular expression as a path prefix The default is the kubernetes ingress mode. It can be changed by a startup option to any of the other modes, and the individual ingress rules can also override the default behavior with the zalando.org/skipper-ingress-path-mode annotation. E.g.: zalando.org/skipper-ingress-path-mode: path-prefix Kubernetes ingress specification base path \u00b6 By default, the ingress path is interpreted as a regular expression with a mandatory leading \u201c/\u201d, and is automatically prepended by a \u201c^\u201d control character, enforcing that the path has to be at the start of the incoming request path. Plain regular expression \u00b6 When the path mode is set to \u201cpath-regexp\u201d, the ingress path is interpreted similar to the default kubernetes ingress specification way, but is not prepended by the \u201c^\u201d control character. Path prefix \u00b6 When the path mode is set to \u201cpath-prefix\u201d, the ingress path is not a regular expression. As an example, \u201c/foo/bar\u201d will match \u201c/foo/bar\u201d or \u201c/foo/bar/baz\u201d, but won\u2019t match \u201c/foo/barooz\u201d. When PathPrefix is used, the path matching becomes deterministic when a request could match more than one ingress routes otherwise. In PathPrefix mode, when a Path or PathSubtree predicate is set in an annotation, the predicate in the annotation takes precedence over the normal ingress path. Filters and Predicates \u00b6 Filters can manipulate http data, which is not possible in the ingress spec. Predicates change the route matching, beyond normal ingress definitions This example shows how to add predicates and filters: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : predicate1 && predicate2 && .. && predicateN zalando.org/skipper-filter : filter1 -> filter2 -> .. -> filterN name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Custom Routes \u00b6 Custom routes is a way of extending the default routes configured for an ingress resource. Sometimes you just want to return a header, redirect or even static html content. You can return from skipper without doing a proxy call to a backend, if you end your filter chain with <shunt> . The use of <shunt> recommends the use in combination with status() filter, to not respond with the default http code, which defaults to 404. To match your custom route with higher priority than your ingress you also have to add another predicate, for example the Method(\u201cGET\u201d) predicate to match the route with higher priority. Custom routes specified in ingress will always add the Host() predicate to match the host header specified in the ingress rules: . If there is a path: definition in your ingress, then it will be based on the skipper command line parameter -kubernetes-path-mode set one of theses predicates: Path() PathSubtree() PathRegexp() If you have a path: value defined in your ingress resource, a custom route is not allowed to use Path() nor PathSubtree() predicates. You will get an error in Skipper logs, similar to: [APP]time=\"2019-01-02T13:30:16Z\" level=error msg=\"Failed to add route having 2 path routes: Path(\\\"/foo/bar\\\") -> inlineContent(\\\"custom route\\\") -> status(200) -> <shunt>\" Redirects \u00b6 Overwrite the current ingress with a redirect \u00b6 Sometimes you want to overwrite the current ingress with a redirect to a nicer downtime page. The following example shows how to create a temporary redirect with status code 307 to https://outage.example.org . No requests will pass to your backend defined, because the created route from the annotation zalando.org/skipper-routes will get 3 Predicates Host(\"^app-default[.]example[.]org$\") && Path(\"/\") && PathRegexp(\"/\") , instead of the 2 Predicates Host(\"^app-default[.]example[.]org$\") && Path(\"/\") , that will be created for the ingress backend. apiVersion : extensions / v1beta1 kind : Ingress metadata : name : app namespace : default annotations : zalando . org / skipper - routes : | redirect_app_default : PathRegexp ( \"/\" ) -> redirectTo ( 307 , \"https://outage.example.org/\" ) -> < shunt >; spec : rules : - host : \"app-default.example.org\" http : paths : - path : / backend : serviceName : app - svc servicePort : 80 Redirect a specific path from ingress \u00b6 Sometimes you want to have a redirect from http://app-default.example.org/myredirect to https://somewhere.example.org/another/path . The following example shows how to create a permanent redirect with status code 308 from http://app-default.example.org/myredirect to https://somewhere.example.org/another/path , other paths will not be redirected and passed to the backend selected by serviceName=app-svc and servicePort=80 : apiVersion : extensions / v1beta1 kind : Ingress metadata : name : app namespace : default annotations : zalando . org / skipper - routes : | redirect_app_default : PathRegexp ( \"/myredirect\" ) -> redirectTo ( 308 , \"https://somewhere.example.org/another/path\" ) -> < shunt >; spec : rules : - host : \"app-default.example.org\" http : paths : - path : / backend : serviceName : app - svc servicePort : 80 Return static content \u00b6 The following example sets a response header X: bar , a response body <html><body>hello</body></html> and respond from the ingress directly with a HTTP status code 200: zalando.org/skipper-routes: | Path(\"/\") -> setResponseHeader(\"X\", \"bar\") -> inlineContent(\" <html><body> hello </body></html> \") -> status(200) -> <shunt> Keep in mind that you need a valid backend definition to backends which are available, otherwise Skipper would not accept the entire route definition from the ingress object for safety reasons. CORS example \u00b6 This example shows how to add a custom route for handling OPTIONS requests. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-routes : | Method(\"OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Origin\", \"*\") -> setResponseHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Headers\", \"Authorization\") -> status(200) -> <shunt> name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 This will generate a custom route for the ingress which looks like this: Host(/^app-default[.]example[.]org$/) && Method(\"OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Origin\", \"*\") -> setResponseHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Headers\", \"Authorization\") -> status(200) -> <shunt> Multiple routes \u00b6 You can also set multiple routes, but you have to set the names of the route as defined in eskip: zalando . org / skipper-routes : | routename1 : Path ( \"/\" ) - > localRatelimit ( 2 , \"1h\" ) - > inlineContent ( \"A\" ) - > status ( 200 ) - > < shunt >; routename2 : Path ( \"/foo\" ) - > localRatelimit ( 5 , \"1h\" ) - > inlineContent ( \"B\" ) - > status ( 200 ) - > < shunt >; Make sure the ; semicolon is used to terminate the routes, if you use multiple routes definitions. Disclaimer : This feature works only with having different Path* predicates in ingress, if there are no paths rules defined. For example this will not work: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : skipper-ingress annotations : kubernetes.io/ingress.class : skipper zalando.org/skipper-routes : | redirect1: Path(\"/foo/\") -> redirectTo(308, \"/bar/\") -> <shunt>; spec : rules : - host : foo.bar http : paths : - path : /something/ backend : serviceName : something servicePort : 80 - path : /else/ backend : serviceName : else servicePort : 80 A possible solution will be a skipper route CRD: https://github.com/zalando/skipper/issues/660 Filters - Basic HTTP manipulations \u00b6 HTTP manipulations are done by using skipper filters. Changes can be done in the request path, meaning request to your backend or in the response path to the client, which made the request. The following examples can be used within zalando.org/skipper-filter annotation. Add a request Header \u00b6 Add a HTTP header in the request path to your backend. setRequestHeader(\"X-Foo\", \"bar\") Add a response Header \u00b6 Add a HTTP header in the response path of your clients. setResponseHeader(\"X-Foo\", \"bar\") Enable gzip \u00b6 Compress responses with gzip. compress() // compress all valid MIME types compress(\"text/html\") // only compress HTML files compress(9, \"text/html\") // control the level of compression, 1 = fastest, 9 = best compression, 0 = no compression Set the Path \u00b6 Change the path in the request path to your backend to /newPath/ . setPath(\"/newPath/\") Modify Path \u00b6 Modify the path in the request path from /api/foo to your backend to /foo . modPath(\"^/api/\", \"/\") Set the Querystring \u00b6 Set the Querystring in the request path to your backend to ?text=godoc%20skipper . setQuery(\"text\", \"godoc skipper\") Redirect \u00b6 Create a redirect with HTTP code 301 to https://foo.example.org/ . redirectTo(301, \"https://foo.example.org/\") Cookies \u00b6 Set a Cookie in the request path to your backend. requestCookie(\"test-session\", \"abc\") Set a Cookie in the response path of your clients. responseCookie(\"test-session\", \"abc\", 31536000) responseCookie(\"test-session\", \"abc\", 31536000, \"change-only\") // response cookie without HttpOnly: jsCookie(\"test-session-info\", \"abc-debug\", 31536000, \"change-only\") Authorization \u00b6 Our autnetication and authorization tutorial or filter auth godoc shows how to use filters for authorization. Basic Auth \u00b6 % htpasswd -nbm myName myPassword basicAuth ( \" / path / to / htpasswd \" ) basicAuth ( \" / path / to / htpasswd \" , \" My Website \" ) Bearer Token (OAuth/JWT) \u00b6 OAuth2/JWT tokens can be validated and allowed based on different content of the token. Please check the filter documentation for that: oauthTokeninfoAnyScope oauthTokeninfoAllScope oauthTokeninfoAnyKV oauthTokeninfoAllKV There are also auth predicates , which will allow you to match a route based on the content of a token: JWTPayloadAnyKV() JWTPayloadAllKV() These are not validating the tokens, which should be done separately by the filters mentioned above. Diagnosis - Throttling Bandwidth - Latency \u00b6 For diagnosis purpose there are filters that enable you to throttle the bandwidth or add latency. For the full list of filters see our diag filter godoc page . bandwidth(30) // incoming in kb/s backendBandwidth(30) // outgoing in kb/s backendLatency(120) // in ms Filter documentation: latency bandwidth chunks backendlatency backendChunks randomcontent Flow Id to trace request flows \u00b6 To trace request flows skipper can generate a unique Flow Id for every HTTP request that it receives. You can then find the trace of the request in all your access logs. Skipper sets the X-Flow-Id header to a unique value. Read more about this in our flowid filter and godoc . flowId(\"reuse\") Filters - reliability features \u00b6 Filters can modify http requests and responses. There are plenty of things you can do with them. Circuitbreaker \u00b6 Consecutive Breaker \u00b6 The consecutiveBreaker filter is a breaker for the ingress route that open if the backend failures for the route reach a value of N (in this example N=15), where N is a mandatory argument of the filter and there are some more optional arguments documented. consecutiveBreaker(15) The ingress spec would look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : consecutiveBreaker(15) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Rate Breaker \u00b6 The rateBreaker filter is a breaker for the ingress route that open if the backend failures for the route reach a value of N within a window of the last M requests, where N (in this example 30) and M (in this example 300) are mandatory arguments of the filter and there are some more optional arguments documented. rateBreaker(30, 300) The ingress spec would look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : rateBreaker(30, 300) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Ratelimits \u00b6 There are two kind of ratelimits: Client side ratelimits are used to slow down login enumeration attacks, that targets your login pages. This is a security protection for DDoS or login attacks. Service or backend side ratelimits are used to protect your services due too much traffic. This can be used in an emergency situation to make sure you calm down ingress traffic or in general if you know how much calls per duration your backend is able to handle. Cluster ratelimits can be enforced either on client or on service side as described above. Ratelimits are enforced per route. More details you will find in ratelimit package and in our ratelimit tutorial . Client Ratelimits \u00b6 The example shows 20 calls per hour per client, based on X-Forwarded-For header or IP incase there is no X-Forwarded-For header set, are allowed to each skipper instance for the given ingress. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : localRatelimit(20, \"1h\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 If you need to rate limit service to service communication and you use Authorization headers to protect your backend from your clients, then you can pass a 3 parameter to group clients by \u201cAuthorization Header\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : localRatelimit(20, \"1h\", \"auth\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Service Ratelimits \u00b6 The example shows 50 calls per minute are allowed to each skipper instance for the given ingress. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : ratelimit(50, \"1m\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Cluster Ratelimits \u00b6 Cluster ratelimits are eventual consistent and require the flag -enable-swarm to be set. Service \u00b6 The example shows 50 calls per minute are allowed to pass this ingress rule to the backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : clusterRatelimit(\"groupSvcApp\", 50, \"1m\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Client \u00b6 The example shows 10 calls per hour are allowed per client, X-Forwarded-For header, to pass this ingress rule to the backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : clusterClientRatelimit(\"groupSvcApp\", 10, \"1h\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Shadow Traffic \u00b6 If you want to test a new replacement of a production service with production load, you can copy incoming requests to your new endpoint and ignore the responses from your new backend. This can be done by the tee() and teenf() filters. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : teenf(\"https://app-new.example.org\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Predicates \u00b6 Predicates are influencing the route matching, which you might want to carefully test before using it in production. This enables you to do feature toggles or time based enabling endpoints. You can use all kinds of predicates with filters together. Feature Toggle \u00b6 Feature toggles are often implemented as query string to select a new feature. Normally you would have to implement this in your application, but Skipper can help you with that and you can select routes with an ingress definition. You create 2 ingresses that matches the same route, here host header match to app-default.example.org and one ingress has a defined query parameter to select the route to the alpha version deployment. If the query string in the URL has version=alpha set, for example https://app-default.example.org/mypath?version=alpha , the service alpha-svc will get the traffic, if not prod-svc . alpha-svc: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : QueryParam(\"version\", \"^alpha$\") name : alpha-app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : alpha-svc servicePort : 80 prod-svc: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : prod-app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : prod-svc servicePort : 80 IP Whitelisting \u00b6 This ingress route will only allow traffic from networks 1.2.3.0/24 and 195.168.0.0/17 apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Source(\"1.2.3.0/24\", \"195.168.0.0/17\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 A/B test \u00b6 Implementing A/B testing is heavy. Skipper can help you to do that. You need to have a traffic split somewhere and have your customers sticky to either A or B flavor of your application. Most likely people would implement using cookies. Skipper can set a cookie with responseCookie() in a response to the client and the cookie predicate can be used to match the route based on the cookie. Like this you can have sticky sessions to either A or B for your clients. This example shows to have 10% traffic using A and the rest using B. 10% choice of setting the Cookie \u201cflavor\u201d to \u201cA\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Traffic(.1, \"flavor\", \"A\") zalando.org/skipper-filter : responseCookie(\"flavor\", \"A\", 31536000) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : a-app-svc servicePort : 80 Rest is setting Cookie \u201cflavor\u201d to \u201cB\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : responseCookie(\"flavor, \"B\", 31536000) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : b-app-svc servicePort : 80 To be sticky, you have to create 2 ingress with predicate to match routes with the cookie we set before. For \u201cA\u201d this would be: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^A$/) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : a-app-svc servicePort : 80 For \u201cB\u201d this would be: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^B$/) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : b-app-svc servicePort : 80 Blue-Green deployments \u00b6 To do blue-green deployments you have to have control over traffic switching. Skipper gives you the opportunity to set weights to backend services in your ingress specification. zalando.org/backend-weights is a hash map, which key relates to the serviceName of the backend and the value is the weight of traffic you want to send to the particular backend. It works for more than 2 backends, but for simplicity this example shows 2 backends, which should be the default case for supporting blue-green deployments. In the following example my-app-1 service will get 80% of the traffic and my-app-2 will get 20% of the traffic: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-app labels : application : my-app annotations : zalando.org/backend-weights : | {\"my-app-1\": 80, \"my-app-2\": 20} spec : rules : - host : my-app.example.org http : paths : - backend : serviceName : my-app-1 servicePort : http path : / - backend : serviceName : my-app-2 servicePort : http path : / For more advanced blue-green deployments, check out our stackset-controller . Chaining Filters and Predicates \u00b6 You can set multiple filters in a chain similar to the eskip format . apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^B$/) && Source(\"1.2.3.0/24\", \"195.168.0.0/17\") zalando.org/skipper-filter : localRatelimit(50, \"10m\") -> requestCookie(\"test-session\", \"abc\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Controlling HTTPS redirect \u00b6 Skipper Ingress can provide HTTP->HTTPS redirection. Enabling it and setting the status code used by default can be done with the command line options: -kubernetes-https-redirect and -kubernetes-https-redirect-code. By using annotations, this behavior can be overridden from the individual ingress specs for the scope of routes generated based on these ingresses specs. Annotations: zalando.org/skipper-ingress-redirect: the possible values are true or false. When the global HTTPS redirect is disabled, the value true enables it for the current ingress. When the global redirect is enabled, the value false disables it for the current ingress. zalando.org/skipper-ingress-redirect-code: the possible values are integers 300 <= x < 400. Sets the redirect status code for the current ingress. Example: apiVersion : extensions / v1beta1 kind : Ingress metadata : annotations : zalando . org / skipper - ingress - redirect : true zalando . org / skipper - ingress - redirect - code : 301 name : app spec : rules : - host : mobile - api . example . org http : paths : - backend : serviceName : app - svc servicePort : 80","title":"Ingress Usage"},{"location":"kubernetes/ingress-usage/#skipper-ingress-usage","text":"This documentation is meant for people deploying to Kubernetes Clusters and describes to use Ingress and low level and high level features Skipper provides","title":"Skipper Ingress Usage"},{"location":"kubernetes/ingress-usage/#skipper-ingress-annotations","text":"Annotation example data usage zalando.org/backend-weights {\"my-app-1\": 80, \"my-app-2\": 20} blue-green deployments zalando.org/skipper-filter consecutiveBreaker(15) arbitrary filters zalando.org/skipper-predicate QueryParam(\"version\", \"^alpha$\") arbitrary predicates zalando.org/skipper-routes Method(\"OPTIONS\") -> status(200) -> <shunt> extra custom routes zalando.org/ratelimit ratelimit(50, \"1m\") deprecated, use zalando.org/skipper-filter instead zalando.org/skipper-ingress-redirect true change the default HTTPS redirect behavior for specific ingresses (true/false) zalando.org/skipper-ingress-redirect-code 301 change the default HTTPS redirect code for specific ingresses","title":"Skipper Ingress Annotations"},{"location":"kubernetes/ingress-usage/#supported-service-types","text":"Ingress backend definitions are services, which have different service types . Service type supported workaround ClusterIP yes \u2014 NodePort yes \u2014 ExternalName no, related issue use deployment with routestring LoadBalancer no it should not, because Kubernetes cloud-controller-manager will maintain it","title":"Supported Service types"},{"location":"kubernetes/ingress-usage/#http-host-header-routing","text":"HTTP host header is defined within the rules host section and this route will match by http Host: app-default.example.org and route to endpoints selected by the Kubernetes service app-svc on port 80 . apiVersion : extensions / v1beta1 kind : Ingress metadata : name : app spec : rules : - host : app - default . example . org http : paths : - backend : serviceName : app - svc servicePort : 80 To have 2 routes with different Host headers serving the same backends, you have to specify 2 entries in the rules section, as Kubernetes defined the ingress spec. This is often used in cases of migrations from one domain to another one or migrations to or from bare metal datacenters to cloud providers or inter cloud or intra cloud providers migrations. Examples are AWS account migration, AWS to GCP migration, GCP to bare metal migration or bare metal to Alibaba Cloud migration. apiVersion : extensions / v1beta1 kind : Ingress metadata : name : app spec : rules : - host : app - default . example . org http : paths : - backend : serviceName : app - svc servicePort : 80 - host : foo . example . org http : paths : - backend : serviceName : app - svc servicePort : 80","title":"HTTP Host header routing"},{"location":"kubernetes/ingress-usage/#multiple-ingresses-defining-the-same-route","text":"Warning If multiple ingresses define the same host and the same predicates, traffic routing may become non-deterministic. Consider the following two ingresses which have the same hostname and therefore overlap. In skipper the routing of this is currently undefined as skipper doesn\u2019t pick one over the other, but just creates routes (possible overlapping) for each of the ingresses. In this example (taken from the issues we saw in production clusters) one ingress points to a service with no endpoints and the other to a service with endpoints. (Most likely service-x was renamed to service-x-live and the old ingress was forgot). apiVersion : extensions / v1beta1 kind : Ingress metadata : name : service - x spec : rules : - host : service - x . example . org http : paths : - backend : serviceName : service - x # this service has 0 endpoints servicePort : 80 \u200b apiVersion : extensions / v1beta1 kind : Ingress metadata : name : service - x - live spec : rules : - host : service - x . example . org http : paths : - backend : serviceName : service - x - live servicePort : 80","title":"Multiple Ingresses defining the same route"},{"location":"kubernetes/ingress-usage/#ingress-path-handling","text":"Ingress paths can be interpreted in four different modes: based on the kubernetes ingress specification as plain regular expression as a path prefix The default is the kubernetes ingress mode. It can be changed by a startup option to any of the other modes, and the individual ingress rules can also override the default behavior with the zalando.org/skipper-ingress-path-mode annotation. E.g.: zalando.org/skipper-ingress-path-mode: path-prefix","title":"Ingress path handling"},{"location":"kubernetes/ingress-usage/#kubernetes-ingress-specification-base-path","text":"By default, the ingress path is interpreted as a regular expression with a mandatory leading \u201c/\u201d, and is automatically prepended by a \u201c^\u201d control character, enforcing that the path has to be at the start of the incoming request path.","title":"Kubernetes ingress specification base path"},{"location":"kubernetes/ingress-usage/#plain-regular-expression","text":"When the path mode is set to \u201cpath-regexp\u201d, the ingress path is interpreted similar to the default kubernetes ingress specification way, but is not prepended by the \u201c^\u201d control character.","title":"Plain regular expression"},{"location":"kubernetes/ingress-usage/#path-prefix","text":"When the path mode is set to \u201cpath-prefix\u201d, the ingress path is not a regular expression. As an example, \u201c/foo/bar\u201d will match \u201c/foo/bar\u201d or \u201c/foo/bar/baz\u201d, but won\u2019t match \u201c/foo/barooz\u201d. When PathPrefix is used, the path matching becomes deterministic when a request could match more than one ingress routes otherwise. In PathPrefix mode, when a Path or PathSubtree predicate is set in an annotation, the predicate in the annotation takes precedence over the normal ingress path.","title":"Path prefix"},{"location":"kubernetes/ingress-usage/#filters-and-predicates","text":"Filters can manipulate http data, which is not possible in the ingress spec. Predicates change the route matching, beyond normal ingress definitions This example shows how to add predicates and filters: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : predicate1 && predicate2 && .. && predicateN zalando.org/skipper-filter : filter1 -> filter2 -> .. -> filterN name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Filters and Predicates"},{"location":"kubernetes/ingress-usage/#custom-routes","text":"Custom routes is a way of extending the default routes configured for an ingress resource. Sometimes you just want to return a header, redirect or even static html content. You can return from skipper without doing a proxy call to a backend, if you end your filter chain with <shunt> . The use of <shunt> recommends the use in combination with status() filter, to not respond with the default http code, which defaults to 404. To match your custom route with higher priority than your ingress you also have to add another predicate, for example the Method(\u201cGET\u201d) predicate to match the route with higher priority. Custom routes specified in ingress will always add the Host() predicate to match the host header specified in the ingress rules: . If there is a path: definition in your ingress, then it will be based on the skipper command line parameter -kubernetes-path-mode set one of theses predicates: Path() PathSubtree() PathRegexp() If you have a path: value defined in your ingress resource, a custom route is not allowed to use Path() nor PathSubtree() predicates. You will get an error in Skipper logs, similar to: [APP]time=\"2019-01-02T13:30:16Z\" level=error msg=\"Failed to add route having 2 path routes: Path(\\\"/foo/bar\\\") -> inlineContent(\\\"custom route\\\") -> status(200) -> <shunt>\"","title":"Custom Routes"},{"location":"kubernetes/ingress-usage/#redirects","text":"","title":"Redirects"},{"location":"kubernetes/ingress-usage/#overwrite-the-current-ingress-with-a-redirect","text":"Sometimes you want to overwrite the current ingress with a redirect to a nicer downtime page. The following example shows how to create a temporary redirect with status code 307 to https://outage.example.org . No requests will pass to your backend defined, because the created route from the annotation zalando.org/skipper-routes will get 3 Predicates Host(\"^app-default[.]example[.]org$\") && Path(\"/\") && PathRegexp(\"/\") , instead of the 2 Predicates Host(\"^app-default[.]example[.]org$\") && Path(\"/\") , that will be created for the ingress backend. apiVersion : extensions / v1beta1 kind : Ingress metadata : name : app namespace : default annotations : zalando . org / skipper - routes : | redirect_app_default : PathRegexp ( \"/\" ) -> redirectTo ( 307 , \"https://outage.example.org/\" ) -> < shunt >; spec : rules : - host : \"app-default.example.org\" http : paths : - path : / backend : serviceName : app - svc servicePort : 80","title":"Overwrite the current ingress with a redirect"},{"location":"kubernetes/ingress-usage/#redirect-a-specific-path-from-ingress","text":"Sometimes you want to have a redirect from http://app-default.example.org/myredirect to https://somewhere.example.org/another/path . The following example shows how to create a permanent redirect with status code 308 from http://app-default.example.org/myredirect to https://somewhere.example.org/another/path , other paths will not be redirected and passed to the backend selected by serviceName=app-svc and servicePort=80 : apiVersion : extensions / v1beta1 kind : Ingress metadata : name : app namespace : default annotations : zalando . org / skipper - routes : | redirect_app_default : PathRegexp ( \"/myredirect\" ) -> redirectTo ( 308 , \"https://somewhere.example.org/another/path\" ) -> < shunt >; spec : rules : - host : \"app-default.example.org\" http : paths : - path : / backend : serviceName : app - svc servicePort : 80","title":"Redirect a specific path from ingress"},{"location":"kubernetes/ingress-usage/#return-static-content","text":"The following example sets a response header X: bar , a response body <html><body>hello</body></html> and respond from the ingress directly with a HTTP status code 200: zalando.org/skipper-routes: | Path(\"/\") -> setResponseHeader(\"X\", \"bar\") -> inlineContent(\" <html><body> hello </body></html> \") -> status(200) -> <shunt> Keep in mind that you need a valid backend definition to backends which are available, otherwise Skipper would not accept the entire route definition from the ingress object for safety reasons.","title":"Return static content"},{"location":"kubernetes/ingress-usage/#cors-example","text":"This example shows how to add a custom route for handling OPTIONS requests. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-routes : | Method(\"OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Origin\", \"*\") -> setResponseHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Headers\", \"Authorization\") -> status(200) -> <shunt> name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 This will generate a custom route for the ingress which looks like this: Host(/^app-default[.]example[.]org$/) && Method(\"OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Origin\", \"*\") -> setResponseHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Headers\", \"Authorization\") -> status(200) -> <shunt>","title":"CORS example"},{"location":"kubernetes/ingress-usage/#multiple-routes","text":"You can also set multiple routes, but you have to set the names of the route as defined in eskip: zalando . org / skipper-routes : | routename1 : Path ( \"/\" ) - > localRatelimit ( 2 , \"1h\" ) - > inlineContent ( \"A\" ) - > status ( 200 ) - > < shunt >; routename2 : Path ( \"/foo\" ) - > localRatelimit ( 5 , \"1h\" ) - > inlineContent ( \"B\" ) - > status ( 200 ) - > < shunt >; Make sure the ; semicolon is used to terminate the routes, if you use multiple routes definitions. Disclaimer : This feature works only with having different Path* predicates in ingress, if there are no paths rules defined. For example this will not work: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : skipper-ingress annotations : kubernetes.io/ingress.class : skipper zalando.org/skipper-routes : | redirect1: Path(\"/foo/\") -> redirectTo(308, \"/bar/\") -> <shunt>; spec : rules : - host : foo.bar http : paths : - path : /something/ backend : serviceName : something servicePort : 80 - path : /else/ backend : serviceName : else servicePort : 80 A possible solution will be a skipper route CRD: https://github.com/zalando/skipper/issues/660","title":"Multiple routes"},{"location":"kubernetes/ingress-usage/#filters-basic-http-manipulations","text":"HTTP manipulations are done by using skipper filters. Changes can be done in the request path, meaning request to your backend or in the response path to the client, which made the request. The following examples can be used within zalando.org/skipper-filter annotation.","title":"Filters - Basic HTTP manipulations"},{"location":"kubernetes/ingress-usage/#add-a-request-header","text":"Add a HTTP header in the request path to your backend. setRequestHeader(\"X-Foo\", \"bar\")","title":"Add a request Header"},{"location":"kubernetes/ingress-usage/#add-a-response-header","text":"Add a HTTP header in the response path of your clients. setResponseHeader(\"X-Foo\", \"bar\")","title":"Add a response Header"},{"location":"kubernetes/ingress-usage/#enable-gzip","text":"Compress responses with gzip. compress() // compress all valid MIME types compress(\"text/html\") // only compress HTML files compress(9, \"text/html\") // control the level of compression, 1 = fastest, 9 = best compression, 0 = no compression","title":"Enable gzip"},{"location":"kubernetes/ingress-usage/#set-the-path","text":"Change the path in the request path to your backend to /newPath/ . setPath(\"/newPath/\")","title":"Set the Path"},{"location":"kubernetes/ingress-usage/#modify-path","text":"Modify the path in the request path from /api/foo to your backend to /foo . modPath(\"^/api/\", \"/\")","title":"Modify Path"},{"location":"kubernetes/ingress-usage/#set-the-querystring","text":"Set the Querystring in the request path to your backend to ?text=godoc%20skipper . setQuery(\"text\", \"godoc skipper\")","title":"Set the Querystring"},{"location":"kubernetes/ingress-usage/#redirect","text":"Create a redirect with HTTP code 301 to https://foo.example.org/ . redirectTo(301, \"https://foo.example.org/\")","title":"Redirect"},{"location":"kubernetes/ingress-usage/#cookies","text":"Set a Cookie in the request path to your backend. requestCookie(\"test-session\", \"abc\") Set a Cookie in the response path of your clients. responseCookie(\"test-session\", \"abc\", 31536000) responseCookie(\"test-session\", \"abc\", 31536000, \"change-only\") // response cookie without HttpOnly: jsCookie(\"test-session-info\", \"abc-debug\", 31536000, \"change-only\")","title":"Cookies"},{"location":"kubernetes/ingress-usage/#authorization","text":"Our autnetication and authorization tutorial or filter auth godoc shows how to use filters for authorization.","title":"Authorization"},{"location":"kubernetes/ingress-usage/#basic-auth","text":"% htpasswd -nbm myName myPassword basicAuth ( \" / path / to / htpasswd \" ) basicAuth ( \" / path / to / htpasswd \" , \" My Website \" )","title":"Basic Auth"},{"location":"kubernetes/ingress-usage/#bearer-token-oauthjwt","text":"OAuth2/JWT tokens can be validated and allowed based on different content of the token. Please check the filter documentation for that: oauthTokeninfoAnyScope oauthTokeninfoAllScope oauthTokeninfoAnyKV oauthTokeninfoAllKV There are also auth predicates , which will allow you to match a route based on the content of a token: JWTPayloadAnyKV() JWTPayloadAllKV() These are not validating the tokens, which should be done separately by the filters mentioned above.","title":"Bearer Token (OAuth/JWT)"},{"location":"kubernetes/ingress-usage/#diagnosis-throttling-bandwidth-latency","text":"For diagnosis purpose there are filters that enable you to throttle the bandwidth or add latency. For the full list of filters see our diag filter godoc page . bandwidth(30) // incoming in kb/s backendBandwidth(30) // outgoing in kb/s backendLatency(120) // in ms Filter documentation: latency bandwidth chunks backendlatency backendChunks randomcontent","title":"Diagnosis - Throttling Bandwidth - Latency"},{"location":"kubernetes/ingress-usage/#flow-id-to-trace-request-flows","text":"To trace request flows skipper can generate a unique Flow Id for every HTTP request that it receives. You can then find the trace of the request in all your access logs. Skipper sets the X-Flow-Id header to a unique value. Read more about this in our flowid filter and godoc . flowId(\"reuse\")","title":"Flow Id to trace request flows"},{"location":"kubernetes/ingress-usage/#filters-reliability-features","text":"Filters can modify http requests and responses. There are plenty of things you can do with them.","title":"Filters - reliability features"},{"location":"kubernetes/ingress-usage/#circuitbreaker","text":"","title":"Circuitbreaker"},{"location":"kubernetes/ingress-usage/#consecutive-breaker","text":"The consecutiveBreaker filter is a breaker for the ingress route that open if the backend failures for the route reach a value of N (in this example N=15), where N is a mandatory argument of the filter and there are some more optional arguments documented. consecutiveBreaker(15) The ingress spec would look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : consecutiveBreaker(15) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Consecutive Breaker"},{"location":"kubernetes/ingress-usage/#rate-breaker","text":"The rateBreaker filter is a breaker for the ingress route that open if the backend failures for the route reach a value of N within a window of the last M requests, where N (in this example 30) and M (in this example 300) are mandatory arguments of the filter and there are some more optional arguments documented. rateBreaker(30, 300) The ingress spec would look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : rateBreaker(30, 300) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Rate Breaker"},{"location":"kubernetes/ingress-usage/#ratelimits","text":"There are two kind of ratelimits: Client side ratelimits are used to slow down login enumeration attacks, that targets your login pages. This is a security protection for DDoS or login attacks. Service or backend side ratelimits are used to protect your services due too much traffic. This can be used in an emergency situation to make sure you calm down ingress traffic or in general if you know how much calls per duration your backend is able to handle. Cluster ratelimits can be enforced either on client or on service side as described above. Ratelimits are enforced per route. More details you will find in ratelimit package and in our ratelimit tutorial .","title":"Ratelimits"},{"location":"kubernetes/ingress-usage/#client-ratelimits","text":"The example shows 20 calls per hour per client, based on X-Forwarded-For header or IP incase there is no X-Forwarded-For header set, are allowed to each skipper instance for the given ingress. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : localRatelimit(20, \"1h\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 If you need to rate limit service to service communication and you use Authorization headers to protect your backend from your clients, then you can pass a 3 parameter to group clients by \u201cAuthorization Header\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : localRatelimit(20, \"1h\", \"auth\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Client Ratelimits"},{"location":"kubernetes/ingress-usage/#service-ratelimits","text":"The example shows 50 calls per minute are allowed to each skipper instance for the given ingress. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : ratelimit(50, \"1m\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Service Ratelimits"},{"location":"kubernetes/ingress-usage/#cluster-ratelimits","text":"Cluster ratelimits are eventual consistent and require the flag -enable-swarm to be set.","title":"Cluster Ratelimits"},{"location":"kubernetes/ingress-usage/#service","text":"The example shows 50 calls per minute are allowed to pass this ingress rule to the backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : clusterRatelimit(\"groupSvcApp\", 50, \"1m\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Service"},{"location":"kubernetes/ingress-usage/#client","text":"The example shows 10 calls per hour are allowed per client, X-Forwarded-For header, to pass this ingress rule to the backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : clusterClientRatelimit(\"groupSvcApp\", 10, \"1h\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Client"},{"location":"kubernetes/ingress-usage/#shadow-traffic","text":"If you want to test a new replacement of a production service with production load, you can copy incoming requests to your new endpoint and ignore the responses from your new backend. This can be done by the tee() and teenf() filters. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : teenf(\"https://app-new.example.org\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Shadow Traffic"},{"location":"kubernetes/ingress-usage/#predicates","text":"Predicates are influencing the route matching, which you might want to carefully test before using it in production. This enables you to do feature toggles or time based enabling endpoints. You can use all kinds of predicates with filters together.","title":"Predicates"},{"location":"kubernetes/ingress-usage/#feature-toggle","text":"Feature toggles are often implemented as query string to select a new feature. Normally you would have to implement this in your application, but Skipper can help you with that and you can select routes with an ingress definition. You create 2 ingresses that matches the same route, here host header match to app-default.example.org and one ingress has a defined query parameter to select the route to the alpha version deployment. If the query string in the URL has version=alpha set, for example https://app-default.example.org/mypath?version=alpha , the service alpha-svc will get the traffic, if not prod-svc . alpha-svc: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : QueryParam(\"version\", \"^alpha$\") name : alpha-app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : alpha-svc servicePort : 80 prod-svc: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : prod-app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : prod-svc servicePort : 80","title":"Feature Toggle"},{"location":"kubernetes/ingress-usage/#ip-whitelisting","text":"This ingress route will only allow traffic from networks 1.2.3.0/24 and 195.168.0.0/17 apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Source(\"1.2.3.0/24\", \"195.168.0.0/17\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"IP Whitelisting"},{"location":"kubernetes/ingress-usage/#ab-test","text":"Implementing A/B testing is heavy. Skipper can help you to do that. You need to have a traffic split somewhere and have your customers sticky to either A or B flavor of your application. Most likely people would implement using cookies. Skipper can set a cookie with responseCookie() in a response to the client and the cookie predicate can be used to match the route based on the cookie. Like this you can have sticky sessions to either A or B for your clients. This example shows to have 10% traffic using A and the rest using B. 10% choice of setting the Cookie \u201cflavor\u201d to \u201cA\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Traffic(.1, \"flavor\", \"A\") zalando.org/skipper-filter : responseCookie(\"flavor\", \"A\", 31536000) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : a-app-svc servicePort : 80 Rest is setting Cookie \u201cflavor\u201d to \u201cB\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : responseCookie(\"flavor, \"B\", 31536000) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : b-app-svc servicePort : 80 To be sticky, you have to create 2 ingress with predicate to match routes with the cookie we set before. For \u201cA\u201d this would be: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^A$/) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : a-app-svc servicePort : 80 For \u201cB\u201d this would be: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^B$/) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : b-app-svc servicePort : 80","title":"A/B test"},{"location":"kubernetes/ingress-usage/#blue-green-deployments","text":"To do blue-green deployments you have to have control over traffic switching. Skipper gives you the opportunity to set weights to backend services in your ingress specification. zalando.org/backend-weights is a hash map, which key relates to the serviceName of the backend and the value is the weight of traffic you want to send to the particular backend. It works for more than 2 backends, but for simplicity this example shows 2 backends, which should be the default case for supporting blue-green deployments. In the following example my-app-1 service will get 80% of the traffic and my-app-2 will get 20% of the traffic: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-app labels : application : my-app annotations : zalando.org/backend-weights : | {\"my-app-1\": 80, \"my-app-2\": 20} spec : rules : - host : my-app.example.org http : paths : - backend : serviceName : my-app-1 servicePort : http path : / - backend : serviceName : my-app-2 servicePort : http path : / For more advanced blue-green deployments, check out our stackset-controller .","title":"Blue-Green deployments"},{"location":"kubernetes/ingress-usage/#chaining-filters-and-predicates","text":"You can set multiple filters in a chain similar to the eskip format . apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^B$/) && Source(\"1.2.3.0/24\", \"195.168.0.0/17\") zalando.org/skipper-filter : localRatelimit(50, \"10m\") -> requestCookie(\"test-session\", \"abc\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Chaining Filters and Predicates"},{"location":"kubernetes/ingress-usage/#controlling-https-redirect","text":"Skipper Ingress can provide HTTP->HTTPS redirection. Enabling it and setting the status code used by default can be done with the command line options: -kubernetes-https-redirect and -kubernetes-https-redirect-code. By using annotations, this behavior can be overridden from the individual ingress specs for the scope of routes generated based on these ingresses specs. Annotations: zalando.org/skipper-ingress-redirect: the possible values are true or false. When the global HTTPS redirect is disabled, the value true enables it for the current ingress. When the global redirect is enabled, the value false disables it for the current ingress. zalando.org/skipper-ingress-redirect-code: the possible values are integers 300 <= x < 400. Sets the redirect status code for the current ingress. Example: apiVersion : extensions / v1beta1 kind : Ingress metadata : annotations : zalando . org / skipper - ingress - redirect : true zalando . org / skipper - ingress - redirect - code : 301 name : app spec : rules : - host : mobile - api . example . org http : paths : - backend : serviceName : app - svc servicePort : 80","title":"Controlling HTTPS redirect"},{"location":"operation/deployment/","text":"Deployments and Data-Clients \u00b6 Edge HTTP Routing \u00b6 Edge HTTP routing is the first hit to your production HTTP loadbalancer. Skipper can serve this well and reliably in production since 2016. On the edge you want to dispatch incoming HTTP requests to your backends, which could be a microservice architecture. In this deployment mode you might have 100k HTTP routes, which are used in production and modified by many parties. To support this scenario we have the etcd dataclient . Etcd is a distributed database. TODO: why we use ETCD for this purpose Kubernetes Ingress \u00b6 Kubernetes Ingress is the component responsible to route traffic into your Kubernetes cluster. As deployer you can define an ingress object and an ingress controller will make sure incoming traffic gets routed to her backend service as defined. Skipper supports this scenario with the Kubernetes dataclient and is used in production since end of 2016. Skipper as ingress controller does not need to have any file configuration or anything external which configures Skipper. Skipper automatically finds Ingress objects and configures routes automatically, without reloading. The only requirement is to target all traffic you want to serve with Kubernetes to a loadbalancer pool of Skippers. This is a clear advantage over other ingress controllers like nginx, haproxy or envoy. Read more about Skipper\u2019s Kubernetes dataclient . Demos / Talks \u00b6 In demos you may want to show arbitrary hello world applications. You can easily describe html or json output on the command line with the route-string dataclient . Simple Routes File \u00b6 The most static deployment that is known from apache, nginx or haproxy is write your routes into a file and start your http server. This is what the Eskip file dataclient is about.","title":"Deployment"},{"location":"operation/deployment/#deployments-and-data-clients","text":"","title":"Deployments and Data-Clients"},{"location":"operation/deployment/#edge-http-routing","text":"Edge HTTP routing is the first hit to your production HTTP loadbalancer. Skipper can serve this well and reliably in production since 2016. On the edge you want to dispatch incoming HTTP requests to your backends, which could be a microservice architecture. In this deployment mode you might have 100k HTTP routes, which are used in production and modified by many parties. To support this scenario we have the etcd dataclient . Etcd is a distributed database. TODO: why we use ETCD for this purpose","title":"Edge HTTP Routing"},{"location":"operation/deployment/#kubernetes-ingress","text":"Kubernetes Ingress is the component responsible to route traffic into your Kubernetes cluster. As deployer you can define an ingress object and an ingress controller will make sure incoming traffic gets routed to her backend service as defined. Skipper supports this scenario with the Kubernetes dataclient and is used in production since end of 2016. Skipper as ingress controller does not need to have any file configuration or anything external which configures Skipper. Skipper automatically finds Ingress objects and configures routes automatically, without reloading. The only requirement is to target all traffic you want to serve with Kubernetes to a loadbalancer pool of Skippers. This is a clear advantage over other ingress controllers like nginx, haproxy or envoy. Read more about Skipper\u2019s Kubernetes dataclient .","title":"Kubernetes Ingress"},{"location":"operation/deployment/#demos-talks","text":"In demos you may want to show arbitrary hello world applications. You can easily describe html or json output on the command line with the route-string dataclient .","title":"Demos / Talks"},{"location":"operation/deployment/#simple-routes-file","text":"The most static deployment that is known from apache, nginx or haproxy is write your routes into a file and start your http server. This is what the Eskip file dataclient is about.","title":"Simple Routes File"},{"location":"operation/operation/","text":"Operations \u00b6 This is the work in progress operations guide for showing information, which are relevant for production use. Skipper is proven to scale with number of routes beyond 300.000 routes per instance. Skipper is running with peaks to 65.000 http requests per second using multiple instances. Connection Options \u00b6 Skipper\u2019s connection options are allowing you to set Go\u2019s http.Server Options on the client side and http.Transport on the backend side. \u201cIt is recommended to read this blog post about net http timeouts in order to better understand the impact of these settings. Backend \u00b6 Backend is the side skipper opens a client connection to. Closing idle connections is required for DNS failover, because Go\u2019s http.Transport caches DNS lookups and needs to create new connections for doing so. Skipper will start a goroutine and use the specified time.Duration to call CloseIdleConnections() on that http.Transport . -close-idle-conns-period string period of closing all idle connections in seconds or as a duration string. Not closing when less than 0 (default \"20\") This will set MaxIdleConnsPerHost on the http.Transport to limit the number of idle connections per backend such that we do not run out of sockets. -idle-conns-num int maximum idle connections per backend host (default 64) This will set MaxIdleConns on the http.Transport to limit the number for all backends such that we do not run out of sockets. -max-idle-connection-backend int sets the maximum idle connections for all backend connections This will set TLSHandshakeTimeout on the http.Transport to have timeouts based on TLS connections. -tls-timeout-backend duration sets the TLS handshake timeout for backend connections (default 1m0s) This will set Timeout on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -timeout-backend duration sets the TCP client connection timeout for backend connections (default 1m0s) This will set KeepAlive on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -keepalive-backend duration sets the keepalive for backend connections (default 30s) This will set DualStack (IPv4 and IPv6) on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -enable-dualstack-backend enables DualStack for backend connections (default true) Client \u00b6 Client is the side skipper gets incoming calls from. Here we can set timeouts in different parts of the http connection. This will set ReadTimeout in http.Server handling incoming calls from your clients. -read-timeout-server duration set ReadTimeout for http server connections (default 5m0s) This will set ReadHeaderTimeout in http.Server handling incoming calls from your clients. -read-header-timeout-server duration set ReadHeaderTimeout for http server connections (default 1m0s) This will set WriteTimeout in http.Server handling incoming calls from your clients. -write-timeout-server duration set WriteTimeout for http server connections (default 1m0s) This will set IdleTimeout in http.Server handling incoming calls from your clients. -idle-timeout-server duration maximum idle connections per backend host (default 1m0s) This will set MaxHeaderBytes in http.Server to limit the size of the http header from your clients. -max-header-bytes int set MaxHeaderBytes for http server connections (default 1048576) OAuth2 Tokeninfo \u00b6 OAuth2 filters integrate with external services and have their own connection handling. Outgoing calls to these services have a default timeout of 2s, which can be changed by the flag -oauth2-tokeninfo-timeout=<OAuthTokeninfoTimeout> . OAuth2 Tokenintrospection RFC7662 \u00b6 OAuth2 filters integrate with external services and have their own connection handling. Outgoing calls to these services have a default timeout of 2s, which can be changed by the flag -oauth2-tokenintrospect-timeout=<OAuthTokenintrospectionTimeout> . Monitoring \u00b6 Monitoring is one of the most important things you need to run in production and skipper has a godoc page for the metrics package , describing options and most keys you will find in the metrics handler endpoint. The default is listening on :9911/metrics . You can modify the listen port with the -support-listener flag. Metrics can exposed using formats Codahale (json) or Prometheus and be configured by -metrics-flavour= , which defaults to codahale . To expose both formats you can use a comma separated list: -metrics-flavour=codahale,prometheus . Prometheus \u00b6 In case you want to get metrics in Prometheus format exposed, use this option to enable it: -metrics-flavour=prometheus It will return Prometheus metrics on the common metrics endpoint :9911/metrics. To monitor skipper we recommend the following queries: P99 backend latency: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{}[1m])) by (le)) HTTP 2xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"2.*\"}[1m])) by (le) ) HTTP 4xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"4.*\"}[1m])) by (le) ) HTTP 5xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"52.*\"}[1m])) by (le) ) Max goroutines (depends on label selector): max(go_goroutines{application=\"skipper-ingress\"}) Max threads (depends on label selector): max(go_threads{application=\"skipper-ingress\"}) max heap memory in use in MB (depends on label selector): max(go_memstats_heap_inuse_bytes{application=\"skipper-ingress\"}) / 1024 / 1000 Max number of heap objects (depends on label selector): max(go_memstats_heap_objects{application=\"skipper-ingress\"}) Max of P75 Go GC runtime in ms (depends on label selector): max(go_gc_duration_seconds{application=\"skipper-ingress\",quantile=\"0.75\"}) * 1000 * 1000 P99 request filter duration (depends on label selector): histogram_quantile(0.99, sum(rate(skipper_filter_request_duration_seconds_bucket{application=\"skipper-ingress\"}[1m])) by (le) ) P99 response filter duration (depends on label selector): histogram_quantile(0.99, sum(rate(skipper_filter_response_duration_seconds_bucket{application=\"skipper-ingress\"}[1m])) by (le) ) If you use Kubernetes limits or Linux cgroup CFS quotas (depends on label selector): sum(rate(container_cpu_cfs_throttled_periods_total{container_name=\"skipper-ingress\"}[1m])) Connection metrics \u00b6 This option will enable known loadbalancer connections metrics, like counters for active and new connections. This feature sets a metrics callback on http.Server and uses a counter to collect http.ConnState . -enable-connection-metrics enables connection metrics for http server connections It will expose them in /metrics, for example json structure looks like this example: { \"counters\": { \"skipper.lb-conn-active\": { \"count\": 6 }, \"skipper.lb-conn-closed\": { \"count\": 6 }, \"skipper.lb-conn-idle\": { \"count\": 6 }, \"skipper.lb-conn-new\": { \"count\": 6 } }, /* stripped a lot of metrics here */ } Application metrics \u00b6 Application metrics for your proxied applications you can enable with the option: -serve-host-metrics enables reporting total serve time metrics for each host This will make sure you will get stats for each \u201cHost\u201d header as \u201ctimers\u201d: \"timers\": { \"skipper.servehost.app1_example_com.GET.200\": { \"15m.rate\": 0.06830666203045982, \"1m.rate\": 2.162612637718806e-06, \"5m.rate\": 0.008312609284452856, \"75%\": 236603815, \"95%\": 236603815, \"99%\": 236603815, \"99.9%\": 236603815, \"count\": 3, \"max\": 236603815, \"mean\": 116515451.66666667, \"mean.rate\": 0.0030589345776699827, \"median\": 91273391, \"min\": 21669149, \"stddev\": 89543653.71950394 }, \"skipper.servehost.app1_example_com.GET.304\": { \"15m.rate\": 0.3503336738177459, \"1m.rate\": 0.07923086447313292, \"5m.rate\": 0.27019839341602214, \"75%\": 99351895.25, \"95%\": 105381847, \"99%\": 105381847, \"99.9%\": 105381847, \"count\": 4, \"max\": 105381847, \"mean\": 47621612, \"mean.rate\": 0.03087161486272533, \"median\": 41676170.5, \"min\": 1752260, \"stddev\": 46489302.203724876 }, \"skipper.servehost.app1_example_com.GET.401\": { \"15m.rate\": 0.16838468990057648, \"1m.rate\": 0.01572861413072501, \"5m.rate\": 0.1194724817779537, \"75%\": 91094832, \"95%\": 91094832, \"99%\": 91094832, \"99.9%\": 91094832, \"count\": 2, \"max\": 91094832, \"mean\": 58090623, \"mean.rate\": 0.012304914018033056, \"median\": 58090623, \"min\": 25086414, \"stddev\": 33004209 } }, To change the sampling type of how metrics are handled from uniform to exponential decay , you can use the following option, which is better for not so huge utilized applications (less than 100 requests per second): -metrics-exp-decay-sample use exponentially decaying sample in metrics Go metrics \u00b6 Metrics from the go runtime memstats are exposed from skipper to the metrics endpoint, default listener :9911, on path /metrics : \"gauges\": { \"skipper.runtime.MemStats.Alloc\": { \"value\": 3083680 }, \"skipper.runtime.MemStats.BuckHashSys\": { \"value\": 1452675 }, \"skipper.runtime.MemStats.DebugGC\": { \"value\": 0 }, \"skipper.runtime.MemStats.EnableGC\": { \"value\": 1 }, \"skipper.runtime.MemStats.Frees\": { \"value\": 121 }, \"skipper.runtime.MemStats.HeapAlloc\": { \"value\": 3083680 }, \"skipper.runtime.MemStats.HeapIdle\": { \"value\": 778240 }, \"skipper.runtime.MemStats.HeapInuse\": { \"value\": 4988928 }, \"skipper.runtime.MemStats.HeapObjects\": { \"value\": 24005 }, \"skipper.runtime.MemStats.HeapReleased\": { \"value\": 0 }, \"skipper.runtime.MemStats.HeapSys\": { \"value\": 5767168 }, \"skipper.runtime.MemStats.LastGC\": { \"value\": 1516098381155094500 }, \"skipper.runtime.MemStats.Lookups\": { \"value\": 2 }, \"skipper.runtime.MemStats.MCacheInuse\": { \"value\": 6944 }, \"skipper.runtime.MemStats.MCacheSys\": { \"value\": 16384 }, \"skipper.runtime.MemStats.MSpanInuse\": { \"value\": 77368 }, \"skipper.runtime.MemStats.MSpanSys\": { \"value\": 81920 }, \"skipper.runtime.MemStats.Mallocs\": { \"value\": 1459 }, \"skipper.runtime.MemStats.NextGC\": { \"value\": 4194304 }, \"skipper.runtime.MemStats.NumGC\": { \"value\": 0 }, \"skipper.runtime.MemStats.PauseTotalNs\": { \"value\": 683352 }, \"skipper.runtime.MemStats.StackInuse\": { \"value\": 524288 }, \"skipper.runtime.MemStats.StackSys\": { \"value\": 524288 }, \"skipper.runtime.MemStats.Sys\": { \"value\": 9246968 }, \"skipper.runtime.MemStats.TotalAlloc\": { \"value\": 35127624 }, \"skipper.runtime.NumCgoCall\": { \"value\": 0 }, \"skipper.runtime.NumGoroutine\": { \"value\": 11 }, \"skipper.runtime.NumThread\": { \"value\": 9 } }, \"histograms\": { \"skipper.runtime.MemStats.PauseNs\": { \"75%\": 82509.25, \"95%\": 132609, \"99%\": 132609, \"99.9%\": 132609, \"count\": 12, \"max\": 132609, \"mean\": 56946, \"median\": 39302.5, \"min\": 28749, \"stddev\": 31567.015005117817 } } Dataclient \u00b6 Dataclients poll some kind of data source for routes. To change the timeout for calls that polls a dataclient, which could be the Kubernetes API, use the following option: -source-poll-timeout int polling timeout of the routing data sources, in milliseconds (default 3000) Routing table information \u00b6 Skipper allows you to get some runtime insights. You can get the current routing table from skipper with in the eskip file format : curl localhost:9911/routes * -> \"http://localhost:12345/\" You also can get the number of routes X-Count and the UNIX timestamp of the last route table update X-Timestamp , using a HEAD request: curl -I localhost:9911/routes HTTP/1.1 200 OK Content-Type: text/plain X-Count: 1 X-Timestamp: 1517777628 Date: Sun, 04 Feb 2018 20:54:31 GMT The number of routes given is limited (1024 routes by default). In order to control this limits, there are two parameters: limit and offset . The limit defines the number of routes to get and offset where to start the list. Thanks to this, it\u2019s possible to get the results paginated or getting all of them at the same time. curl localhost:9911/routes?offset=200&limit=100 Memory consumption \u00b6 While Skipper is generally not memory bound, some features may require some attention and planning regarding the memory consumption. Potentially high memory consumers: Metrics Filters Slow Backends and chatty clients Make sure you monitor backend latency, request and error rates. Additionally use Go metrics for the number of goroutines and threads, GC pause times should be less than 1ms in general, route lookup time, request and response filter times and heap memory. Metrics \u00b6 Memory consumption of metrics are dependent on enabled command line flags. Make sure to monitor Go metrics. If you use -metrics-flavour=codahale,prometheus you enable both storage backends. If you use the Prometheus histogram buckets -histogram-metric-buckets . If you enable route based -route-backend-metrics -route-response-metrics -serve-route-metrics , error codes -route-response-metrics and host -serve-host-metrics based metrics it can count up. Please check the support listener endpoint (default 9911) to understand the usage: % curl localhost:9911/metrics Filters \u00b6 Ratelimit filter clusterClientRatelimit implementation using the swim based protocol, consumes roughly 15MB per filter for 100.000 individual clients and 10 maximum hits. Make sure you monitor Go metrics. Ratelimit filter clusterClientRatelimit implementation using the Redis ring based solution, adds 2 additional roundtrips to redis per hit. Make sure you monitor redis closely, because skipper will fallback to allow traffic if redis can not be reached. Slow Backends \u00b6 Skipper has to keep track of all active connections and http Requests. Slow Backends can pile up in number of connections, that will consume each a little memory per request. If you have high traffic per instance and a backend times out it can start to increase your memory consumption. Make sure you monitor backend latency, request and error rates. Default Filters \u00b6 Default filters will be applied to all routes created or updated. Global Default Filters \u00b6 Global default filters can be specified via two different command line flags -default-filters-prepend and -default-filters-append . Filters passed to these command line flags will be applied to all routes. The difference prepend and append is where in the filter chain these default filters are applied. For example a user specified the route: r: * -> setPath(\"/foo\") If you run skipper with -default-filters-prepend=enableAccessLog(4,5) -> lifo(100,100,\"10s\") , the actual route will look like this: r: * -> enableAccessLog(4,5) -> lifo(100,100,\"10s\") -> setPath(\"/foo\") . If you run skipper with -default-filters-append=enableAccessLog(4,5) -> lifo(100,100,\"10s\") , the actual route will look like this: r: * -> setPath(\"/foo\") -> enableAccessLog(4,5) -> lifo(100,100,\"10s\") . Kubernetes Default Filters \u00b6 Kubernetes dataclient supports default filters. You can enable this feature by specifying default-filters-dir . The defined directory must contain per-service filter configurations, with file name following the pattern ${service}.${namespace} . The content of the files is the actual filter configurations. These filters are then prepended to the filters already defined in Ingresses. The default filters are supposed to be used only if the filters of the same kind are not configured on the Ingress resource. Otherwise, it can and will lead to potentially contradicting filter configurations and race conditions, i.e. you should specify a specific filter either on the Ingress resource or as a default filter. Scheduler \u00b6 HTTP request schedulers change the queuing behavior of in-flight requests. A queue has two generic properties: a limit of requests and a concurrency level. The limit of request can be unlimited (unbounded queue), or limited (bounded queue). The concurrency level is either limited or unlimited. The default scheduler is an unbounded first in first out (FIFO) queue, that is provided by Go\u2019s standard library. Skipper provides 2 last in first out (LIFO) filters to change the scheduling behavior. On failure conditions, Skipper will return HTTP status code: 503 if the queue is full, which is expected on the route with a failing backend 502 if queue access times out, because the queue access was not fast enough 500 on unknown errors, please create an issue The problem \u00b6 Why should you use boundaries to limit concurrency level and limit the queue? The short answer is resiliency. If you have one route, that is timing out, the request queue of skipper will pile up and consume much more memory, than before. This can lead to out of memory kill, which will affect all other routes. In this comment you can see the memory usage increased in Go\u2019s standard library bufio package. Why LIFO queue instead of FIFO queue? In normal cases the queue should not contain many requests. Skipper is able to process many requests concurrently without letting the queue piling up. In overrun situations you might want to process at least some fraction of requests instead of timing out all requests. LIFO would not time out all requests within the queue, if the backend is capable of responding some requests fast enough. A solution \u00b6 Skipper has two filters lifo() and lifoGroup() , that can limit the number of requests for a route. A documented load test shows the behavior with an enabled lifo(100,100,\"10s\") filter for all routes, that was added by default. You can do this, if you pass the following flag to skipper: -default-filters-prepend=lifo(100,100,\"10s\") . Both LIFO filters will, use a last in first out queue to handle most requests fast. If skipper is in an overrun mode, it will serve some requests fast and some will timeout. The idea is based on Dropbox bandaid proxy, which is not opensource. Dropbox shared their idea in a public blogpost . Skipper\u2019s scheduler implementation makes sure, that one route will not interfere with other routes, if these routes are not in the same scheduler group. LifoGroup has a user chosen scheduler group and lifo() will get a per route unique scheduler group.","title":"Operation"},{"location":"operation/operation/#operations","text":"This is the work in progress operations guide for showing information, which are relevant for production use. Skipper is proven to scale with number of routes beyond 300.000 routes per instance. Skipper is running with peaks to 65.000 http requests per second using multiple instances.","title":"Operations"},{"location":"operation/operation/#connection-options","text":"Skipper\u2019s connection options are allowing you to set Go\u2019s http.Server Options on the client side and http.Transport on the backend side. \u201cIt is recommended to read this blog post about net http timeouts in order to better understand the impact of these settings.","title":"Connection Options"},{"location":"operation/operation/#backend","text":"Backend is the side skipper opens a client connection to. Closing idle connections is required for DNS failover, because Go\u2019s http.Transport caches DNS lookups and needs to create new connections for doing so. Skipper will start a goroutine and use the specified time.Duration to call CloseIdleConnections() on that http.Transport . -close-idle-conns-period string period of closing all idle connections in seconds or as a duration string. Not closing when less than 0 (default \"20\") This will set MaxIdleConnsPerHost on the http.Transport to limit the number of idle connections per backend such that we do not run out of sockets. -idle-conns-num int maximum idle connections per backend host (default 64) This will set MaxIdleConns on the http.Transport to limit the number for all backends such that we do not run out of sockets. -max-idle-connection-backend int sets the maximum idle connections for all backend connections This will set TLSHandshakeTimeout on the http.Transport to have timeouts based on TLS connections. -tls-timeout-backend duration sets the TLS handshake timeout for backend connections (default 1m0s) This will set Timeout on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -timeout-backend duration sets the TCP client connection timeout for backend connections (default 1m0s) This will set KeepAlive on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -keepalive-backend duration sets the keepalive for backend connections (default 30s) This will set DualStack (IPv4 and IPv6) on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -enable-dualstack-backend enables DualStack for backend connections (default true)","title":"Backend"},{"location":"operation/operation/#client","text":"Client is the side skipper gets incoming calls from. Here we can set timeouts in different parts of the http connection. This will set ReadTimeout in http.Server handling incoming calls from your clients. -read-timeout-server duration set ReadTimeout for http server connections (default 5m0s) This will set ReadHeaderTimeout in http.Server handling incoming calls from your clients. -read-header-timeout-server duration set ReadHeaderTimeout for http server connections (default 1m0s) This will set WriteTimeout in http.Server handling incoming calls from your clients. -write-timeout-server duration set WriteTimeout for http server connections (default 1m0s) This will set IdleTimeout in http.Server handling incoming calls from your clients. -idle-timeout-server duration maximum idle connections per backend host (default 1m0s) This will set MaxHeaderBytes in http.Server to limit the size of the http header from your clients. -max-header-bytes int set MaxHeaderBytes for http server connections (default 1048576)","title":"Client"},{"location":"operation/operation/#oauth2-tokeninfo","text":"OAuth2 filters integrate with external services and have their own connection handling. Outgoing calls to these services have a default timeout of 2s, which can be changed by the flag -oauth2-tokeninfo-timeout=<OAuthTokeninfoTimeout> .","title":"OAuth2 Tokeninfo"},{"location":"operation/operation/#oauth2-tokenintrospection-rfc7662","text":"OAuth2 filters integrate with external services and have their own connection handling. Outgoing calls to these services have a default timeout of 2s, which can be changed by the flag -oauth2-tokenintrospect-timeout=<OAuthTokenintrospectionTimeout> .","title":"OAuth2 Tokenintrospection RFC7662"},{"location":"operation/operation/#monitoring","text":"Monitoring is one of the most important things you need to run in production and skipper has a godoc page for the metrics package , describing options and most keys you will find in the metrics handler endpoint. The default is listening on :9911/metrics . You can modify the listen port with the -support-listener flag. Metrics can exposed using formats Codahale (json) or Prometheus and be configured by -metrics-flavour= , which defaults to codahale . To expose both formats you can use a comma separated list: -metrics-flavour=codahale,prometheus .","title":"Monitoring"},{"location":"operation/operation/#prometheus","text":"In case you want to get metrics in Prometheus format exposed, use this option to enable it: -metrics-flavour=prometheus It will return Prometheus metrics on the common metrics endpoint :9911/metrics. To monitor skipper we recommend the following queries: P99 backend latency: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{}[1m])) by (le)) HTTP 2xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"2.*\"}[1m])) by (le) ) HTTP 4xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"4.*\"}[1m])) by (le) ) HTTP 5xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"52.*\"}[1m])) by (le) ) Max goroutines (depends on label selector): max(go_goroutines{application=\"skipper-ingress\"}) Max threads (depends on label selector): max(go_threads{application=\"skipper-ingress\"}) max heap memory in use in MB (depends on label selector): max(go_memstats_heap_inuse_bytes{application=\"skipper-ingress\"}) / 1024 / 1000 Max number of heap objects (depends on label selector): max(go_memstats_heap_objects{application=\"skipper-ingress\"}) Max of P75 Go GC runtime in ms (depends on label selector): max(go_gc_duration_seconds{application=\"skipper-ingress\",quantile=\"0.75\"}) * 1000 * 1000 P99 request filter duration (depends on label selector): histogram_quantile(0.99, sum(rate(skipper_filter_request_duration_seconds_bucket{application=\"skipper-ingress\"}[1m])) by (le) ) P99 response filter duration (depends on label selector): histogram_quantile(0.99, sum(rate(skipper_filter_response_duration_seconds_bucket{application=\"skipper-ingress\"}[1m])) by (le) ) If you use Kubernetes limits or Linux cgroup CFS quotas (depends on label selector): sum(rate(container_cpu_cfs_throttled_periods_total{container_name=\"skipper-ingress\"}[1m]))","title":"Prometheus"},{"location":"operation/operation/#connection-metrics","text":"This option will enable known loadbalancer connections metrics, like counters for active and new connections. This feature sets a metrics callback on http.Server and uses a counter to collect http.ConnState . -enable-connection-metrics enables connection metrics for http server connections It will expose them in /metrics, for example json structure looks like this example: { \"counters\": { \"skipper.lb-conn-active\": { \"count\": 6 }, \"skipper.lb-conn-closed\": { \"count\": 6 }, \"skipper.lb-conn-idle\": { \"count\": 6 }, \"skipper.lb-conn-new\": { \"count\": 6 } }, /* stripped a lot of metrics here */ }","title":"Connection metrics"},{"location":"operation/operation/#application-metrics","text":"Application metrics for your proxied applications you can enable with the option: -serve-host-metrics enables reporting total serve time metrics for each host This will make sure you will get stats for each \u201cHost\u201d header as \u201ctimers\u201d: \"timers\": { \"skipper.servehost.app1_example_com.GET.200\": { \"15m.rate\": 0.06830666203045982, \"1m.rate\": 2.162612637718806e-06, \"5m.rate\": 0.008312609284452856, \"75%\": 236603815, \"95%\": 236603815, \"99%\": 236603815, \"99.9%\": 236603815, \"count\": 3, \"max\": 236603815, \"mean\": 116515451.66666667, \"mean.rate\": 0.0030589345776699827, \"median\": 91273391, \"min\": 21669149, \"stddev\": 89543653.71950394 }, \"skipper.servehost.app1_example_com.GET.304\": { \"15m.rate\": 0.3503336738177459, \"1m.rate\": 0.07923086447313292, \"5m.rate\": 0.27019839341602214, \"75%\": 99351895.25, \"95%\": 105381847, \"99%\": 105381847, \"99.9%\": 105381847, \"count\": 4, \"max\": 105381847, \"mean\": 47621612, \"mean.rate\": 0.03087161486272533, \"median\": 41676170.5, \"min\": 1752260, \"stddev\": 46489302.203724876 }, \"skipper.servehost.app1_example_com.GET.401\": { \"15m.rate\": 0.16838468990057648, \"1m.rate\": 0.01572861413072501, \"5m.rate\": 0.1194724817779537, \"75%\": 91094832, \"95%\": 91094832, \"99%\": 91094832, \"99.9%\": 91094832, \"count\": 2, \"max\": 91094832, \"mean\": 58090623, \"mean.rate\": 0.012304914018033056, \"median\": 58090623, \"min\": 25086414, \"stddev\": 33004209 } }, To change the sampling type of how metrics are handled from uniform to exponential decay , you can use the following option, which is better for not so huge utilized applications (less than 100 requests per second): -metrics-exp-decay-sample use exponentially decaying sample in metrics","title":"Application metrics"},{"location":"operation/operation/#go-metrics","text":"Metrics from the go runtime memstats are exposed from skipper to the metrics endpoint, default listener :9911, on path /metrics : \"gauges\": { \"skipper.runtime.MemStats.Alloc\": { \"value\": 3083680 }, \"skipper.runtime.MemStats.BuckHashSys\": { \"value\": 1452675 }, \"skipper.runtime.MemStats.DebugGC\": { \"value\": 0 }, \"skipper.runtime.MemStats.EnableGC\": { \"value\": 1 }, \"skipper.runtime.MemStats.Frees\": { \"value\": 121 }, \"skipper.runtime.MemStats.HeapAlloc\": { \"value\": 3083680 }, \"skipper.runtime.MemStats.HeapIdle\": { \"value\": 778240 }, \"skipper.runtime.MemStats.HeapInuse\": { \"value\": 4988928 }, \"skipper.runtime.MemStats.HeapObjects\": { \"value\": 24005 }, \"skipper.runtime.MemStats.HeapReleased\": { \"value\": 0 }, \"skipper.runtime.MemStats.HeapSys\": { \"value\": 5767168 }, \"skipper.runtime.MemStats.LastGC\": { \"value\": 1516098381155094500 }, \"skipper.runtime.MemStats.Lookups\": { \"value\": 2 }, \"skipper.runtime.MemStats.MCacheInuse\": { \"value\": 6944 }, \"skipper.runtime.MemStats.MCacheSys\": { \"value\": 16384 }, \"skipper.runtime.MemStats.MSpanInuse\": { \"value\": 77368 }, \"skipper.runtime.MemStats.MSpanSys\": { \"value\": 81920 }, \"skipper.runtime.MemStats.Mallocs\": { \"value\": 1459 }, \"skipper.runtime.MemStats.NextGC\": { \"value\": 4194304 }, \"skipper.runtime.MemStats.NumGC\": { \"value\": 0 }, \"skipper.runtime.MemStats.PauseTotalNs\": { \"value\": 683352 }, \"skipper.runtime.MemStats.StackInuse\": { \"value\": 524288 }, \"skipper.runtime.MemStats.StackSys\": { \"value\": 524288 }, \"skipper.runtime.MemStats.Sys\": { \"value\": 9246968 }, \"skipper.runtime.MemStats.TotalAlloc\": { \"value\": 35127624 }, \"skipper.runtime.NumCgoCall\": { \"value\": 0 }, \"skipper.runtime.NumGoroutine\": { \"value\": 11 }, \"skipper.runtime.NumThread\": { \"value\": 9 } }, \"histograms\": { \"skipper.runtime.MemStats.PauseNs\": { \"75%\": 82509.25, \"95%\": 132609, \"99%\": 132609, \"99.9%\": 132609, \"count\": 12, \"max\": 132609, \"mean\": 56946, \"median\": 39302.5, \"min\": 28749, \"stddev\": 31567.015005117817 } }","title":"Go metrics"},{"location":"operation/operation/#dataclient","text":"Dataclients poll some kind of data source for routes. To change the timeout for calls that polls a dataclient, which could be the Kubernetes API, use the following option: -source-poll-timeout int polling timeout of the routing data sources, in milliseconds (default 3000)","title":"Dataclient"},{"location":"operation/operation/#routing-table-information","text":"Skipper allows you to get some runtime insights. You can get the current routing table from skipper with in the eskip file format : curl localhost:9911/routes * -> \"http://localhost:12345/\" You also can get the number of routes X-Count and the UNIX timestamp of the last route table update X-Timestamp , using a HEAD request: curl -I localhost:9911/routes HTTP/1.1 200 OK Content-Type: text/plain X-Count: 1 X-Timestamp: 1517777628 Date: Sun, 04 Feb 2018 20:54:31 GMT The number of routes given is limited (1024 routes by default). In order to control this limits, there are two parameters: limit and offset . The limit defines the number of routes to get and offset where to start the list. Thanks to this, it\u2019s possible to get the results paginated or getting all of them at the same time. curl localhost:9911/routes?offset=200&limit=100","title":"Routing table information"},{"location":"operation/operation/#memory-consumption","text":"While Skipper is generally not memory bound, some features may require some attention and planning regarding the memory consumption. Potentially high memory consumers: Metrics Filters Slow Backends and chatty clients Make sure you monitor backend latency, request and error rates. Additionally use Go metrics for the number of goroutines and threads, GC pause times should be less than 1ms in general, route lookup time, request and response filter times and heap memory.","title":"Memory consumption"},{"location":"operation/operation/#metrics","text":"Memory consumption of metrics are dependent on enabled command line flags. Make sure to monitor Go metrics. If you use -metrics-flavour=codahale,prometheus you enable both storage backends. If you use the Prometheus histogram buckets -histogram-metric-buckets . If you enable route based -route-backend-metrics -route-response-metrics -serve-route-metrics , error codes -route-response-metrics and host -serve-host-metrics based metrics it can count up. Please check the support listener endpoint (default 9911) to understand the usage: % curl localhost:9911/metrics","title":"Metrics"},{"location":"operation/operation/#filters","text":"Ratelimit filter clusterClientRatelimit implementation using the swim based protocol, consumes roughly 15MB per filter for 100.000 individual clients and 10 maximum hits. Make sure you monitor Go metrics. Ratelimit filter clusterClientRatelimit implementation using the Redis ring based solution, adds 2 additional roundtrips to redis per hit. Make sure you monitor redis closely, because skipper will fallback to allow traffic if redis can not be reached.","title":"Filters"},{"location":"operation/operation/#slow-backends","text":"Skipper has to keep track of all active connections and http Requests. Slow Backends can pile up in number of connections, that will consume each a little memory per request. If you have high traffic per instance and a backend times out it can start to increase your memory consumption. Make sure you monitor backend latency, request and error rates.","title":"Slow Backends"},{"location":"operation/operation/#default-filters","text":"Default filters will be applied to all routes created or updated.","title":"Default Filters"},{"location":"operation/operation/#global-default-filters","text":"Global default filters can be specified via two different command line flags -default-filters-prepend and -default-filters-append . Filters passed to these command line flags will be applied to all routes. The difference prepend and append is where in the filter chain these default filters are applied. For example a user specified the route: r: * -> setPath(\"/foo\") If you run skipper with -default-filters-prepend=enableAccessLog(4,5) -> lifo(100,100,\"10s\") , the actual route will look like this: r: * -> enableAccessLog(4,5) -> lifo(100,100,\"10s\") -> setPath(\"/foo\") . If you run skipper with -default-filters-append=enableAccessLog(4,5) -> lifo(100,100,\"10s\") , the actual route will look like this: r: * -> setPath(\"/foo\") -> enableAccessLog(4,5) -> lifo(100,100,\"10s\") .","title":"Global Default Filters"},{"location":"operation/operation/#kubernetes-default-filters","text":"Kubernetes dataclient supports default filters. You can enable this feature by specifying default-filters-dir . The defined directory must contain per-service filter configurations, with file name following the pattern ${service}.${namespace} . The content of the files is the actual filter configurations. These filters are then prepended to the filters already defined in Ingresses. The default filters are supposed to be used only if the filters of the same kind are not configured on the Ingress resource. Otherwise, it can and will lead to potentially contradicting filter configurations and race conditions, i.e. you should specify a specific filter either on the Ingress resource or as a default filter.","title":"Kubernetes Default Filters"},{"location":"operation/operation/#scheduler","text":"HTTP request schedulers change the queuing behavior of in-flight requests. A queue has two generic properties: a limit of requests and a concurrency level. The limit of request can be unlimited (unbounded queue), or limited (bounded queue). The concurrency level is either limited or unlimited. The default scheduler is an unbounded first in first out (FIFO) queue, that is provided by Go\u2019s standard library. Skipper provides 2 last in first out (LIFO) filters to change the scheduling behavior. On failure conditions, Skipper will return HTTP status code: 503 if the queue is full, which is expected on the route with a failing backend 502 if queue access times out, because the queue access was not fast enough 500 on unknown errors, please create an issue","title":"Scheduler"},{"location":"operation/operation/#the-problem","text":"Why should you use boundaries to limit concurrency level and limit the queue? The short answer is resiliency. If you have one route, that is timing out, the request queue of skipper will pile up and consume much more memory, than before. This can lead to out of memory kill, which will affect all other routes. In this comment you can see the memory usage increased in Go\u2019s standard library bufio package. Why LIFO queue instead of FIFO queue? In normal cases the queue should not contain many requests. Skipper is able to process many requests concurrently without letting the queue piling up. In overrun situations you might want to process at least some fraction of requests instead of timing out all requests. LIFO would not time out all requests within the queue, if the backend is capable of responding some requests fast enough.","title":"The problem"},{"location":"operation/operation/#a-solution","text":"Skipper has two filters lifo() and lifoGroup() , that can limit the number of requests for a route. A documented load test shows the behavior with an enabled lifo(100,100,\"10s\") filter for all routes, that was added by default. You can do this, if you pass the following flag to skipper: -default-filters-prepend=lifo(100,100,\"10s\") . Both LIFO filters will, use a last in first out queue to handle most requests fast. If skipper is in an overrun mode, it will serve some requests fast and some will timeout. The idea is based on Dropbox bandaid proxy, which is not opensource. Dropbox shared their idea in a public blogpost . Skipper\u2019s scheduler implementation makes sure, that one route will not interfere with other routes, if these routes are not in the same scheduler group. LifoGroup has a user chosen scheduler group and lifo() will get a per route unique scheduler group.","title":"A solution"},{"location":"reference/architecture/","text":"Architecture \u00b6 Skipper is written as a library and is also a multi binary project with 2 binaries, named skipper and eskip . Skipper is the HTTP proxy and eskip is a CLI application to verify, print, update or delete Skipper routes. Skipper\u2019s internal architecture is split into different packages. The skipper package has connections to multiple dataclient , that pull information from different sources, for example static routes from an eskip file or dynamic routes from Kubernetes ingress objects. The proxy package gets the routes populated by skipper and has always a current routing table which will be replaced on change. A route is one entry in the routing table. A route consists of one or more predicate , that are used to find a route for a given HTTP request. A route can also have one or more filter , that can modify the content of the request or response. A route can point to a backend, it can be a <shunt> , meaning that skipper serves the requests for the route, a <loopback> , meaning that the requests will be matched against the routing table again after filters have modified them, or a <dynamic> , meaning that the target url can be set dynamically by a filter (e.g. setDynamicBackendUrl ). Opentracing API is supported via skipper-plugins . For example Jaeger is supported. Skipper has a rich set of metrics that are exposed as json, but can be exported in Prometheus format. Route processing \u00b6 Package skipper has a Go http.Server and does the ListenAndServe call with the loggingHandler wrapped proxy . The loggingHandler is basically a middleware for the proxy providing access logs and both implement the plain Go http.Handler interface . For each incoming http.Request the proxy will create a request context and enhance it with an Opentracing API Span. It will check proxy global ratelimits first and after that lookup the route in the routing table. After that skipper will apply all request filters, that can modify the http.Request . It will then check the route local ratelimits, the circuitbreakers and do the backend call. If the backend call got a TCP or TLS connection error in a loadbalanced route, skipper will do a retry to another backend of that loadbalanced group automatically. Just before the response to the caller, skipper will process the response filters, that can change the http.Response . In two special cases, skipper doesn\u2019t forward the request to the backend. When the route is shunted ( <shunt> ), skipper serves the request alone, by using only the filters. When the route is a <loopback> , the request is passed to the routing table for finding another route, based on the changes that the filters made to the request. Routing mechanism \u00b6 The routing executes the following steps in the typical case: Select the best fitting route by matching the request against the predicates. When no route found, respond with 404 (unless the default status code is configured to a different value). Execute the filters defined in the route in normal order on the request. The filters may or may not alter the request. Forward the request to the backend defined by the route and receive a response. Execute the filters defined in the route in reverse order on the response. The filters may or may not alter the response. Respond to the incoming request with the resulting response. Route matching \u00b6 Skipper can handle a relatively large number of routes with acceptable performance, while being able to use any attribute of the incoming HTTP requests to distinguish between them. In order to be able to do so, the path matching predicates ( Path() and PathSubtree() but not PathRegexp() ) have a special role during route matching, which is a tradeoff by design, and needs to be kept in mind to understand in some cases why a certain route was matched for a request instead of another. The route matching logic can be summed up as follows: Lookup in the path tree based on the Path() and the PathSubtree() predicates, using the path component of the incoming request\u2019s URI. Then the remaining predicates of the found route(s) are evaluated. the path lookup is a radix tree with O(log(n)) time complexity in case of intersecting paths, the more specific path is matched in the tree PathRegexp() is not used in the tree, but it is evaluated only after Path() or PathSubtree() , just like e.g. Method() or Host() . If step #1 matches multiple routes, which means there are multiple routes in the same position of the path tree, and all other predicates match the request, too, then the route with the most defined predicates is matched. this is an O(n) lookup, but only on the same leaf the root of the tree is considered a single leaf, so if not using the Path() or PathSubtree() predicates, the entire lookup will become O(n) over all the routes. If #2 results in multiple matching routes, then one route will be selected. It is unspecified which one.","title":"Architecture"},{"location":"reference/architecture/#architecture","text":"Skipper is written as a library and is also a multi binary project with 2 binaries, named skipper and eskip . Skipper is the HTTP proxy and eskip is a CLI application to verify, print, update or delete Skipper routes. Skipper\u2019s internal architecture is split into different packages. The skipper package has connections to multiple dataclient , that pull information from different sources, for example static routes from an eskip file or dynamic routes from Kubernetes ingress objects. The proxy package gets the routes populated by skipper and has always a current routing table which will be replaced on change. A route is one entry in the routing table. A route consists of one or more predicate , that are used to find a route for a given HTTP request. A route can also have one or more filter , that can modify the content of the request or response. A route can point to a backend, it can be a <shunt> , meaning that skipper serves the requests for the route, a <loopback> , meaning that the requests will be matched against the routing table again after filters have modified them, or a <dynamic> , meaning that the target url can be set dynamically by a filter (e.g. setDynamicBackendUrl ). Opentracing API is supported via skipper-plugins . For example Jaeger is supported. Skipper has a rich set of metrics that are exposed as json, but can be exported in Prometheus format.","title":"Architecture"},{"location":"reference/architecture/#route-processing","text":"Package skipper has a Go http.Server and does the ListenAndServe call with the loggingHandler wrapped proxy . The loggingHandler is basically a middleware for the proxy providing access logs and both implement the plain Go http.Handler interface . For each incoming http.Request the proxy will create a request context and enhance it with an Opentracing API Span. It will check proxy global ratelimits first and after that lookup the route in the routing table. After that skipper will apply all request filters, that can modify the http.Request . It will then check the route local ratelimits, the circuitbreakers and do the backend call. If the backend call got a TCP or TLS connection error in a loadbalanced route, skipper will do a retry to another backend of that loadbalanced group automatically. Just before the response to the caller, skipper will process the response filters, that can change the http.Response . In two special cases, skipper doesn\u2019t forward the request to the backend. When the route is shunted ( <shunt> ), skipper serves the request alone, by using only the filters. When the route is a <loopback> , the request is passed to the routing table for finding another route, based on the changes that the filters made to the request.","title":"Route processing"},{"location":"reference/architecture/#routing-mechanism","text":"The routing executes the following steps in the typical case: Select the best fitting route by matching the request against the predicates. When no route found, respond with 404 (unless the default status code is configured to a different value). Execute the filters defined in the route in normal order on the request. The filters may or may not alter the request. Forward the request to the backend defined by the route and receive a response. Execute the filters defined in the route in reverse order on the response. The filters may or may not alter the response. Respond to the incoming request with the resulting response.","title":"Routing mechanism"},{"location":"reference/architecture/#route-matching","text":"Skipper can handle a relatively large number of routes with acceptable performance, while being able to use any attribute of the incoming HTTP requests to distinguish between them. In order to be able to do so, the path matching predicates ( Path() and PathSubtree() but not PathRegexp() ) have a special role during route matching, which is a tradeoff by design, and needs to be kept in mind to understand in some cases why a certain route was matched for a request instead of another. The route matching logic can be summed up as follows: Lookup in the path tree based on the Path() and the PathSubtree() predicates, using the path component of the incoming request\u2019s URI. Then the remaining predicates of the found route(s) are evaluated. the path lookup is a radix tree with O(log(n)) time complexity in case of intersecting paths, the more specific path is matched in the tree PathRegexp() is not used in the tree, but it is evaluated only after Path() or PathSubtree() , just like e.g. Method() or Host() . If step #1 matches multiple routes, which means there are multiple routes in the same position of the path tree, and all other predicates match the request, too, then the route with the most defined predicates is matched. this is an O(n) lookup, but only on the same leaf the root of the tree is considered a single leaf, so if not using the Path() or PathSubtree() predicates, the entire lookup will become O(n) over all the routes. If #2 results in multiple matching routes, then one route will be selected. It is unspecified which one.","title":"Route matching"},{"location":"reference/backends/","text":"A backend is the last part of a route and will define the backend to call for a given request that match the route. Generic route example: routeID : Predicate1 && Predicate2 -> filter1 -> filter2 -> < backend >; Network backend \u00b6 A network backend is an arbitrary HTTP or HTTPS URL, that will be called by the proxy. Route example with a network backend \"https://www.zalando.de/\" : r0 : Method ( \"GET\" ) -> setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) -> \"https://www.zalando.de/\" ; Proxy example with request in access log ./ bin / skipper -inline-routes 'r0: Method(\"GET\") -> setRequestHeader(\"X-Passed-Skipper\", \"true\") -> \"https://www.zalando.de/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on : 9911 [ APP ] INFO [ 0000 ] proxy listener on : 9090 [ APP ] INFO [ 0000 ] TLS settings not found , defaulting to HTTP [ APP ] INFO [ 0000 ] route settings , reset , route : r0 : Method ( \"GET\" ) - > setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) - > \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied :: 1 - - [ 05 / Feb / 2019 : 14 : 31 : 05 + 0100 ] \"GET / HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 457 localhost : 9090 - - Client example with request and response headers: $ curl -v localhost:9090 >/dev/null * Rebuilt URL to: localhost:9090/ * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 13 :31:38 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Pragma: no-cache < Server: Skipper < Set-Cookie: ... ; Path = / ; Domain = zalando.de ; Expires = Sun, 04 Aug 2019 13 :31:38 GMT ; Max-Age = 15552000 ; HttpOnly ; Secure < Vary: Accept-Encoding < Transfer-Encoding: chunked < { [ 3205 bytes data ] Shunt backend \u00b6 A shunt backend, <shunt> , will not call a backend, but reply directly from the proxy itself. This can be used to shortcut, for example have a default that replies with 404 or use skipper as a backend serving static content in demos. Route Example proxying to \"https://www.zalando.de/\" in case Host header is set to \"zalando\" and rest will be served HTTP status code 404 with the body \"no matching route\" : r0 : Host ( \"zalando\" ) -> \"https://www.zalando.de/\" ; rest : * -> status ( 404 ) -> inlineContent ( \"no matching route\" ) -> < shunt >; Proxy configured as defined above with access log showing 404: $ ./bin/skipper -inline-routes 'r0: Host(\"zalando\") -> \"https://www.zalando.de/\"; rest: * -> status(404) -> inlineContent(\"no matching route\") -> \"http://localhost:9999/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: Host ( /zalando/ ) -> \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings, reset, route: rest: * -> status ( 404 ) -> inlineContent ( \"no matching route\" ) -> \"http://localhost:9999/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:14:39:26 +0100 ] \"GET / HTTP/1.1\" 404 17 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090 * Rebuilt URL to: localhost:9090/ * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 404 Not Found < Content-Length: 17 < Content-Type: text/plain ; charset = utf-8 < Server: Skipper < Date: Tue, 05 Feb 2019 13 :37:27 GMT < * Connection #0 to host localhost left intact no matching route Loopback backend \u00b6 The loopback backend, <loopback> , will lookup again the routing table to a better matching route after processing the current route. Like this you can add some headers or change the request path for some specific matching requests. Example: Route r0 is a route with loopback backend that will be matched for requests with paths that start with /api . The route will modify the http request removing /api in the path of the incoming request. In the second step of the routing the modified request will be matched by route r1 . Route r1 is a default route with a network backend to call \"https://www.zalando.de/\" r0 : PathSubtree ( \"/api\" ) -> modPath ( \"^/api\" , \"\" ) -> < loopback >; r1 : * -> \"https://www.zalando.de/\" ; Proxy configured as defined above with access logs showing 404 for the first call and 200 for the second: $ ./bin/skipper -inline-routes 'r0: PathSubtree(\"/api\") -> setRequestHeader(\"X-Passed-Skipper\", \"true\") -> modPath(/^\\/api/, \"\") -> <loopback>; r1: * -> \"https://www.zalando.de/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] route settings, reset, route: r0: PathSubtree ( \"/api\" ) -> setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) -> modPath ( \"^/api\" , \"\" ) -> <loopback> [ APP ] INFO [ 0000 ] route settings, reset, route: r1: * -> \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP ::1 - - [ 05 /Feb/2019:14:54:14 +0100 ] \"GET /api/foo HTTP/1.1\" 404 98348 \"-\" \"curl/7.49.0\" 562 localhost:9090 - - ::1 - - [ 05 /Feb/2019:14:54:28 +0100 ] \"GET /api HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 120 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090/api/foo >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET /api/foo HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 404 Not Found < Content-Language: de-DE < Content-Type: text/html ; charset = UTF-8 < Date: Tue, 05 Feb 2019 14 :00:33 GMT < Transfer-Encoding: chunked < { [ 2669 bytes data ] * Connection #0 to host localhost left intact $ curl -sv localhost:9090/api >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET /api HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 14 :00:44 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Transfer-Encoding: chunked < { [ 3491 bytes data ] Dynamic backend \u00b6 The dynamic backend, <dynamic> , will get the backend to call by data provided by filters. This allows skipper as library users to do proxy calls to a certain target from their own implementation dynamically looked up by their filters. Example shows how to set a target by a provided filter, which would be similar to a network backend: r0 : * - > setDynamicBackendUrl ( \"https://www.zalando.de\" ) - > < dynamic >; Proxy configured as defined above with access logs showing 200 for the call: $ ./bin/skipper -inline-routes 'r0: * -> setDynamicBackendUrl(\"https://www.zalando.de\") -> <dynamic>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> setDynamicBackendUrl ( \"https://www.zalando.de\" ) -> <dynamic> [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:15:09:34 +0100 ] \"GET / HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 132 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090/ >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 14 :09:34 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Pragma: no-cache < Server: Skipper < Transfer-Encoding: chunked < { [ 3491 bytes data ] * Connection #0 to host localhost left intact When no filters modifying the target are set (e.g. r0: * -> <dynamic>; ), the target host defaults to either the Host header or the host name given in the URL, and the target scheme defaults to either https when TLS is configured or http when TLS is not configured. Load Balancer backend \u00b6 The loadbalancer backend, <$algorithm, \"backend1\", \"backend2\"> , will balance the load across all given backends using the algorithm set in $algorithm . If $algorithm is not specified it will use the default algorithm set by Skipper at start. Current implemented algorithms: roundRobin : backend is chosen by the round robin algorithm, starting with a random selected backend to spread across all backends from the beginning random : backend is chosen at random consistentHash : backend is chosen by a consistent hashing algorithm with the client X-Forwarded-For header with remote IP as the fallback as input to the hash function TODO : https://github.com/zalando/skipper/issues/557 Route example with 2 backends and the roundRobin algorithm: r0 : * - > < roundRobin , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Route example with 2 backends and the random algorithm: r0 : * - > < random , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Route example with 2 backends and the consistentHash algorithm: r0 : * - > < consistentHash , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Proxy with roundRobin loadbalancer and two backends: $ ./bin/skipper -inline-routes 'r0: * -> <roundRobin, \"http://127.0.0.1:9998\", \"http://127.0.0.1:9997\">;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> <roundRobin, \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" > [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:15:39:06 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 3 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:07 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:08 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:09 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - Backend1 returns \u201cA\u201d in the body: $ ./bin/skipper -address = \":9998\" -inline-routes 'r0: * -> inlineContent(\"A\") -> <shunt>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9998 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> inlineContent ( \"A\" ) -> <shunt> [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied 127 .0.0.1 - - [ 05 /Feb/2019:15:39:06 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9998 - - 127 .0.0.1 - - [ 05 /Feb/2019:15:39:08 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9998 - - Backend2 returns \u201cB\u201d in the body: $ ./bin/skipper -address = \":9997\" -inline-routes 'r0: * -> inlineContent(\"B\") -> <shunt>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9997 [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> inlineContent ( \"B\" ) -> <shunt> [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied 127 .0.0.1 - - [ 05 /Feb/2019:15:39:07 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9997 - - 127 .0.0.1 - - [ 05 /Feb/2019:15:39:09 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9997 - - Client: $ curl -s http://localhost:9090/ A $ curl -s http://localhost:9090/ B $ curl -s http://localhost:9090/ A $ curl -s http://localhost:9090/ B","title":"Backends"},{"location":"reference/backends/#network-backend","text":"A network backend is an arbitrary HTTP or HTTPS URL, that will be called by the proxy. Route example with a network backend \"https://www.zalando.de/\" : r0 : Method ( \"GET\" ) -> setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) -> \"https://www.zalando.de/\" ; Proxy example with request in access log ./ bin / skipper -inline-routes 'r0: Method(\"GET\") -> setRequestHeader(\"X-Passed-Skipper\", \"true\") -> \"https://www.zalando.de/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on : 9911 [ APP ] INFO [ 0000 ] proxy listener on : 9090 [ APP ] INFO [ 0000 ] TLS settings not found , defaulting to HTTP [ APP ] INFO [ 0000 ] route settings , reset , route : r0 : Method ( \"GET\" ) - > setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) - > \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied :: 1 - - [ 05 / Feb / 2019 : 14 : 31 : 05 + 0100 ] \"GET / HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 457 localhost : 9090 - - Client example with request and response headers: $ curl -v localhost:9090 >/dev/null * Rebuilt URL to: localhost:9090/ * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 13 :31:38 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Pragma: no-cache < Server: Skipper < Set-Cookie: ... ; Path = / ; Domain = zalando.de ; Expires = Sun, 04 Aug 2019 13 :31:38 GMT ; Max-Age = 15552000 ; HttpOnly ; Secure < Vary: Accept-Encoding < Transfer-Encoding: chunked < { [ 3205 bytes data ]","title":"Network backend"},{"location":"reference/backends/#shunt-backend","text":"A shunt backend, <shunt> , will not call a backend, but reply directly from the proxy itself. This can be used to shortcut, for example have a default that replies with 404 or use skipper as a backend serving static content in demos. Route Example proxying to \"https://www.zalando.de/\" in case Host header is set to \"zalando\" and rest will be served HTTP status code 404 with the body \"no matching route\" : r0 : Host ( \"zalando\" ) -> \"https://www.zalando.de/\" ; rest : * -> status ( 404 ) -> inlineContent ( \"no matching route\" ) -> < shunt >; Proxy configured as defined above with access log showing 404: $ ./bin/skipper -inline-routes 'r0: Host(\"zalando\") -> \"https://www.zalando.de/\"; rest: * -> status(404) -> inlineContent(\"no matching route\") -> \"http://localhost:9999/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: Host ( /zalando/ ) -> \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings, reset, route: rest: * -> status ( 404 ) -> inlineContent ( \"no matching route\" ) -> \"http://localhost:9999/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:14:39:26 +0100 ] \"GET / HTTP/1.1\" 404 17 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090 * Rebuilt URL to: localhost:9090/ * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 404 Not Found < Content-Length: 17 < Content-Type: text/plain ; charset = utf-8 < Server: Skipper < Date: Tue, 05 Feb 2019 13 :37:27 GMT < * Connection #0 to host localhost left intact no matching route","title":"Shunt backend"},{"location":"reference/backends/#loopback-backend","text":"The loopback backend, <loopback> , will lookup again the routing table to a better matching route after processing the current route. Like this you can add some headers or change the request path for some specific matching requests. Example: Route r0 is a route with loopback backend that will be matched for requests with paths that start with /api . The route will modify the http request removing /api in the path of the incoming request. In the second step of the routing the modified request will be matched by route r1 . Route r1 is a default route with a network backend to call \"https://www.zalando.de/\" r0 : PathSubtree ( \"/api\" ) -> modPath ( \"^/api\" , \"\" ) -> < loopback >; r1 : * -> \"https://www.zalando.de/\" ; Proxy configured as defined above with access logs showing 404 for the first call and 200 for the second: $ ./bin/skipper -inline-routes 'r0: PathSubtree(\"/api\") -> setRequestHeader(\"X-Passed-Skipper\", \"true\") -> modPath(/^\\/api/, \"\") -> <loopback>; r1: * -> \"https://www.zalando.de/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] route settings, reset, route: r0: PathSubtree ( \"/api\" ) -> setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) -> modPath ( \"^/api\" , \"\" ) -> <loopback> [ APP ] INFO [ 0000 ] route settings, reset, route: r1: * -> \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP ::1 - - [ 05 /Feb/2019:14:54:14 +0100 ] \"GET /api/foo HTTP/1.1\" 404 98348 \"-\" \"curl/7.49.0\" 562 localhost:9090 - - ::1 - - [ 05 /Feb/2019:14:54:28 +0100 ] \"GET /api HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 120 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090/api/foo >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET /api/foo HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 404 Not Found < Content-Language: de-DE < Content-Type: text/html ; charset = UTF-8 < Date: Tue, 05 Feb 2019 14 :00:33 GMT < Transfer-Encoding: chunked < { [ 2669 bytes data ] * Connection #0 to host localhost left intact $ curl -sv localhost:9090/api >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET /api HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 14 :00:44 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Transfer-Encoding: chunked < { [ 3491 bytes data ]","title":"Loopback backend"},{"location":"reference/backends/#dynamic-backend","text":"The dynamic backend, <dynamic> , will get the backend to call by data provided by filters. This allows skipper as library users to do proxy calls to a certain target from their own implementation dynamically looked up by their filters. Example shows how to set a target by a provided filter, which would be similar to a network backend: r0 : * - > setDynamicBackendUrl ( \"https://www.zalando.de\" ) - > < dynamic >; Proxy configured as defined above with access logs showing 200 for the call: $ ./bin/skipper -inline-routes 'r0: * -> setDynamicBackendUrl(\"https://www.zalando.de\") -> <dynamic>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> setDynamicBackendUrl ( \"https://www.zalando.de\" ) -> <dynamic> [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:15:09:34 +0100 ] \"GET / HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 132 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090/ >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 14 :09:34 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Pragma: no-cache < Server: Skipper < Transfer-Encoding: chunked < { [ 3491 bytes data ] * Connection #0 to host localhost left intact When no filters modifying the target are set (e.g. r0: * -> <dynamic>; ), the target host defaults to either the Host header or the host name given in the URL, and the target scheme defaults to either https when TLS is configured or http when TLS is not configured.","title":"Dynamic backend"},{"location":"reference/backends/#load-balancer-backend","text":"The loadbalancer backend, <$algorithm, \"backend1\", \"backend2\"> , will balance the load across all given backends using the algorithm set in $algorithm . If $algorithm is not specified it will use the default algorithm set by Skipper at start. Current implemented algorithms: roundRobin : backend is chosen by the round robin algorithm, starting with a random selected backend to spread across all backends from the beginning random : backend is chosen at random consistentHash : backend is chosen by a consistent hashing algorithm with the client X-Forwarded-For header with remote IP as the fallback as input to the hash function TODO : https://github.com/zalando/skipper/issues/557 Route example with 2 backends and the roundRobin algorithm: r0 : * - > < roundRobin , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Route example with 2 backends and the random algorithm: r0 : * - > < random , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Route example with 2 backends and the consistentHash algorithm: r0 : * - > < consistentHash , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Proxy with roundRobin loadbalancer and two backends: $ ./bin/skipper -inline-routes 'r0: * -> <roundRobin, \"http://127.0.0.1:9998\", \"http://127.0.0.1:9997\">;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> <roundRobin, \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" > [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:15:39:06 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 3 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:07 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:08 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:09 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - Backend1 returns \u201cA\u201d in the body: $ ./bin/skipper -address = \":9998\" -inline-routes 'r0: * -> inlineContent(\"A\") -> <shunt>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9998 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> inlineContent ( \"A\" ) -> <shunt> [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied 127 .0.0.1 - - [ 05 /Feb/2019:15:39:06 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9998 - - 127 .0.0.1 - - [ 05 /Feb/2019:15:39:08 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9998 - - Backend2 returns \u201cB\u201d in the body: $ ./bin/skipper -address = \":9997\" -inline-routes 'r0: * -> inlineContent(\"B\") -> <shunt>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9997 [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> inlineContent ( \"B\" ) -> <shunt> [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied 127 .0.0.1 - - [ 05 /Feb/2019:15:39:07 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9997 - - 127 .0.0.1 - - [ 05 /Feb/2019:15:39:09 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9997 - - Client: $ curl -s http://localhost:9090/ A $ curl -s http://localhost:9090/ B $ curl -s http://localhost:9090/ A $ curl -s http://localhost:9090/ B","title":"Load Balancer backend"},{"location":"reference/development/","text":"How to develop a Filter \u00b6 A filter is part of a route and can change arbitary http data in the http.Request and http.Response path of a proxy. The filter example shows a non trivial diff of a filter implementation, that implements an authnz webhook. It shows global settings passed via flags, user documentation, developer documentation for library users, the filter implementation and some test cases. Tests should test the actual filter implementation in a proxy setup. How to pass options to your filter \u00b6 Set a default and a Usage string as const. Add a var to hold the value and put the flag to the category, that makes the most sense. If a filter, predicate or dataclient need Options passed from flags, then you should register the filter in skipper.go , the main library entrypoint. In case you do not need options from flags, use MakeRegistry() in ./filters/builtin/builtin.go to register your filter. diff --git a/cmd/skipper/main.go b/cmd/skipper/main.go index 28f18f9..4530b85 100644 --- a/cmd/skipper/main.go +++ b/cmd/skipper/main.go @@ -59,9 +59,10 @@ const ( defaultOAuthTokeninfoTimeout = 2 * time.Second defaultOAuthTokenintrospectionTimeout = 2 * time.Second + defaultWebhookTimeout = 2 * time.Second // generic: addressUsage = \"network address that skipper should listen on\" @@ -141,6 +142,8 @@ const ( oauth2TokeninfoURLUsage = \"sets the default tokeninfo URL to query information about an incoming OAuth2 token in oauth2Tokeninfo filters\" oauth2TokeninfoTimeoutUsage = \"sets the default tokeninfo request timeout duration to 2000ms\" oauth2TokenintrospectionTimeoutUsage = \"sets the default tokenintrospection request timeout duration to 2000ms\" + webhookTimeoutUsage = \"sets the webhook request timeout duration, defaults to 2s\" + // connections, timeouts: idleConnsPerHostUsage = \"maximum idle connections per backend host\" closeIdleConnsPeriodUsage = \"period of closing all idle connections in seconds or as a duration string. Not closing when less than 0\" @@ -243,13 +246,14 @@ var ( oauth2TokeninfoURL string oauth2TokeninfoTimeout time.Duration oauth2TokenintrospectionTimeout time.Duration + webhookTimeout time.Duration // connections, timeouts: idleConnsPerHost int @@ -351,13 +355,14 @@ func init() { flag.DurationVar(&oauth2TokeninfoTimeout, \"oauth2-tokeninfo-timeout\", defaultOAuthTokeninfoTimeout, oauth2TokeninfoTimeoutUsage) flag.DurationVar(&oauth2TokenintrospectionTimeout, \"oauth2-tokenintrospect-timeout\", defaultOAuthTokenintrospectionTimeout, oauth2TokenintrospectionTimeoutUsage) + flag.DurationVar(&webhookTimeout, \"webhook-timeout\", defaultWebhookTimeout, webhookTimeoutUsage) // connections, timeouts: flag.IntVar(&idleConnsPerHost, \"idle-conns-num\", proxy.DefaultIdleConnsPerHost, idleConnsPerHostUsage) @@ -536,13 +541,14 @@ func main() { OAuthTokeninfoURL: oauth2TokeninfoURL, OAuthTokeninfoTimeout: oauth2TokeninfoTimeout, OAuthTokenintrospectionTimeout: oauth2TokenintrospectionTimeout, + WebhookTimeout: webhookTimeout, // connections, timeouts: IdleConnectionsPerHost: idleConnsPerHost, diff --git a/skipper.go b/skipper.go index 10d5769..da46fe0 100644 --- a/skipper.go +++ b/skipper.go @@ -443,6 +443,9 @@ type Options struct { // OAuthTokenintrospectionTimeout sets timeout duration while calling oauth tokenintrospection service OAuthTokenintrospectionTimeout time.Duration + // WebhookTimeout sets timeout duration while calling a custom webhook auth service + WebhookTimeout time.Duration + // MaxAuditBody sets the maximum read size of the body read by the audit log filter MaxAuditBody int } @@ -677,7 +680,8 @@ func Run(o Options) error { auth.NewOAuthTokenintrospectionAnyClaims(o.OAuthTokenintrospectionTimeout), auth.NewOAuthTokenintrospectionAllClaims(o.OAuthTokenintrospectionTimeout), auth.NewOAuthTokenintrospectionAnyKV(o.OAuthTokenintrospectionTimeout), - auth.NewOAuthTokenintrospectionAllKV(o.OAuthTokenintrospectionTimeout)) + auth.NewOAuthTokenintrospectionAllKV(o.OAuthTokenintrospectionTimeout), + auth.NewWebhook(o.WebhookTimeout)) // create a filter registry with the available filter specs registered, // and register the custom filters User documentation \u00b6 Documentation for users should be done in docs/ . diff --git a/docs/filters.md b/docs/filters.md index d3bb872..a877062 100644 --- a/docs/filters.md +++ b/docs/filters.md @@ -382,6 +382,24 @@ basicAuth(\"/path/to/htpasswd\") basicAuth(\"/path/to/htpasswd\", \"My Website\") ``` +## webhook + +The `webhook` filter makes it possible to have your own authentication and +authorization endpoint as a filter. + +Headers from the incoming request will be copied into the request that +is being done to the webhook endpoint. Responses from the webhook with +status code less than 300 will be authorized, rest unauthorized. + +Examples: + +``` +webhook(\"https://custom-webhook.example.org/auth\") +``` + +The webhook timeout has a default of 2 seconds and can be globally +changed, if skipper is started with `-webhook-timeout=2s` flag. + ## oauthTokeninfoAnyScope If skipper is started with `-oauth2-tokeninfo-url` flag, you can use Add godoc \u00b6 Godoc is meant for developers using skipper as library, use doc.go of the package to document generic functionality, usage and library usage. diff --git a/filters/auth/doc.go b/filters/auth/doc.go index 696d3fd..1d6e3a8 100644 --- a/filters/auth/doc.go +++ b/filters/auth/doc.go @@ -318,5 +318,12 @@ filter after the auth filter. a: Path(\"/only-allowed-audit-log\") -> oauthTokeninfoAnyScope(\"bar-w\") -> auditLog() -> \"https://internal.example.org/\"; b: Path(\"/all-access-requests-audit-log\") -> auditLog() -> oauthTokeninfoAnyScope(\"foo-r\") -> \"https://internal.example.org/\"; +Webhook - webhook() filter + +The filter webhook allows you to have a custom authentication and +authorization endpoint for a route. + + a: Path(\"/only-allowed-by-webhook\") -> webhook(\"https://custom-webhook.example.org/auth\") -> \"https://protected-backend.example.org/\"; + */ package auth Filter implementation \u00b6 A filter can modify the incoming http.Request before calling the backend and the outgoing http.Response from the backend to the client. A filter consists of at least two types a spec and a filter . Spec consists of everything that is needed and known before a user will instantiate a filter. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the Spec interface Name() string and CreateFilter([]interface{}) (filters.Filter, error) . The actual filter implementation has to satisfy the Filter interface Request(filters.FilterContext) and Response(filters.FilterContext) . If you need to clean up for example a goroutine you can do it in Close() , which will be called on filter shutdown. diff --git a/filters/auth/webhook.go b/filters/auth/webhook.go new file mode 100644 index 0000000..f0632a6 --- /dev/null +++ b/filters/auth/webhook.go @@ -0,0 +1,84 @@ +package auth + +import ( + \"net/http\" + \"time\" + + \"github.com/zalando/skipper/filters\" +) + +const ( + WebhookName = \"webhook\" +) + +type ( + webhookSpec struct { + Timeout time.Duration + } + webhookFilter struct { + authClient *authClient + } +) + +// NewWebhook creates a new auth filter specification +// to validate authorization for requests. +func NewWebhook(d time.Duration) filters.Spec { + return &webhookSpec{Timeout: d} +} + +func (*webhookSpec) Name() string { + return WebhookName +} + +// CreateFilter creates an auth filter. The first argument is an URL +// string. +// +// s.CreateFilter(\"https://my-auth-service.example.org/auth\") +// +func (ws *webhookSpec) CreateFilter(args []interface{}) (filters.Filter, error) { + if l := len(args); l == 0 || l > 2 { + return nil, filters.ErrInvalidFilterParameters + } + + s, ok := args[0].(string) + if !ok { + return nil, filters.ErrInvalidFilterParameters + } + + ac, err := newAuthClient(s, ws.Timeout) + if err != nil { + return nil, filters.ErrInvalidFilterParameters + } + + return &webhookFilter{authClient: ac}, nil +} + +func copyHeader(to, from http.Header) { + for k, v := range from { + to[http.CanonicalHeaderKey(k)] = v + } +} + +func (f *webhookFilter) Request(ctx filters.FilterContext) { + statusCode, err := f.authClient.getWebhook(ctx.Request()) + if err != nil { + unauthorized(ctx, WebhookName, authServiceAccess, f.authClient.url.Hostname()) + } + // redirects, auth errors, webhook errors + if statusCode >= 300 { + unauthorized(ctx, WebhookName, invalidAccess, f.authClient.url.Hostname()) + } + authorized(ctx, WebhookName) +} + +func (*webhookFilter) Response(filters.FilterContext) {} + +// Close cleans-up the quit channel used for this filter +func (f *webhookFilter) Close() { + f.authClient.mu.Lock() + if f.authClient.quit != nil { + close(f.authClient.quit) + f.authClient.quit = nil + } + f.authClient.mu.Unlock() +} Writing tests \u00b6 Skipper uses normal table driven Go tests without frameworks. This example filter test creates a backend, an auth service to be called by our filter, and a filter configured by our table driven test. In general we use real backends with dynamic port allocations. We call these and inspect the http.Response to check, if we get expected results for invalid and valid data. Skipper has some helpers to create the test proxy in the proxytest package. Backends can be created with httptest.NewServer as in the example below. diff --git a/filters/auth/webhook_test.go b/filters/auth/webhook_test.go new file mode 100644 index 0000000..d43c4ea --- /dev/null +++ b/filters/auth/webhook_test.go @@ -0,0 +1,128 @@ +package auth + +import ( + \"fmt\" + \"io\" + \"net/http\" + \"net/http/httptest\" + \"net/url\" + \"testing\" + \"time\" + + \"github.com/zalando/skipper/eskip\" + \"github.com/zalando/skipper/filters\" + \"github.com/zalando/skipper/proxy/proxytest\" +) + +func TestWebhook(t *testing.T) { + for _, ti := range []struct { + msg string + token string + expected int + authorized bool + timeout bool + }{{ + msg: \"invalid-token-should-be-unauthorized\", + token: \"invalid-token\", + expected: http.StatusUnauthorized, + authorized: false, + }, { + msg: \"valid-token-should-be-authorized\", + token: testToken, + expected: http.StatusOK, + authorized: true, + }, { + msg: \"webhook-timeout-should-be-unauthorized\", + token: testToken, + expected: http.StatusUnauthorized, + authorized: false, + timeout: true, + }} { + t.Run(ti.msg, func(t *testing.T) { + backend := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, _ *http.Request) { + w.WriteHeader(http.StatusOK) + io.WriteString(w, \"Hello from backend\") + return + })) + defer backend.Close() + + authServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { + if ti.timeout { + time.Sleep(time.Second + time.Millisecond) + } + + if r.Method != \"GET\" { + w.WriteHeader(489) + io.WriteString(w, \"FAIL - not a GET request\") + return + } + + tok := r.Header.Get(authHeaderName) + tok = tok[len(authHeaderPrefix):len(tok)] + switch tok { + case testToken: + w.WriteHeader(200) + fmt.Fprintln(w, \"OK - Got token: \"+tok) + return + } + w.WriteHeader(402) //http.StatusUnauthorized) + fmt.Fprintln(w, \"Unauthorized - Got token: \") //+tok) + })) + defer authServer.Close() + + spec := NewWebhook(time.Second) + + args := []interface{}{ + \"http://\" + authServer.Listener.Addr().String(), + } + f, err := spec.CreateFilter(args) + if err != nil { + t.Errorf(\"error in creating filter for %s: %v\", ti.msg, err) + return + } + + f2 := f.(*webhookFilter) + defer f2.Close() + + fr := make(filters.Registry) + fr.Register(spec) + r := &eskip.Route{Filters: []*eskip.Filter{{Name: spec.Name(), Args: args}}, Backend: backend.URL} + + proxy := proxytest.New(fr, r) + defer proxy.Close() + + reqURL, err := url.Parse(proxy.URL) + if err != nil { + t.Errorf(\"Failed to parse url %s: %v\", proxy.URL, err) + return + } + + req, err := http.NewRequest(\"GET\", reqURL.String(), nil) + if err != nil { + t.Errorf(\"failed to create request %v\", err) + return + } + req.Header.Set(authHeaderName, authHeaderPrefix+ti.token) + + rsp, err := http.DefaultClient.Do(req) + if err != nil { + t.Errorf(\"failed to get response: %v\", err) + return + } + defer rsp.Body.Close() + + buf := make([]byte, 128) + var n int + if n, err = rsp.Body.Read(buf); err != nil && err != io.EOF { + t.Errorf(\"Could not read response body: %v\", err) + return + } + + t.Logf(\"%d %d\", rsp.StatusCode, ti.expected) + if rsp.StatusCode != ti.expected { + t.Errorf(\"unexpected status code: %v != %v %d %s\", rsp.StatusCode, ti.expected, n, buf) + return + } + }) + } +} Using a debugger \u00b6 Skipper supports plugins and to offer this support it uses the plugin library. Due to a bug in the Go compiler as reported here a debugger cannot be used. This issue will be fixed in Go 1.12 but until then the only workaround is to remove references to the plugin library. The following patch can be used for debugging. diff --git a/plugins.go b/plugins.go index 837b6cf..aa69f09 100644 --- a/plugins.go +++ b/plugins.go @@ -1,5 +1,6 @@ package skipper +/* import ( \"fmt\" \"io/ioutil\" @@ -13,8 +14,13 @@ import ( \"github.com/zalando/skipper/filters\" \"github.com/zalando/skipper/routing\" ) +*/ func (o *Options) findAndLoadPlugins() error { + return nil +} + +/* found := make(map[string]string) done := make(map[string][]string) @@ -366,3 +372,4 @@ func readPluginConfig(plugin string) (conf []string, err error) { } return conf, nil } +*/ The patch can be applied with the git apply $PATCH_FILE command. Please do not commit the modified plugins.go along with your changes.","title":"Development"},{"location":"reference/development/#how-to-develop-a-filter","text":"A filter is part of a route and can change arbitary http data in the http.Request and http.Response path of a proxy. The filter example shows a non trivial diff of a filter implementation, that implements an authnz webhook. It shows global settings passed via flags, user documentation, developer documentation for library users, the filter implementation and some test cases. Tests should test the actual filter implementation in a proxy setup.","title":"How to develop a Filter"},{"location":"reference/development/#how-to-pass-options-to-your-filter","text":"Set a default and a Usage string as const. Add a var to hold the value and put the flag to the category, that makes the most sense. If a filter, predicate or dataclient need Options passed from flags, then you should register the filter in skipper.go , the main library entrypoint. In case you do not need options from flags, use MakeRegistry() in ./filters/builtin/builtin.go to register your filter. diff --git a/cmd/skipper/main.go b/cmd/skipper/main.go index 28f18f9..4530b85 100644 --- a/cmd/skipper/main.go +++ b/cmd/skipper/main.go @@ -59,9 +59,10 @@ const ( defaultOAuthTokeninfoTimeout = 2 * time.Second defaultOAuthTokenintrospectionTimeout = 2 * time.Second + defaultWebhookTimeout = 2 * time.Second // generic: addressUsage = \"network address that skipper should listen on\" @@ -141,6 +142,8 @@ const ( oauth2TokeninfoURLUsage = \"sets the default tokeninfo URL to query information about an incoming OAuth2 token in oauth2Tokeninfo filters\" oauth2TokeninfoTimeoutUsage = \"sets the default tokeninfo request timeout duration to 2000ms\" oauth2TokenintrospectionTimeoutUsage = \"sets the default tokenintrospection request timeout duration to 2000ms\" + webhookTimeoutUsage = \"sets the webhook request timeout duration, defaults to 2s\" + // connections, timeouts: idleConnsPerHostUsage = \"maximum idle connections per backend host\" closeIdleConnsPeriodUsage = \"period of closing all idle connections in seconds or as a duration string. Not closing when less than 0\" @@ -243,13 +246,14 @@ var ( oauth2TokeninfoURL string oauth2TokeninfoTimeout time.Duration oauth2TokenintrospectionTimeout time.Duration + webhookTimeout time.Duration // connections, timeouts: idleConnsPerHost int @@ -351,13 +355,14 @@ func init() { flag.DurationVar(&oauth2TokeninfoTimeout, \"oauth2-tokeninfo-timeout\", defaultOAuthTokeninfoTimeout, oauth2TokeninfoTimeoutUsage) flag.DurationVar(&oauth2TokenintrospectionTimeout, \"oauth2-tokenintrospect-timeout\", defaultOAuthTokenintrospectionTimeout, oauth2TokenintrospectionTimeoutUsage) + flag.DurationVar(&webhookTimeout, \"webhook-timeout\", defaultWebhookTimeout, webhookTimeoutUsage) // connections, timeouts: flag.IntVar(&idleConnsPerHost, \"idle-conns-num\", proxy.DefaultIdleConnsPerHost, idleConnsPerHostUsage) @@ -536,13 +541,14 @@ func main() { OAuthTokeninfoURL: oauth2TokeninfoURL, OAuthTokeninfoTimeout: oauth2TokeninfoTimeout, OAuthTokenintrospectionTimeout: oauth2TokenintrospectionTimeout, + WebhookTimeout: webhookTimeout, // connections, timeouts: IdleConnectionsPerHost: idleConnsPerHost, diff --git a/skipper.go b/skipper.go index 10d5769..da46fe0 100644 --- a/skipper.go +++ b/skipper.go @@ -443,6 +443,9 @@ type Options struct { // OAuthTokenintrospectionTimeout sets timeout duration while calling oauth tokenintrospection service OAuthTokenintrospectionTimeout time.Duration + // WebhookTimeout sets timeout duration while calling a custom webhook auth service + WebhookTimeout time.Duration + // MaxAuditBody sets the maximum read size of the body read by the audit log filter MaxAuditBody int } @@ -677,7 +680,8 @@ func Run(o Options) error { auth.NewOAuthTokenintrospectionAnyClaims(o.OAuthTokenintrospectionTimeout), auth.NewOAuthTokenintrospectionAllClaims(o.OAuthTokenintrospectionTimeout), auth.NewOAuthTokenintrospectionAnyKV(o.OAuthTokenintrospectionTimeout), - auth.NewOAuthTokenintrospectionAllKV(o.OAuthTokenintrospectionTimeout)) + auth.NewOAuthTokenintrospectionAllKV(o.OAuthTokenintrospectionTimeout), + auth.NewWebhook(o.WebhookTimeout)) // create a filter registry with the available filter specs registered, // and register the custom filters","title":"How to pass options to your filter"},{"location":"reference/development/#user-documentation","text":"Documentation for users should be done in docs/ . diff --git a/docs/filters.md b/docs/filters.md index d3bb872..a877062 100644 --- a/docs/filters.md +++ b/docs/filters.md @@ -382,6 +382,24 @@ basicAuth(\"/path/to/htpasswd\") basicAuth(\"/path/to/htpasswd\", \"My Website\") ``` +## webhook + +The `webhook` filter makes it possible to have your own authentication and +authorization endpoint as a filter. + +Headers from the incoming request will be copied into the request that +is being done to the webhook endpoint. Responses from the webhook with +status code less than 300 will be authorized, rest unauthorized. + +Examples: + +``` +webhook(\"https://custom-webhook.example.org/auth\") +``` + +The webhook timeout has a default of 2 seconds and can be globally +changed, if skipper is started with `-webhook-timeout=2s` flag. + ## oauthTokeninfoAnyScope If skipper is started with `-oauth2-tokeninfo-url` flag, you can use","title":"User documentation"},{"location":"reference/development/#add-godoc","text":"Godoc is meant for developers using skipper as library, use doc.go of the package to document generic functionality, usage and library usage. diff --git a/filters/auth/doc.go b/filters/auth/doc.go index 696d3fd..1d6e3a8 100644 --- a/filters/auth/doc.go +++ b/filters/auth/doc.go @@ -318,5 +318,12 @@ filter after the auth filter. a: Path(\"/only-allowed-audit-log\") -> oauthTokeninfoAnyScope(\"bar-w\") -> auditLog() -> \"https://internal.example.org/\"; b: Path(\"/all-access-requests-audit-log\") -> auditLog() -> oauthTokeninfoAnyScope(\"foo-r\") -> \"https://internal.example.org/\"; +Webhook - webhook() filter + +The filter webhook allows you to have a custom authentication and +authorization endpoint for a route. + + a: Path(\"/only-allowed-by-webhook\") -> webhook(\"https://custom-webhook.example.org/auth\") -> \"https://protected-backend.example.org/\"; + */ package auth","title":"Add godoc"},{"location":"reference/development/#filter-implementation","text":"A filter can modify the incoming http.Request before calling the backend and the outgoing http.Response from the backend to the client. A filter consists of at least two types a spec and a filter . Spec consists of everything that is needed and known before a user will instantiate a filter. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the Spec interface Name() string and CreateFilter([]interface{}) (filters.Filter, error) . The actual filter implementation has to satisfy the Filter interface Request(filters.FilterContext) and Response(filters.FilterContext) . If you need to clean up for example a goroutine you can do it in Close() , which will be called on filter shutdown. diff --git a/filters/auth/webhook.go b/filters/auth/webhook.go new file mode 100644 index 0000000..f0632a6 --- /dev/null +++ b/filters/auth/webhook.go @@ -0,0 +1,84 @@ +package auth + +import ( + \"net/http\" + \"time\" + + \"github.com/zalando/skipper/filters\" +) + +const ( + WebhookName = \"webhook\" +) + +type ( + webhookSpec struct { + Timeout time.Duration + } + webhookFilter struct { + authClient *authClient + } +) + +// NewWebhook creates a new auth filter specification +// to validate authorization for requests. +func NewWebhook(d time.Duration) filters.Spec { + return &webhookSpec{Timeout: d} +} + +func (*webhookSpec) Name() string { + return WebhookName +} + +// CreateFilter creates an auth filter. The first argument is an URL +// string. +// +// s.CreateFilter(\"https://my-auth-service.example.org/auth\") +// +func (ws *webhookSpec) CreateFilter(args []interface{}) (filters.Filter, error) { + if l := len(args); l == 0 || l > 2 { + return nil, filters.ErrInvalidFilterParameters + } + + s, ok := args[0].(string) + if !ok { + return nil, filters.ErrInvalidFilterParameters + } + + ac, err := newAuthClient(s, ws.Timeout) + if err != nil { + return nil, filters.ErrInvalidFilterParameters + } + + return &webhookFilter{authClient: ac}, nil +} + +func copyHeader(to, from http.Header) { + for k, v := range from { + to[http.CanonicalHeaderKey(k)] = v + } +} + +func (f *webhookFilter) Request(ctx filters.FilterContext) { + statusCode, err := f.authClient.getWebhook(ctx.Request()) + if err != nil { + unauthorized(ctx, WebhookName, authServiceAccess, f.authClient.url.Hostname()) + } + // redirects, auth errors, webhook errors + if statusCode >= 300 { + unauthorized(ctx, WebhookName, invalidAccess, f.authClient.url.Hostname()) + } + authorized(ctx, WebhookName) +} + +func (*webhookFilter) Response(filters.FilterContext) {} + +// Close cleans-up the quit channel used for this filter +func (f *webhookFilter) Close() { + f.authClient.mu.Lock() + if f.authClient.quit != nil { + close(f.authClient.quit) + f.authClient.quit = nil + } + f.authClient.mu.Unlock() +}","title":"Filter implementation"},{"location":"reference/development/#writing-tests","text":"Skipper uses normal table driven Go tests without frameworks. This example filter test creates a backend, an auth service to be called by our filter, and a filter configured by our table driven test. In general we use real backends with dynamic port allocations. We call these and inspect the http.Response to check, if we get expected results for invalid and valid data. Skipper has some helpers to create the test proxy in the proxytest package. Backends can be created with httptest.NewServer as in the example below. diff --git a/filters/auth/webhook_test.go b/filters/auth/webhook_test.go new file mode 100644 index 0000000..d43c4ea --- /dev/null +++ b/filters/auth/webhook_test.go @@ -0,0 +1,128 @@ +package auth + +import ( + \"fmt\" + \"io\" + \"net/http\" + \"net/http/httptest\" + \"net/url\" + \"testing\" + \"time\" + + \"github.com/zalando/skipper/eskip\" + \"github.com/zalando/skipper/filters\" + \"github.com/zalando/skipper/proxy/proxytest\" +) + +func TestWebhook(t *testing.T) { + for _, ti := range []struct { + msg string + token string + expected int + authorized bool + timeout bool + }{{ + msg: \"invalid-token-should-be-unauthorized\", + token: \"invalid-token\", + expected: http.StatusUnauthorized, + authorized: false, + }, { + msg: \"valid-token-should-be-authorized\", + token: testToken, + expected: http.StatusOK, + authorized: true, + }, { + msg: \"webhook-timeout-should-be-unauthorized\", + token: testToken, + expected: http.StatusUnauthorized, + authorized: false, + timeout: true, + }} { + t.Run(ti.msg, func(t *testing.T) { + backend := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, _ *http.Request) { + w.WriteHeader(http.StatusOK) + io.WriteString(w, \"Hello from backend\") + return + })) + defer backend.Close() + + authServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { + if ti.timeout { + time.Sleep(time.Second + time.Millisecond) + } + + if r.Method != \"GET\" { + w.WriteHeader(489) + io.WriteString(w, \"FAIL - not a GET request\") + return + } + + tok := r.Header.Get(authHeaderName) + tok = tok[len(authHeaderPrefix):len(tok)] + switch tok { + case testToken: + w.WriteHeader(200) + fmt.Fprintln(w, \"OK - Got token: \"+tok) + return + } + w.WriteHeader(402) //http.StatusUnauthorized) + fmt.Fprintln(w, \"Unauthorized - Got token: \") //+tok) + })) + defer authServer.Close() + + spec := NewWebhook(time.Second) + + args := []interface{}{ + \"http://\" + authServer.Listener.Addr().String(), + } + f, err := spec.CreateFilter(args) + if err != nil { + t.Errorf(\"error in creating filter for %s: %v\", ti.msg, err) + return + } + + f2 := f.(*webhookFilter) + defer f2.Close() + + fr := make(filters.Registry) + fr.Register(spec) + r := &eskip.Route{Filters: []*eskip.Filter{{Name: spec.Name(), Args: args}}, Backend: backend.URL} + + proxy := proxytest.New(fr, r) + defer proxy.Close() + + reqURL, err := url.Parse(proxy.URL) + if err != nil { + t.Errorf(\"Failed to parse url %s: %v\", proxy.URL, err) + return + } + + req, err := http.NewRequest(\"GET\", reqURL.String(), nil) + if err != nil { + t.Errorf(\"failed to create request %v\", err) + return + } + req.Header.Set(authHeaderName, authHeaderPrefix+ti.token) + + rsp, err := http.DefaultClient.Do(req) + if err != nil { + t.Errorf(\"failed to get response: %v\", err) + return + } + defer rsp.Body.Close() + + buf := make([]byte, 128) + var n int + if n, err = rsp.Body.Read(buf); err != nil && err != io.EOF { + t.Errorf(\"Could not read response body: %v\", err) + return + } + + t.Logf(\"%d %d\", rsp.StatusCode, ti.expected) + if rsp.StatusCode != ti.expected { + t.Errorf(\"unexpected status code: %v != %v %d %s\", rsp.StatusCode, ti.expected, n, buf) + return + } + }) + } +}","title":"Writing tests"},{"location":"reference/development/#using-a-debugger","text":"Skipper supports plugins and to offer this support it uses the plugin library. Due to a bug in the Go compiler as reported here a debugger cannot be used. This issue will be fixed in Go 1.12 but until then the only workaround is to remove references to the plugin library. The following patch can be used for debugging. diff --git a/plugins.go b/plugins.go index 837b6cf..aa69f09 100644 --- a/plugins.go +++ b/plugins.go @@ -1,5 +1,6 @@ package skipper +/* import ( \"fmt\" \"io/ioutil\" @@ -13,8 +14,13 @@ import ( \"github.com/zalando/skipper/filters\" \"github.com/zalando/skipper/routing\" ) +*/ func (o *Options) findAndLoadPlugins() error { + return nil +} + +/* found := make(map[string]string) done := make(map[string][]string) @@ -366,3 +372,4 @@ func readPluginConfig(plugin string) (conf []string, err error) { } return conf, nil } +*/ The patch can be applied with the git apply $PATCH_FILE command. Please do not commit the modified plugins.go along with your changes.","title":"Using a debugger"},{"location":"reference/filters/","text":"Skipper Filters \u00b6 The parameters can be strings, regex or float64 / int string is a string surrounded by double quotes ( \" ) regex is a regular expression, surrounded by / , e.g. /^www\\.example\\.org(:\\d+)?$/ int / float64 are usual (decimal) numbers like 401 or 1.23456 time is a string in double quotes, parseable by time.Duration ) Filters are a generic tool and can change HTTP header and body in the request and response path. Filter can be chained using the arrow operator -> . Example route with a match all, 2 filters and a backend: all : * - > filter1 - > filter2 - > \"http://127.0.0.1:1234/\" ; setRequestHeader \u00b6 Set headers for requests. Parameters: header name (string) header value (string) Example: foo : * - > setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) - > \"https://backend.example.org\" ; setResponseHeader \u00b6 Same as setRequestHeader , only for responses appendRequestHeader \u00b6 Same as setRequestHeader , does not remove a possibly existing value, but adds a new header value appendResponseHeader \u00b6 Same as appendRequestHeader , only for responses dropRequestHeader \u00b6 Removes a header from the request Parameters: header name (string) Example: foo : * - > dropRequestHeader ( \"User-Agent\" ) - > \"https://backend.example.org\" ; dropResponseHeader \u00b6 Same as dropRequestHeader but for responses from the backend modPath \u00b6 Replace all matched regex expressions in the path. Parameters: the expression to match (regex) the replacement (string) setPath \u00b6 Replace the path of the original request to the replacement. Parameters: the replacement (string) redirectTo \u00b6 Creates an HTTP redirect response. Parameters: redirect status code (int) location (string) Example: redir : PathRegex (/^\\/ foo \\/ bar /) -> redirectTo(302, \"/foo/ newBar \" ) -> < shunt >; redirectToLower \u00b6 Same as redirectTo , but replaces all strings to lower case. static \u00b6 Serves static content from the filesystem. Parameters: Request path to strip (string) Target base path in the filesystem (string) Example: This serves files from /srv/www/dehydrated when requested via /.well-known/acme-challenge/ , e.g. the request GET /.well-known/acme-challenge/foo will serve the file /srv/www/dehydrated/foo . acme : Host (/./) && Method ( \"GET\" ) && Path ( \"/.well-known/acme-challenge/*\" ) -> static ( \"/.well-known/acme-challenge/\" , \"/srv/www/dehydrated\" ) -> < shunt >; Notes: redirects to the directory when a file index.html exists and it is requested, i.e. GET /foo/index.html redirects to /foo/ which serves then the /foo/index.html serves the content of the index.html when a directory is requested does a simple directory listing of files / directories when no index.html is present stripQuery \u00b6 preserveHost \u00b6 Sets the incoming Host: header on the outgoing backend connection. It can be used to override the proxyPreserveHost behavior for individual routes. Parameters: \u201ctrue\u201d or \u201cfalse\u201d \u201ctrue\u201d - use the Host header from the incoming request \u201cfalse\u201d - use the host from the backend address Example: route1 : * - > preserveHost ( \"true\" ) - > \"http://backend.example.org\" ; status \u00b6 Sets the response status code to the given value, with no regards to the backend response. Parameters: status code (int) Example: route1 : Host (/^ all401 \\. example \\. org$ /) -> status ( 401 ) -> < shunt >; compress \u00b6 The filter, when executed on the response path, checks if the response entity can be compressed. To decide, it checks the Content-Encoding, the Cache-Control and the Content-Type headers. It doesn\u2019t compress the content if the Content-Encoding is set to other than identity, or the Cache-Control applies the no-transform pragma, or the Content-Type is set to an unsupported value. The default supported content types are: text/plain , text/html , application/json , application/javascript , application/x-javascript , text/javascript , text/css , image/svg+xml , application/octet-stream . The default set of MIME types can be reset or extended by passing in the desired types as filter arguments. When extending the defaults, the first argument needs to be \"...\" . E.g. to compress tiff in addition to the defaults: * -> compress(\"...\", \"image/tiff\") -> \"https://www.example.org\" To reset the supported types, e.g. to compress only HTML, the \u201c\u2026\u201d argument needs to be omitted: * -> compress(\"text/html\") -> \"https://www.example.org\" It is possible to control the compression level, by setting it as the first filter argument, in front of the MIME types. The default compression level is best-speed. The possible values are integers between 0 and 9 (inclusive), where 0 means no-compression, 1 means best-speed and 9 means best-compression. Example: * -> compress(9, \"image/tiff\") -> \"https://www.example.org\" The filter also checks the incoming request, if it accepts the supported encodings, explicitly stated in the Accept-Encoding header. The filter currently supports gzip and deflate . It does not assume that the client accepts any encoding if the Accept-Encoding header is not set. It ignores * in the Accept-Encoding header. When compressing the response, it updates the response header. It deletes the Content-Length value triggering the proxy to always return the response with chunked transfer encoding, sets the Content-Encoding to the selected encoding and sets the Vary: Accept-Encoding header, if missing. The compression happens in a streaming way, using only a small internal buffer. setQuery \u00b6 Set the query string ?k=v in the request to the backend to a given value. Parameters: key (string) value (string) Example: setQuery(\"k\", \"v\") dropQuery \u00b6 Delete the query string ?k=v in the request to the backend for a given key. Parameters: key (string) Example: dropQuery(\"k\") inlineContent \u00b6 Returns arbitrary content in the HTTP body. Parameters: arbitrary (string) Example: * -> inlineContent(\" <h1> Hello </h1> \") -> <shunt> flowId \u00b6 Sets an X-Flow-Id header, if it\u2019s not already in the request. This allows you to have a trace in your logs, that traces from the incoming request on the edge to all backend services. Paramters: no parameter: resets always the X-Flow-Id header to a new value \u201creuse\u201d: only create X-Flow-Id header if not set in the request Example: * - > flowId () - > \"https://some-backend.example.org\" ; * - > flowId ( \"reuse\" ) - > \"https://some-backend.example.org\" ; randomContent \u00b6 Generate response with random text of specified length. Parameters: length of data (int) Example: * -> randomContent(42) -> <shunt>; latency \u00b6 Enable adding artificial latency Parameters: latency in milliseconds (int) Example: * - > latency ( 120 ) - > \"https://www.example.org\" ; bandwidth \u00b6 Enable bandwidth throttling. Parameters: bandwidth in kb/s (int) Example: * - > bandwidth ( 30 ) - > \"https://www.example.org\" ; chunks \u00b6 Enables adding chunking responses with custom chunk size with artificial delays in between response chunks. To disable delays, set the second parameter to \u201c0\u201d. Parameters: byte length (int) time duration (time.Duration) Example: * - > chunks ( 1024 , \"120ms\" ) - > \"https://www.example.org\" ; * - > chunks ( 1024 , \"0\" ) - > \"https://www.example.org\" ; backendLatency \u00b6 Same as latency filter , but on the request path and not on the response path. backendBandwidth \u00b6 Same as bandwidth filter , but on the request path and not on the response path. backendChunks \u00b6 Same as chunks filter , but on the request path and not on the response path. tee \u00b6 Provides a unix-like tee feature for routing. Using this filter, the request will be sent to a \u201cshadow\u201d backend in addition to the main backend of the route. Example: * - > tee ( \"https://audit-logging.example.org\" ) - > \"https://foo.example.org\" ; This will send an identical request for foo.example.org to audit-logging.example.org. Another use case could be using it for benchmarking a new backend with some real traffic. This we call \u201cshadow traffic\u201d. The above route will forward the request to https://foo.example.org as it normally would do, but in addition to that, it will send an identical request to https://audit-logging.example.org . The request sent to https://audit-logging.example.org will receive the same method and headers, and a copy of the body stream. The tee response is ignored for this shadow backend. It is possible to change the path of the tee request, in a similar way to the modPath filter: Path ( \"/api/v1\" ) - > tee ( \"https://api.example.org\" , \"^/v1\" , \"/v2\" ) - > \"http://api.example.org\" ; In the above example, one can test how a new version of an API would behave on incoming requests. teenf \u00b6 The same as tee filter , but does not follow redirects from the backend. basicAuth \u00b6 Enable Basic Authentication The filter accepts two parameters, the first mandatory one is the path to the htpasswd file usually used with Apache or nginx. The second one is the optional realm name that will be displayed in the browser. MD5, SHA1 and BCrypt are supported for Basic authentication password storage, see also the http-auth module page . Examples: basicAuth(\"/path/to/htpasswd\") basicAuth(\"/path/to/htpasswd\", \"My Website\") webhook \u00b6 The webhook filter makes it possible to have your own authentication and authorization endpoint as a filter. Headers from the incoming request will be copied into the request that is being done to the webhook endpoint. Responses from the webhook with status code less than 300 will be authorized, rest unauthorized. Examples: webhook(\"https://custom-webhook.example.org/auth\") The webhook timeout has a default of 2 seconds and can be globally changed, if skipper is started with -webhook-timeout=2s flag. oauthTokeninfoAnyScope \u00b6 If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If any of the configured scopes from the filter is found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAnyScope(\"s1\", \"s2\", \"s3\") oauthTokeninfoAllScope \u00b6 If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If all of the configured scopes from the filter are found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAllScope(\"s1\", \"s2\", \"s3\") oauthTokeninfoAnyKV \u00b6 If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If any of the configured key value pairs from the filter is found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAnyKV(\"k1\", \"v1\", \"k2\", \"v2\") oauthTokeninfoAllKV \u00b6 If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If all of the configured key value pairs from the filter are found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAllKV(\"k1\", \"v1\", \"k2\", \"v2\") oauthTokenintrospectionAnyClaims \u00b6 The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If one of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAnyClaims(\"c1\", \"c2\", \"c3\") oauthTokenintrospectionAllClaims \u00b6 The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If all of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAllClaims(\"c1\", \"c2\", \"c3\") oauthTokenintrospectionAnyKV \u00b6 The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If one of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAnyKV(\"k1\", \"v1\", \"k2\", \"v2\") oauthTokenintrospectionAllKV \u00b6 The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If all of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAllKV(\"k1\", \"v1\", \"k2\", \"v2\") secureOauthTokenintrospectionAnyClaims \u00b6 The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If one of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAnyClaims(\"issuerURL\", \"client-id\", \"client-secret\", \"claim1\", \"claim2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAnyClaims(\"issuerURL\", \"\", \"\", \"claim1\", \"claim2\") secureOauthTokenintrospectionAllClaims \u00b6 The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If all of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAllClaims(\"issuerURL\", \"client-id\", \"client-secret\", \"claim1\", \"claim2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAllClaims(\"issuerURL\", \"\", \"\", \"claim1\", \"claim2\") secureOauthTokenintrospectionAnyKV \u00b6 The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If one of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAnyKV(\"issuerURL\", \"client-id\", \"client-secret\", \"k1\", \"v1\", \"k2\", \"v2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAnyKV(\"issuerURL\", \"\", \"\", \"k1\", \"v1\", \"k2\", \"v2\") secureOauthTokenintrospectionAllKV \u00b6 The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If all of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAllKV(\"issuerURL\", \"client-id\", \"client-secret\", \"k1\", \"v1\", \"k2\", \"v2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAllKV(\"issuerURL\", \"\", \"\", \"k1\", \"v1\", \"k2\", \"v2\") forwardToken \u00b6 The filter accepts a single string as an argument. The argument is the header name where the result of token info or token introspection is added when the request is passed to the backend. If this filter is used when there is no token introspection or token info data then it does not have any effect. Examples: forwardToken(\"X-Tokeninfo-Forward\") oauthOIDCUserInfo \u00b6 oauthOIDCUserInfo(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims The claims which should be present in the token returned by the provider. oauthOIDCAnyClaims \u00b6 oauthOIDCAnyClaims(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims Several claims can be specified and the request is allowed as long as at least one of them is present. oauthOIDCAllClaims \u00b6 oauthOIDCAllClaims(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims Several claims can be specified and the request is allowed only when all claims are present. requestCookie \u00b6 Append a cookie to the request header. Parameters: cookie name (string) cookie value (string) Example: requestCookie(\"test-session\", \"abc\") responseCookie \u00b6 Appends cookies to responses in the \u201cSet-Cookie\u201d header. The response cookie accepts an optional argument to control the max-age property of the cookie, of type int , in seconds. The response cookie accepts an optional fourth argument, \u201cchange-only\u201d, to control if the cookie should be set on every response, or only if the request does not contain a cookie with the provided name and value. Example: responseCookie(\"test-session\", \"abc\") responseCookie(\"test-session\", \"abc\", 31536000), responseCookie(\"test-session\", \"abc\", 31536000, \"change-only\") jsCookie \u00b6 The JS cookie behaves exactly as the response cookie, but it does not set the HttpOnly directive, so these cookies will be accessible from JS code running in web browsers. Example: jsCookie(\"test-session-info\", \"abc-debug\", 31536000, \"change-only\") consecutiveBreaker \u00b6 This breaker opens when the proxy could not connect to a backend or received a >=500 status code at least N times in a row. When open, the proxy returns 503 - Service Unavailable response during the breaker timeout. After this timeout, the breaker goes into half-open state, in which it expects that M number of requests succeed. The requests in the half-open state are accepted concurrently. If any of the requests during the half-open state fails, the breaker goes back to open state. If all succeed, it goes to closed state again. Parameters: number of consecutive failures to open (int) timeout (time string, parseable by time.Duration ) - optional half-open requests (int) - optional idle-ttl (time string, parseable by time.Duration ) - optional See also the circuit breaker docs . rateBreaker \u00b6 The \u201crate breaker\u201d works similar to the consecutiveBreaker , but instead of considering N consecutive failures for going open, it maintains a sliding window of the last M events, both successes and failures, and opens only when the number of failures reaches N within the window. This way the sliding window is not time based and allows the same breaker characteristics for low and high rate traffic. Parameters: number of consecutive failures to open (int) sliding window (time string, parseable by time.Duration ) half-open requests (int) - optional idle-ttl (time string, parseable by time.Duration ) - optional See also the circuit breaker docs . disableBreaker \u00b6 Change (or set) the breaker configurations for an individual route and disable for another, in eskip: updates : Method ( \"POST\" ) && Host ( \"foo.example.org\" ) -> consecutiveBreaker ( 9 ) -> \"https://foo.backend.net\" ; backendHealthcheck : Path ( \"/healthcheck\" ) -> disableBreaker () -> \"https://foo.backend.net\" ; See also the circuit breaker docs . ~~localRatelimit~~ \u00b6 DEPRECATED use clientRatelimit with the same settings instead. clientRatelimit \u00b6 Per skipper instance calculated ratelimit, that allows number of requests by client. The definition of the same client is based on data of the http header and can be changed with an optional third parameter. If the third parameter is set skipper will use the defined HTTP header to put the request in the same client bucket, else the X-Forwarded-For Header will be used. You need to run skipper with command line flag -enable-ratelimits . Skipper will consume roughly 15 MB per filter for 100.000 clients. Parameters: number of allowed requests per time period (int) time period for requests being counted (time.Duration) optional parameter to set the same client by header (string) clientRatelimit(3, \"1m\") clientRatelimit(3, \"1m\", \"Authorization\") See also the ratelimit docs . ratelimit \u00b6 Per skipper instance calculated ratelimit, that allows number of requests to a backend. You need to run skipper with command line flag -enable-ratelimits . Parameters: number of allowed requests per time period (int) time period for requests being counted (time.Duration) ratelimit(20, \"1m\") ratelimit(300, \"1h\") See also the ratelimit docs . clusterClientRatelimit \u00b6 This ratelimit is calculated across all skipper peers and the same rate limit group. The first parameter is a string to select the same ratelimit group across one or more routes. The rate limit group allows the given number of requests by client. The definition of the same client is based on data of the http header and can be changed with an optional fourth parameter. If the fourth parameter is set skipper will use the HTTP header defined by this to put the request in the same client bucket, else the X-Forwarded-For Header will be used. You need to run skipper with command line flags -enable-swarm and -enable-ratelimits . See also our cluster ratelimit tutorial Parameters: rate limit group (string) number of allowed requests per time period (int) time period for requests being counted (time.Duration) optional parameter to set the same client by header (string) clusterClientRatelimit(\"groupA\", 10, \"1h\") clusterClientRatelimit(\"groupA\", 10, \"1h\", \"Authorization\") See also the ratelimit docs . clusterRatelimit \u00b6 This ratelimit is calculated across all skipper peers and the same rate limit group. The first parameter is a string to select the same ratelimit group across one or more routes. The rate limit group allows the given number of requests to a backend. You need to have run skipper with command line flags -enable-swarm and -enable-ratelimits . See also our cluster ratelimit tutorial Parameters: rate limit group (string) number of allowed requests per time period (int) time period for requests being counted (time.Duration) clusterRatelimit(\"groupB\", 20, \"1m\") clusterRatelimit(\"groupB\", 300, \"1h\") See also the ratelimit docs . lua \u00b6 See the scripts page corsOrigin \u00b6 The filter accepts an optional variadic list of acceptable origin parameters. If the input argument list is empty, the header will always be set to * which means any origin is acceptable. Otherwise the header is only set if the request contains an Origin header and its value matches one of the elements in the input list. The header is only set on the response. Parameters: url (variadic string) Examples: corsOrigin() corsOrigin(\"https://www.example.org\") corsOrigin(\"https://www.example.org\", \"http://localhost:9001\") headerToQuery \u00b6 Filter which assigns the value of a given header from the incoming Request to a given query param Parameters: The name of the header to pick from request The name of the query param key to add to request Examples: headerToQuery(\"X-Foo-Header\", \"foo-query-param\") The above filter will set foo-query-param query param respectively to the X-Foo-Header header and will override the value if the queryparam exists already queryToHeader \u00b6 Filter which assigns the value of a given query param from the incoming Request to a given Header with optional format string value. Parameters: The name of the query param key to pick from request The name of the header to add to request The format string used to create the header value, which gets the value from the query value as before Examples: queryToHeader(\"foo-query-param\", \"X-Foo-Header\") queryToHeader(\"access_token\", \"Authorization\", \"Bearer %s\") The first filter will set X-Foo-Header header respectively to the foo-query-param query param and will not override the value if the header exists already. The second filter will set Authorization header to the access_token query param with a prefix value Bearer and will not override the value if the header exists already. ~~accessLogDisabled~~ \u00b6 Deprecated: use disableAccessLog or enableAccessLog The accessLogDisabled filter overrides global Skipper AccessLogDisabled setting for a specific route, which allows to either turn-off the access log for specific route while access log, in general, is enabled or vice versa. Example: accessLogDisabled(\"false\") disableAccessLog \u00b6 Filter overrides global Skipper AccessLogDisabled setting and allows to turn-off the access log for specific route while access log, in general, is enabled. It is also possible to disable access logs only for a subset of response codes from backend by providing an optional list of response code prefixes. Parameters: response code prefixes (variadic int) - optional Example: disableAccessLog() disableAccessLog(1, 301, 40) This disables logs of all requests with status codes 1xxs , 301 and all 40xs . enableAccessLog \u00b6 Filter overrides global Skipper AccessLogDisabled setting and allows to turn-on the access log for specific route while access log, in general, is disabled. It is also possible to enable access logs only for a subset of response codes from backend by providing an optional list of response code prefixes. Parameters: response code prefixes (variadic int) - optional Example: enableAccessLog() enableAccessLog(1, 301, 20) This enables logs of all requests with status codes 1xxs , 301 and all 20xs . auditLog \u00b6 Filter auditLog() logs the request and N bytes of the body into the log file. N defaults to 1024 and can be overidden with -max-audit-body=<int> . N=0 omits logging the body. Example: auditLog() unverifiedAuditLog \u00b6 Filter unverifiedAuditLog() adds a Header, X-Unverified-Audit , to the request, the content of which, will also be written to the log file. By default, the value of the audit header will be equal to the value of the sub key, from the Authorization token. This can be changed by providing a string input to the filter which matches another key from the token. N.B. It is important to note that, if the content of the X-Unverified-Audit header does not match the following regex, then a default value of invalid-sub will be populated in the header instead: ^[a-zA-z0-9_/:?=&%@.#-]*$ Examples: unverifiedAuditLog() unverifiedAuditLog(\"azp\") setDynamicBackendHostFromHeader \u00b6 Filter sets the backend host for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendSchemeFromHeader or setDynamicBackendScheme . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl filters, the latter ones would have priority. Parameters: header name (string) Example: foo : * - > setDynamicBackendHostFromHeader ( \"X-Forwarded-Host\" ) - > < dynamic >; setDynamicBackendSchemeFromHeader \u00b6 Filter sets the backend scheme for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendHostFromHeader or setDynamicBackendHost . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: header name (string) Example: foo : * - > setDynamicBackendSchemeFromHeader ( \"X-Forwarded-Proto\" ) - > < dynamic >; setDynamicBackendUrlFromHeader \u00b6 Filter sets the backend url for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Parameters: header name (string) Example: foo : * - > setDynamicBackendUrlFromHeader ( \"X-Custom-Url\" ) - > < dynamic >; setDynamicBackendHost \u00b6 Filter sets the backend host for a route. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendSchemeFromHeader or setDynamicBackendScheme . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: host (string) Example: foo : * - > setDynamicBackendHost ( \"example.com\" ) - > < dynamic >; setDynamicBackendScheme \u00b6 Filter sets the backend scheme for a route. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendHostFromHeader or setDynamicBackendHost . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: scheme (string) Example: foo : * - > setDynamicBackendScheme ( \"https\" ) - > < dynamic >; setDynamicBackendUrl \u00b6 Filter sets the backend url for a route. Can be used only with <dynamic> backend. Parameters: url (string) Example: foo : * - > setDynamicBackendUrl ( \"https://example.com\" ) - > < dynamic >; apiUsageMonitoring \u00b6 The apiUsageMonitoring filter adds API related metrics to the Skipper monitoring. It is by default not activated. Activate it by providing the -enable-api-usage-monitoring flag at Skipper startup. In its deactivated state, it is still registered as a valid filter (allowing route configurations to specify it), but will perform no operation. That allows, per instance, production environments to use it and testing environments not to while keeping the same route configuration for all environments. For the client based metrics, additional flags need to be specified. Flag Description api-usage-monitoring-realm-keys Name of the property in the JWT JSON body that contains the name of the realm . api-usage-monitoring-client-keys Name of the property in the JWT JSON body that contains the name of the client . api-usage-monitoring-realms-tracking-pattern RegEx of realms to be monitored. Defaults to \u2018services\u2019. NOTE: Make sure to activate the metrics flavour proper to your environment using the metrics-flavour flag in order to get those metrics. Example: skipper -metrics-flavour prometheus -enable-api-usage-monitoring -api-usage-monitoring-realm-keys = \"realm\" -api-usage-monitoring-client-keys = \"managed-id\" api-usage-monitoring-realms-tracking-pattern = \"services,users\" The structure of the metrics is all of those elements, separated by . dots: Part Description apiUsageMonitoring.custom Every filter metrics starts with the name of the filter followed by custom . This part is constant. Application ID Identifier of the application, configured in the filter under app_id . API ID Identifier of the API, configured in the filter under api_id . Method The request\u2019s method (verb), capitalized (ex: GET , POST , PUT , DELETE ). Path The request\u2019s path, in the form of the path template configured in the filter under path_templates . Realm The realm in which the client is authenticated. Client Identifier under which the client is authenticated. Metric Name Name (or key) of the metric being tracked. Available Metrics \u00b6 Endpoint Related Metrics \u00b6 Those metrics are not identifying the realm and client. They always have * in their place. Example: + Realm | apiUsageMonitoring.custom.orders-backend.orders-api.GET.foo/orders/{order-id}.*.*.http_count | | | + Metric Name + Client The available metrics are: Type Metric Name Description Counter http_count number of HTTP exchanges Counter http1xx_count number of HTTP exchanges resulting in information (HTTP status in the 100s) Counter http2xx_count number of HTTP exchanges resulting in success (HTTP status in the 200s) Counter http3xx_count number of HTTP exchanges resulting in a redirect (HTTP status in the 300s) Counter http4xx_count number of HTTP exchanges resulting in a client error (HTTP status in the 400s) Counter http5xx_count number of HTTP exchanges resulting in a server error (HTTP status in the 500s) Histogram latency time between the first observable moment (a call to the filter\u2019s Request ) until the last (a call to the filter\u2019s Response ) Client Related Metrics \u00b6 Those metrics are not identifying endpoint (path) and HTTP verb. They always have * as their place. Example: + HTTP Verb | + Path Template + Metric Name | | | apiUsageMonitoring.custom.orders-backend.orders-api.*.*.users.mmustermann.http_count | | | + Client + Realm The available metrics are: Type Metric Name Description Counter http_count number of HTTP exchanges Counter http1xx_count number of HTTP exchanges resulting in information (HTTP status in the 100s) Counter http2xx_count number of HTTP exchanges resulting in success (HTTP status in the 200s) Counter http3xx_count number of HTTP exchanges resulting in a redirect (HTTP status in the 300s) Counter http4xx_count number of HTTP exchanges resulting in a client error (HTTP status in the 400s) Counter http5xx_count number of HTTP exchanges resulting in a server error (HTTP status in the 500s) Counter latency_sum sum of seconds (in decimal form) between the first observable moment (a call to the filter\u2019s Request ) until the last (a call to the filter\u2019s Response ) Filter Configuration \u00b6 Endpoints can be monitored using the apiUsageMonitoring filter in the route. It accepts JSON objects (as strings) of the format mentioned below. In case any of the required parameters is missing, no-op filter is created, i.e. no metrics are captured, but the creation of the route does not fail. api-usage-monitoring-configuration : type : object required : - application_id - api_id - path_templates properties : application_id : type : string description : ID of the application example : order-service api_id : type : string description : ID of the API example : orders-api path_templates : description : Endpoints to be monitored. type : array minLength : 1 items : type : string description : > Path template in /articles/{article-id} (OpenAPI 3) or in /articles/:article-id format. NOTE: They will be normalized to the :this format for metrics naming. example : /orders/{order-id} client_tracking_pattern : description : > The pattern that matches client id in form of a regular expression. By default (if undefined), it is set to `.*`. An empty string disables the client metrics completely. type : string examples : all_services : summary : All services are tracked (for all activated realms). value : \".*\" just_some_services : summary : Only services `orders-service` and `shipment-service` are tracked. value : \"(orders \\ -service|shipment \\ -service)\" Configuration Example: apiUsageMonitoring(` { \"application_id\": \"my-app\", \"api_id\": \"orders-api\", \"path_templates\": [ \"foo/orders\", \"foo/orders/:order-id\", \"foo/orders/:order-id/order_item/{order-item-id}\" ], \"client_tracking_pattern\": \"(shipping\\-service|payment\\-service)\" }`,`{ \"application_id\": \"my-app\", \"api_id\": \"customers-api\", \"path_templates\": [ \"/foo/customers/\", \"/foo/customers/{customer-id}/\" ] } `) Based on the previous configuration, here is an example of a counter metric. apiUsageMonitoring.custom.my-app.orders-api.GET.foo/orders/{order-id}.*.*.http_count Here is the Prometheus query to obtain it. sum(rate(skipper_custom_total{key=\"apiUsageMonitoring.custom.my-app.orders-api.GET.foo/orders/{order-id}.*.*.http_count\"}[60s])) by (key) Here is an example of a histogram metric. apiUsageMonitoring.custom.my_app.orders-api.POST.foo/orders.latency Here is the Prometheus query to obtain it. histogram_quantile(0.5, sum(rate(skipper_custom_duration_seconds_bucket{key=\"apiUsageMonitoring.custom.my-app.orders-api.POST.foo/orders.*.*.latency\"}[60s])) by (le, key)) NOTE: Non configured paths will be tracked with {unknown} application ID, API ID and path template. However, if all application_id s of your configuration refer to the same application, the filter assume that also non configured paths will be directed to this application. E.g.: apiUsageMonitoring.custom.my-app.{unknown}.GET.{no-match}.*.*.http_count lifo \u00b6 This Filter changes skipper to handle the route with a bounded last in first out queue (LIFO), instead of an unbounded first in first out queue (FIFO). The default skipper scheduler is based on Go net/http package, which provides an unbounded FIFO request handling. If you enable this filter the request scheduling will change to a LIFO. The idea of a LIFO queue is based on Dropbox bandaid proxy, which is not opensource. Dropbox shared their idea in a public blogpost . All bounded scheduler filters will respond requests with server status error codes in case of overrun. All scheduler filters return HTTP status code: 502, if the specified timeout is reached, because a request could not be scheduled fast enough 503, if the queue is full Parameters: MaxConcurrency specifies how many goroutines are allowed to work on this queue(int) MaxStackSize sets the queue size (int) Timeout sets the timeout to get request scheduled (time) Example: lifo(100, 150, \"10s\") The above configuration will set MaxConcurrency to 100, MaxStackSize to 150 and Timeout to 10 seconds. lifoGroup \u00b6 This filter is similar to the lifo filter. Parameters: GroupName to group multiple one or many routes to the same queue, which have to have the same settings (string) MaxConcurrency specifies how many goroutines are allowed to work on this queue(int) MaxStackSize sets the queue size (int) Timeout sets the timeout to get request scheduled (time) Example: lifoGroup(\"mygroup\", 100, 150, \"10s\") The above configuration will set MaxConcurrency to 100, MaxStackSize to 150 and Timeout to 10 seconds for the lifoGroup \u201cmygroup\u201d, that can be shared between more than routes.","title":"Filters"},{"location":"reference/filters/#skipper-filters","text":"The parameters can be strings, regex or float64 / int string is a string surrounded by double quotes ( \" ) regex is a regular expression, surrounded by / , e.g. /^www\\.example\\.org(:\\d+)?$/ int / float64 are usual (decimal) numbers like 401 or 1.23456 time is a string in double quotes, parseable by time.Duration ) Filters are a generic tool and can change HTTP header and body in the request and response path. Filter can be chained using the arrow operator -> . Example route with a match all, 2 filters and a backend: all : * - > filter1 - > filter2 - > \"http://127.0.0.1:1234/\" ;","title":"Skipper Filters"},{"location":"reference/filters/#setrequestheader","text":"Set headers for requests. Parameters: header name (string) header value (string) Example: foo : * - > setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) - > \"https://backend.example.org\" ;","title":"setRequestHeader"},{"location":"reference/filters/#setresponseheader","text":"Same as setRequestHeader , only for responses","title":"setResponseHeader"},{"location":"reference/filters/#appendrequestheader","text":"Same as setRequestHeader , does not remove a possibly existing value, but adds a new header value","title":"appendRequestHeader"},{"location":"reference/filters/#appendresponseheader","text":"Same as appendRequestHeader , only for responses","title":"appendResponseHeader"},{"location":"reference/filters/#droprequestheader","text":"Removes a header from the request Parameters: header name (string) Example: foo : * - > dropRequestHeader ( \"User-Agent\" ) - > \"https://backend.example.org\" ;","title":"dropRequestHeader"},{"location":"reference/filters/#dropresponseheader","text":"Same as dropRequestHeader but for responses from the backend","title":"dropResponseHeader"},{"location":"reference/filters/#modpath","text":"Replace all matched regex expressions in the path. Parameters: the expression to match (regex) the replacement (string)","title":"modPath"},{"location":"reference/filters/#setpath","text":"Replace the path of the original request to the replacement. Parameters: the replacement (string)","title":"setPath"},{"location":"reference/filters/#redirectto","text":"Creates an HTTP redirect response. Parameters: redirect status code (int) location (string) Example: redir : PathRegex (/^\\/ foo \\/ bar /) -> redirectTo(302, \"/foo/ newBar \" ) -> < shunt >;","title":"redirectTo"},{"location":"reference/filters/#redirecttolower","text":"Same as redirectTo , but replaces all strings to lower case.","title":"redirectToLower"},{"location":"reference/filters/#static","text":"Serves static content from the filesystem. Parameters: Request path to strip (string) Target base path in the filesystem (string) Example: This serves files from /srv/www/dehydrated when requested via /.well-known/acme-challenge/ , e.g. the request GET /.well-known/acme-challenge/foo will serve the file /srv/www/dehydrated/foo . acme : Host (/./) && Method ( \"GET\" ) && Path ( \"/.well-known/acme-challenge/*\" ) -> static ( \"/.well-known/acme-challenge/\" , \"/srv/www/dehydrated\" ) -> < shunt >; Notes: redirects to the directory when a file index.html exists and it is requested, i.e. GET /foo/index.html redirects to /foo/ which serves then the /foo/index.html serves the content of the index.html when a directory is requested does a simple directory listing of files / directories when no index.html is present","title":"static"},{"location":"reference/filters/#stripquery","text":"","title":"stripQuery"},{"location":"reference/filters/#preservehost","text":"Sets the incoming Host: header on the outgoing backend connection. It can be used to override the proxyPreserveHost behavior for individual routes. Parameters: \u201ctrue\u201d or \u201cfalse\u201d \u201ctrue\u201d - use the Host header from the incoming request \u201cfalse\u201d - use the host from the backend address Example: route1 : * - > preserveHost ( \"true\" ) - > \"http://backend.example.org\" ;","title":"preserveHost"},{"location":"reference/filters/#status","text":"Sets the response status code to the given value, with no regards to the backend response. Parameters: status code (int) Example: route1 : Host (/^ all401 \\. example \\. org$ /) -> status ( 401 ) -> < shunt >;","title":"status"},{"location":"reference/filters/#compress","text":"The filter, when executed on the response path, checks if the response entity can be compressed. To decide, it checks the Content-Encoding, the Cache-Control and the Content-Type headers. It doesn\u2019t compress the content if the Content-Encoding is set to other than identity, or the Cache-Control applies the no-transform pragma, or the Content-Type is set to an unsupported value. The default supported content types are: text/plain , text/html , application/json , application/javascript , application/x-javascript , text/javascript , text/css , image/svg+xml , application/octet-stream . The default set of MIME types can be reset or extended by passing in the desired types as filter arguments. When extending the defaults, the first argument needs to be \"...\" . E.g. to compress tiff in addition to the defaults: * -> compress(\"...\", \"image/tiff\") -> \"https://www.example.org\" To reset the supported types, e.g. to compress only HTML, the \u201c\u2026\u201d argument needs to be omitted: * -> compress(\"text/html\") -> \"https://www.example.org\" It is possible to control the compression level, by setting it as the first filter argument, in front of the MIME types. The default compression level is best-speed. The possible values are integers between 0 and 9 (inclusive), where 0 means no-compression, 1 means best-speed and 9 means best-compression. Example: * -> compress(9, \"image/tiff\") -> \"https://www.example.org\" The filter also checks the incoming request, if it accepts the supported encodings, explicitly stated in the Accept-Encoding header. The filter currently supports gzip and deflate . It does not assume that the client accepts any encoding if the Accept-Encoding header is not set. It ignores * in the Accept-Encoding header. When compressing the response, it updates the response header. It deletes the Content-Length value triggering the proxy to always return the response with chunked transfer encoding, sets the Content-Encoding to the selected encoding and sets the Vary: Accept-Encoding header, if missing. The compression happens in a streaming way, using only a small internal buffer.","title":"compress"},{"location":"reference/filters/#setquery","text":"Set the query string ?k=v in the request to the backend to a given value. Parameters: key (string) value (string) Example: setQuery(\"k\", \"v\")","title":"setQuery"},{"location":"reference/filters/#dropquery","text":"Delete the query string ?k=v in the request to the backend for a given key. Parameters: key (string) Example: dropQuery(\"k\")","title":"dropQuery"},{"location":"reference/filters/#inlinecontent","text":"Returns arbitrary content in the HTTP body. Parameters: arbitrary (string) Example: * -> inlineContent(\" <h1> Hello </h1> \") -> <shunt>","title":"inlineContent"},{"location":"reference/filters/#flowid","text":"Sets an X-Flow-Id header, if it\u2019s not already in the request. This allows you to have a trace in your logs, that traces from the incoming request on the edge to all backend services. Paramters: no parameter: resets always the X-Flow-Id header to a new value \u201creuse\u201d: only create X-Flow-Id header if not set in the request Example: * - > flowId () - > \"https://some-backend.example.org\" ; * - > flowId ( \"reuse\" ) - > \"https://some-backend.example.org\" ;","title":"flowId"},{"location":"reference/filters/#randomcontent","text":"Generate response with random text of specified length. Parameters: length of data (int) Example: * -> randomContent(42) -> <shunt>;","title":"randomContent"},{"location":"reference/filters/#latency","text":"Enable adding artificial latency Parameters: latency in milliseconds (int) Example: * - > latency ( 120 ) - > \"https://www.example.org\" ;","title":"latency"},{"location":"reference/filters/#bandwidth","text":"Enable bandwidth throttling. Parameters: bandwidth in kb/s (int) Example: * - > bandwidth ( 30 ) - > \"https://www.example.org\" ;","title":"bandwidth"},{"location":"reference/filters/#chunks","text":"Enables adding chunking responses with custom chunk size with artificial delays in between response chunks. To disable delays, set the second parameter to \u201c0\u201d. Parameters: byte length (int) time duration (time.Duration) Example: * - > chunks ( 1024 , \"120ms\" ) - > \"https://www.example.org\" ; * - > chunks ( 1024 , \"0\" ) - > \"https://www.example.org\" ;","title":"chunks"},{"location":"reference/filters/#backendlatency","text":"Same as latency filter , but on the request path and not on the response path.","title":"backendLatency"},{"location":"reference/filters/#backendbandwidth","text":"Same as bandwidth filter , but on the request path and not on the response path.","title":"backendBandwidth"},{"location":"reference/filters/#backendchunks","text":"Same as chunks filter , but on the request path and not on the response path.","title":"backendChunks"},{"location":"reference/filters/#tee","text":"Provides a unix-like tee feature for routing. Using this filter, the request will be sent to a \u201cshadow\u201d backend in addition to the main backend of the route. Example: * - > tee ( \"https://audit-logging.example.org\" ) - > \"https://foo.example.org\" ; This will send an identical request for foo.example.org to audit-logging.example.org. Another use case could be using it for benchmarking a new backend with some real traffic. This we call \u201cshadow traffic\u201d. The above route will forward the request to https://foo.example.org as it normally would do, but in addition to that, it will send an identical request to https://audit-logging.example.org . The request sent to https://audit-logging.example.org will receive the same method and headers, and a copy of the body stream. The tee response is ignored for this shadow backend. It is possible to change the path of the tee request, in a similar way to the modPath filter: Path ( \"/api/v1\" ) - > tee ( \"https://api.example.org\" , \"^/v1\" , \"/v2\" ) - > \"http://api.example.org\" ; In the above example, one can test how a new version of an API would behave on incoming requests.","title":"tee"},{"location":"reference/filters/#teenf","text":"The same as tee filter , but does not follow redirects from the backend.","title":"teenf"},{"location":"reference/filters/#basicauth","text":"Enable Basic Authentication The filter accepts two parameters, the first mandatory one is the path to the htpasswd file usually used with Apache or nginx. The second one is the optional realm name that will be displayed in the browser. MD5, SHA1 and BCrypt are supported for Basic authentication password storage, see also the http-auth module page . Examples: basicAuth(\"/path/to/htpasswd\") basicAuth(\"/path/to/htpasswd\", \"My Website\")","title":"basicAuth"},{"location":"reference/filters/#webhook","text":"The webhook filter makes it possible to have your own authentication and authorization endpoint as a filter. Headers from the incoming request will be copied into the request that is being done to the webhook endpoint. Responses from the webhook with status code less than 300 will be authorized, rest unauthorized. Examples: webhook(\"https://custom-webhook.example.org/auth\") The webhook timeout has a default of 2 seconds and can be globally changed, if skipper is started with -webhook-timeout=2s flag.","title":"webhook"},{"location":"reference/filters/#oauthtokeninfoanyscope","text":"If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If any of the configured scopes from the filter is found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAnyScope(\"s1\", \"s2\", \"s3\")","title":"oauthTokeninfoAnyScope"},{"location":"reference/filters/#oauthtokeninfoallscope","text":"If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If all of the configured scopes from the filter are found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAllScope(\"s1\", \"s2\", \"s3\")","title":"oauthTokeninfoAllScope"},{"location":"reference/filters/#oauthtokeninfoanykv","text":"If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If any of the configured key value pairs from the filter is found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAnyKV(\"k1\", \"v1\", \"k2\", \"v2\")","title":"oauthTokeninfoAnyKV"},{"location":"reference/filters/#oauthtokeninfoallkv","text":"If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If all of the configured key value pairs from the filter are found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAllKV(\"k1\", \"v1\", \"k2\", \"v2\")","title":"oauthTokeninfoAllKV"},{"location":"reference/filters/#oauthtokenintrospectionanyclaims","text":"The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If one of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAnyClaims(\"c1\", \"c2\", \"c3\")","title":"oauthTokenintrospectionAnyClaims"},{"location":"reference/filters/#oauthtokenintrospectionallclaims","text":"The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If all of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAllClaims(\"c1\", \"c2\", \"c3\")","title":"oauthTokenintrospectionAllClaims"},{"location":"reference/filters/#oauthtokenintrospectionanykv","text":"The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If one of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAnyKV(\"k1\", \"v1\", \"k2\", \"v2\")","title":"oauthTokenintrospectionAnyKV"},{"location":"reference/filters/#oauthtokenintrospectionallkv","text":"The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If all of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAllKV(\"k1\", \"v1\", \"k2\", \"v2\")","title":"oauthTokenintrospectionAllKV"},{"location":"reference/filters/#secureoauthtokenintrospectionanyclaims","text":"The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If one of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAnyClaims(\"issuerURL\", \"client-id\", \"client-secret\", \"claim1\", \"claim2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAnyClaims(\"issuerURL\", \"\", \"\", \"claim1\", \"claim2\")","title":"secureOauthTokenintrospectionAnyClaims"},{"location":"reference/filters/#secureoauthtokenintrospectionallclaims","text":"The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If all of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAllClaims(\"issuerURL\", \"client-id\", \"client-secret\", \"claim1\", \"claim2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAllClaims(\"issuerURL\", \"\", \"\", \"claim1\", \"claim2\")","title":"secureOauthTokenintrospectionAllClaims"},{"location":"reference/filters/#secureoauthtokenintrospectionanykv","text":"The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If one of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAnyKV(\"issuerURL\", \"client-id\", \"client-secret\", \"k1\", \"v1\", \"k2\", \"v2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAnyKV(\"issuerURL\", \"\", \"\", \"k1\", \"v1\", \"k2\", \"v2\")","title":"secureOauthTokenintrospectionAnyKV"},{"location":"reference/filters/#secureoauthtokenintrospectionallkv","text":"The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If all of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAllKV(\"issuerURL\", \"client-id\", \"client-secret\", \"k1\", \"v1\", \"k2\", \"v2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAllKV(\"issuerURL\", \"\", \"\", \"k1\", \"v1\", \"k2\", \"v2\")","title":"secureOauthTokenintrospectionAllKV"},{"location":"reference/filters/#forwardtoken","text":"The filter accepts a single string as an argument. The argument is the header name where the result of token info or token introspection is added when the request is passed to the backend. If this filter is used when there is no token introspection or token info data then it does not have any effect. Examples: forwardToken(\"X-Tokeninfo-Forward\")","title":"forwardToken"},{"location":"reference/filters/#oauthoidcuserinfo","text":"oauthOIDCUserInfo(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims The claims which should be present in the token returned by the provider.","title":"oauthOIDCUserInfo"},{"location":"reference/filters/#oauthoidcanyclaims","text":"oauthOIDCAnyClaims(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims Several claims can be specified and the request is allowed as long as at least one of them is present.","title":"oauthOIDCAnyClaims"},{"location":"reference/filters/#oauthoidcallclaims","text":"oauthOIDCAllClaims(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims Several claims can be specified and the request is allowed only when all claims are present.","title":"oauthOIDCAllClaims"},{"location":"reference/filters/#requestcookie","text":"Append a cookie to the request header. Parameters: cookie name (string) cookie value (string) Example: requestCookie(\"test-session\", \"abc\")","title":"requestCookie"},{"location":"reference/filters/#responsecookie","text":"Appends cookies to responses in the \u201cSet-Cookie\u201d header. The response cookie accepts an optional argument to control the max-age property of the cookie, of type int , in seconds. The response cookie accepts an optional fourth argument, \u201cchange-only\u201d, to control if the cookie should be set on every response, or only if the request does not contain a cookie with the provided name and value. Example: responseCookie(\"test-session\", \"abc\") responseCookie(\"test-session\", \"abc\", 31536000), responseCookie(\"test-session\", \"abc\", 31536000, \"change-only\")","title":"responseCookie"},{"location":"reference/filters/#jscookie","text":"The JS cookie behaves exactly as the response cookie, but it does not set the HttpOnly directive, so these cookies will be accessible from JS code running in web browsers. Example: jsCookie(\"test-session-info\", \"abc-debug\", 31536000, \"change-only\")","title":"jsCookie"},{"location":"reference/filters/#consecutivebreaker","text":"This breaker opens when the proxy could not connect to a backend or received a >=500 status code at least N times in a row. When open, the proxy returns 503 - Service Unavailable response during the breaker timeout. After this timeout, the breaker goes into half-open state, in which it expects that M number of requests succeed. The requests in the half-open state are accepted concurrently. If any of the requests during the half-open state fails, the breaker goes back to open state. If all succeed, it goes to closed state again. Parameters: number of consecutive failures to open (int) timeout (time string, parseable by time.Duration ) - optional half-open requests (int) - optional idle-ttl (time string, parseable by time.Duration ) - optional See also the circuit breaker docs .","title":"consecutiveBreaker"},{"location":"reference/filters/#ratebreaker","text":"The \u201crate breaker\u201d works similar to the consecutiveBreaker , but instead of considering N consecutive failures for going open, it maintains a sliding window of the last M events, both successes and failures, and opens only when the number of failures reaches N within the window. This way the sliding window is not time based and allows the same breaker characteristics for low and high rate traffic. Parameters: number of consecutive failures to open (int) sliding window (time string, parseable by time.Duration ) half-open requests (int) - optional idle-ttl (time string, parseable by time.Duration ) - optional See also the circuit breaker docs .","title":"rateBreaker"},{"location":"reference/filters/#disablebreaker","text":"Change (or set) the breaker configurations for an individual route and disable for another, in eskip: updates : Method ( \"POST\" ) && Host ( \"foo.example.org\" ) -> consecutiveBreaker ( 9 ) -> \"https://foo.backend.net\" ; backendHealthcheck : Path ( \"/healthcheck\" ) -> disableBreaker () -> \"https://foo.backend.net\" ; See also the circuit breaker docs .","title":"disableBreaker"},{"location":"reference/filters/#localratelimit","text":"DEPRECATED use clientRatelimit with the same settings instead.","title":"~~localRatelimit~~"},{"location":"reference/filters/#clientratelimit","text":"Per skipper instance calculated ratelimit, that allows number of requests by client. The definition of the same client is based on data of the http header and can be changed with an optional third parameter. If the third parameter is set skipper will use the defined HTTP header to put the request in the same client bucket, else the X-Forwarded-For Header will be used. You need to run skipper with command line flag -enable-ratelimits . Skipper will consume roughly 15 MB per filter for 100.000 clients. Parameters: number of allowed requests per time period (int) time period for requests being counted (time.Duration) optional parameter to set the same client by header (string) clientRatelimit(3, \"1m\") clientRatelimit(3, \"1m\", \"Authorization\") See also the ratelimit docs .","title":"clientRatelimit"},{"location":"reference/filters/#ratelimit","text":"Per skipper instance calculated ratelimit, that allows number of requests to a backend. You need to run skipper with command line flag -enable-ratelimits . Parameters: number of allowed requests per time period (int) time period for requests being counted (time.Duration) ratelimit(20, \"1m\") ratelimit(300, \"1h\") See also the ratelimit docs .","title":"ratelimit"},{"location":"reference/filters/#clusterclientratelimit","text":"This ratelimit is calculated across all skipper peers and the same rate limit group. The first parameter is a string to select the same ratelimit group across one or more routes. The rate limit group allows the given number of requests by client. The definition of the same client is based on data of the http header and can be changed with an optional fourth parameter. If the fourth parameter is set skipper will use the HTTP header defined by this to put the request in the same client bucket, else the X-Forwarded-For Header will be used. You need to run skipper with command line flags -enable-swarm and -enable-ratelimits . See also our cluster ratelimit tutorial Parameters: rate limit group (string) number of allowed requests per time period (int) time period for requests being counted (time.Duration) optional parameter to set the same client by header (string) clusterClientRatelimit(\"groupA\", 10, \"1h\") clusterClientRatelimit(\"groupA\", 10, \"1h\", \"Authorization\") See also the ratelimit docs .","title":"clusterClientRatelimit"},{"location":"reference/filters/#clusterratelimit","text":"This ratelimit is calculated across all skipper peers and the same rate limit group. The first parameter is a string to select the same ratelimit group across one or more routes. The rate limit group allows the given number of requests to a backend. You need to have run skipper with command line flags -enable-swarm and -enable-ratelimits . See also our cluster ratelimit tutorial Parameters: rate limit group (string) number of allowed requests per time period (int) time period for requests being counted (time.Duration) clusterRatelimit(\"groupB\", 20, \"1m\") clusterRatelimit(\"groupB\", 300, \"1h\") See also the ratelimit docs .","title":"clusterRatelimit"},{"location":"reference/filters/#lua","text":"See the scripts page","title":"lua"},{"location":"reference/filters/#corsorigin","text":"The filter accepts an optional variadic list of acceptable origin parameters. If the input argument list is empty, the header will always be set to * which means any origin is acceptable. Otherwise the header is only set if the request contains an Origin header and its value matches one of the elements in the input list. The header is only set on the response. Parameters: url (variadic string) Examples: corsOrigin() corsOrigin(\"https://www.example.org\") corsOrigin(\"https://www.example.org\", \"http://localhost:9001\")","title":"corsOrigin"},{"location":"reference/filters/#headertoquery","text":"Filter which assigns the value of a given header from the incoming Request to a given query param Parameters: The name of the header to pick from request The name of the query param key to add to request Examples: headerToQuery(\"X-Foo-Header\", \"foo-query-param\") The above filter will set foo-query-param query param respectively to the X-Foo-Header header and will override the value if the queryparam exists already","title":"headerToQuery"},{"location":"reference/filters/#querytoheader","text":"Filter which assigns the value of a given query param from the incoming Request to a given Header with optional format string value. Parameters: The name of the query param key to pick from request The name of the header to add to request The format string used to create the header value, which gets the value from the query value as before Examples: queryToHeader(\"foo-query-param\", \"X-Foo-Header\") queryToHeader(\"access_token\", \"Authorization\", \"Bearer %s\") The first filter will set X-Foo-Header header respectively to the foo-query-param query param and will not override the value if the header exists already. The second filter will set Authorization header to the access_token query param with a prefix value Bearer and will not override the value if the header exists already.","title":"queryToHeader"},{"location":"reference/filters/#accesslogdisabled","text":"Deprecated: use disableAccessLog or enableAccessLog The accessLogDisabled filter overrides global Skipper AccessLogDisabled setting for a specific route, which allows to either turn-off the access log for specific route while access log, in general, is enabled or vice versa. Example: accessLogDisabled(\"false\")","title":"~~accessLogDisabled~~"},{"location":"reference/filters/#disableaccesslog","text":"Filter overrides global Skipper AccessLogDisabled setting and allows to turn-off the access log for specific route while access log, in general, is enabled. It is also possible to disable access logs only for a subset of response codes from backend by providing an optional list of response code prefixes. Parameters: response code prefixes (variadic int) - optional Example: disableAccessLog() disableAccessLog(1, 301, 40) This disables logs of all requests with status codes 1xxs , 301 and all 40xs .","title":"disableAccessLog"},{"location":"reference/filters/#enableaccesslog","text":"Filter overrides global Skipper AccessLogDisabled setting and allows to turn-on the access log for specific route while access log, in general, is disabled. It is also possible to enable access logs only for a subset of response codes from backend by providing an optional list of response code prefixes. Parameters: response code prefixes (variadic int) - optional Example: enableAccessLog() enableAccessLog(1, 301, 20) This enables logs of all requests with status codes 1xxs , 301 and all 20xs .","title":"enableAccessLog"},{"location":"reference/filters/#auditlog","text":"Filter auditLog() logs the request and N bytes of the body into the log file. N defaults to 1024 and can be overidden with -max-audit-body=<int> . N=0 omits logging the body. Example: auditLog()","title":"auditLog"},{"location":"reference/filters/#unverifiedauditlog","text":"Filter unverifiedAuditLog() adds a Header, X-Unverified-Audit , to the request, the content of which, will also be written to the log file. By default, the value of the audit header will be equal to the value of the sub key, from the Authorization token. This can be changed by providing a string input to the filter which matches another key from the token. N.B. It is important to note that, if the content of the X-Unverified-Audit header does not match the following regex, then a default value of invalid-sub will be populated in the header instead: ^[a-zA-z0-9_/:?=&%@.#-]*$ Examples: unverifiedAuditLog() unverifiedAuditLog(\"azp\")","title":"unverifiedAuditLog"},{"location":"reference/filters/#setdynamicbackendhostfromheader","text":"Filter sets the backend host for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendSchemeFromHeader or setDynamicBackendScheme . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl filters, the latter ones would have priority. Parameters: header name (string) Example: foo : * - > setDynamicBackendHostFromHeader ( \"X-Forwarded-Host\" ) - > < dynamic >;","title":"setDynamicBackendHostFromHeader"},{"location":"reference/filters/#setdynamicbackendschemefromheader","text":"Filter sets the backend scheme for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendHostFromHeader or setDynamicBackendHost . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: header name (string) Example: foo : * - > setDynamicBackendSchemeFromHeader ( \"X-Forwarded-Proto\" ) - > < dynamic >;","title":"setDynamicBackendSchemeFromHeader"},{"location":"reference/filters/#setdynamicbackendurlfromheader","text":"Filter sets the backend url for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Parameters: header name (string) Example: foo : * - > setDynamicBackendUrlFromHeader ( \"X-Custom-Url\" ) - > < dynamic >;","title":"setDynamicBackendUrlFromHeader"},{"location":"reference/filters/#setdynamicbackendhost","text":"Filter sets the backend host for a route. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendSchemeFromHeader or setDynamicBackendScheme . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: host (string) Example: foo : * - > setDynamicBackendHost ( \"example.com\" ) - > < dynamic >;","title":"setDynamicBackendHost"},{"location":"reference/filters/#setdynamicbackendscheme","text":"Filter sets the backend scheme for a route. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendHostFromHeader or setDynamicBackendHost . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: scheme (string) Example: foo : * - > setDynamicBackendScheme ( \"https\" ) - > < dynamic >;","title":"setDynamicBackendScheme"},{"location":"reference/filters/#setdynamicbackendurl","text":"Filter sets the backend url for a route. Can be used only with <dynamic> backend. Parameters: url (string) Example: foo : * - > setDynamicBackendUrl ( \"https://example.com\" ) - > < dynamic >;","title":"setDynamicBackendUrl"},{"location":"reference/filters/#apiusagemonitoring","text":"The apiUsageMonitoring filter adds API related metrics to the Skipper monitoring. It is by default not activated. Activate it by providing the -enable-api-usage-monitoring flag at Skipper startup. In its deactivated state, it is still registered as a valid filter (allowing route configurations to specify it), but will perform no operation. That allows, per instance, production environments to use it and testing environments not to while keeping the same route configuration for all environments. For the client based metrics, additional flags need to be specified. Flag Description api-usage-monitoring-realm-keys Name of the property in the JWT JSON body that contains the name of the realm . api-usage-monitoring-client-keys Name of the property in the JWT JSON body that contains the name of the client . api-usage-monitoring-realms-tracking-pattern RegEx of realms to be monitored. Defaults to \u2018services\u2019. NOTE: Make sure to activate the metrics flavour proper to your environment using the metrics-flavour flag in order to get those metrics. Example: skipper -metrics-flavour prometheus -enable-api-usage-monitoring -api-usage-monitoring-realm-keys = \"realm\" -api-usage-monitoring-client-keys = \"managed-id\" api-usage-monitoring-realms-tracking-pattern = \"services,users\" The structure of the metrics is all of those elements, separated by . dots: Part Description apiUsageMonitoring.custom Every filter metrics starts with the name of the filter followed by custom . This part is constant. Application ID Identifier of the application, configured in the filter under app_id . API ID Identifier of the API, configured in the filter under api_id . Method The request\u2019s method (verb), capitalized (ex: GET , POST , PUT , DELETE ). Path The request\u2019s path, in the form of the path template configured in the filter under path_templates . Realm The realm in which the client is authenticated. Client Identifier under which the client is authenticated. Metric Name Name (or key) of the metric being tracked.","title":"apiUsageMonitoring"},{"location":"reference/filters/#available-metrics","text":"","title":"Available Metrics"},{"location":"reference/filters/#endpoint-related-metrics","text":"Those metrics are not identifying the realm and client. They always have * in their place. Example: + Realm | apiUsageMonitoring.custom.orders-backend.orders-api.GET.foo/orders/{order-id}.*.*.http_count | | | + Metric Name + Client The available metrics are: Type Metric Name Description Counter http_count number of HTTP exchanges Counter http1xx_count number of HTTP exchanges resulting in information (HTTP status in the 100s) Counter http2xx_count number of HTTP exchanges resulting in success (HTTP status in the 200s) Counter http3xx_count number of HTTP exchanges resulting in a redirect (HTTP status in the 300s) Counter http4xx_count number of HTTP exchanges resulting in a client error (HTTP status in the 400s) Counter http5xx_count number of HTTP exchanges resulting in a server error (HTTP status in the 500s) Histogram latency time between the first observable moment (a call to the filter\u2019s Request ) until the last (a call to the filter\u2019s Response )","title":"Endpoint Related Metrics"},{"location":"reference/filters/#client-related-metrics","text":"Those metrics are not identifying endpoint (path) and HTTP verb. They always have * as their place. Example: + HTTP Verb | + Path Template + Metric Name | | | apiUsageMonitoring.custom.orders-backend.orders-api.*.*.users.mmustermann.http_count | | | + Client + Realm The available metrics are: Type Metric Name Description Counter http_count number of HTTP exchanges Counter http1xx_count number of HTTP exchanges resulting in information (HTTP status in the 100s) Counter http2xx_count number of HTTP exchanges resulting in success (HTTP status in the 200s) Counter http3xx_count number of HTTP exchanges resulting in a redirect (HTTP status in the 300s) Counter http4xx_count number of HTTP exchanges resulting in a client error (HTTP status in the 400s) Counter http5xx_count number of HTTP exchanges resulting in a server error (HTTP status in the 500s) Counter latency_sum sum of seconds (in decimal form) between the first observable moment (a call to the filter\u2019s Request ) until the last (a call to the filter\u2019s Response )","title":"Client Related Metrics"},{"location":"reference/filters/#filter-configuration","text":"Endpoints can be monitored using the apiUsageMonitoring filter in the route. It accepts JSON objects (as strings) of the format mentioned below. In case any of the required parameters is missing, no-op filter is created, i.e. no metrics are captured, but the creation of the route does not fail. api-usage-monitoring-configuration : type : object required : - application_id - api_id - path_templates properties : application_id : type : string description : ID of the application example : order-service api_id : type : string description : ID of the API example : orders-api path_templates : description : Endpoints to be monitored. type : array minLength : 1 items : type : string description : > Path template in /articles/{article-id} (OpenAPI 3) or in /articles/:article-id format. NOTE: They will be normalized to the :this format for metrics naming. example : /orders/{order-id} client_tracking_pattern : description : > The pattern that matches client id in form of a regular expression. By default (if undefined), it is set to `.*`. An empty string disables the client metrics completely. type : string examples : all_services : summary : All services are tracked (for all activated realms). value : \".*\" just_some_services : summary : Only services `orders-service` and `shipment-service` are tracked. value : \"(orders \\ -service|shipment \\ -service)\" Configuration Example: apiUsageMonitoring(` { \"application_id\": \"my-app\", \"api_id\": \"orders-api\", \"path_templates\": [ \"foo/orders\", \"foo/orders/:order-id\", \"foo/orders/:order-id/order_item/{order-item-id}\" ], \"client_tracking_pattern\": \"(shipping\\-service|payment\\-service)\" }`,`{ \"application_id\": \"my-app\", \"api_id\": \"customers-api\", \"path_templates\": [ \"/foo/customers/\", \"/foo/customers/{customer-id}/\" ] } `) Based on the previous configuration, here is an example of a counter metric. apiUsageMonitoring.custom.my-app.orders-api.GET.foo/orders/{order-id}.*.*.http_count Here is the Prometheus query to obtain it. sum(rate(skipper_custom_total{key=\"apiUsageMonitoring.custom.my-app.orders-api.GET.foo/orders/{order-id}.*.*.http_count\"}[60s])) by (key) Here is an example of a histogram metric. apiUsageMonitoring.custom.my_app.orders-api.POST.foo/orders.latency Here is the Prometheus query to obtain it. histogram_quantile(0.5, sum(rate(skipper_custom_duration_seconds_bucket{key=\"apiUsageMonitoring.custom.my-app.orders-api.POST.foo/orders.*.*.latency\"}[60s])) by (le, key)) NOTE: Non configured paths will be tracked with {unknown} application ID, API ID and path template. However, if all application_id s of your configuration refer to the same application, the filter assume that also non configured paths will be directed to this application. E.g.: apiUsageMonitoring.custom.my-app.{unknown}.GET.{no-match}.*.*.http_count","title":"Filter Configuration"},{"location":"reference/filters/#lifo","text":"This Filter changes skipper to handle the route with a bounded last in first out queue (LIFO), instead of an unbounded first in first out queue (FIFO). The default skipper scheduler is based on Go net/http package, which provides an unbounded FIFO request handling. If you enable this filter the request scheduling will change to a LIFO. The idea of a LIFO queue is based on Dropbox bandaid proxy, which is not opensource. Dropbox shared their idea in a public blogpost . All bounded scheduler filters will respond requests with server status error codes in case of overrun. All scheduler filters return HTTP status code: 502, if the specified timeout is reached, because a request could not be scheduled fast enough 503, if the queue is full Parameters: MaxConcurrency specifies how many goroutines are allowed to work on this queue(int) MaxStackSize sets the queue size (int) Timeout sets the timeout to get request scheduled (time) Example: lifo(100, 150, \"10s\") The above configuration will set MaxConcurrency to 100, MaxStackSize to 150 and Timeout to 10 seconds.","title":"lifo"},{"location":"reference/filters/#lifogroup","text":"This filter is similar to the lifo filter. Parameters: GroupName to group multiple one or many routes to the same queue, which have to have the same settings (string) MaxConcurrency specifies how many goroutines are allowed to work on this queue(int) MaxStackSize sets the queue size (int) Timeout sets the timeout to get request scheduled (time) Example: lifoGroup(\"mygroup\", 100, 150, \"10s\") The above configuration will set MaxConcurrency to 100, MaxStackSize to 150 and Timeout to 10 seconds for the lifoGroup \u201cmygroup\u201d, that can be shared between more than routes.","title":"lifoGroup"},{"location":"reference/plugins/","text":"Skipper plugins \u00b6 Skipper may be extended with functionality not present in the core. These additions can be built as go plugin, so they do not have to be present in the main skipper repository. Note the warning from Go\u2019s plugin.go: // The plugin support is currently incomplete, only supports Linux, // and has known bugs. Please report any issues. Note the known problem of using plugins together with vendoring, best described here: https://github.com/golang/go/issues/20481 Plugin directories \u00b6 Plugins are loaded from sub directories of the plugin directories. By default the plugin directory is set to ./plugins (i.e. relative to skipper\u2019s working directory). An additional directory may be given with the -plugindir=/path/to/dir option to skipper. Any file with the suffix .so found below the plugin directories (also in sub directories) is attempted to load without any arguments. When a plugin needs an argument, this must be explicitly loaded and the arguments passed, e.g. with -filter-plugin geoip,db=/path/to/db . Building a plugin \u00b6 Each plugin should be built with Go version >= 1.11, enabled Go modules support similar to the following build command line: GO111MODULE=on go build -buildmode=plugin -o example.so example.go There are some pitfalls: packages which are shared between skipper and the plugin must not be in a vendor/ directory, otherwise the plugin will fail to load or in some cases give wrong results (e.g. an opentracing span cannot be found in the context even if it is present). This also means: Do not vendor skipper in a plugin repo\u2026 plugins must be rebuilt when skipper is rebuilt do not attempt to rebuild a module and copy it over a loaded plugin, that will crash skipper immediately\u2026 Use a plugin \u00b6 In this example we use a geoip database, that you need to find and download. We expect that you did a git clone git@github.com:zalando/skipper.git and entered the directory. Build skipper: % make skipper Install filter plugins: % mkdir plugins % git clone git@github.com:skipper-plugins/filters.git plugins/filters % ls plugins/filters geoip / glide . lock glide . yaml ldapauth / Makefile noop / plugin_test . go % cd plugins/filters/geoip % GO111MODULE=on go build -buildmode=plugin -o geoip.so geoip.go % cd - ~/ go / src / github . com / zalando / skipper Start a pseudo backend that shows all headers in plain: % nc -l 9000 Run the proxy with geoip database: % ./bin/skipper -filter-plugin geoip,db=$HOME/Downloads/GeoLite2-City_20181127/GeoLite2-City.mmdb -inline-routes '* -> geoip() -> \"http://127.0.0.1:9000\"' [ APP ] INFO [ 0000 ] found plugin geoip at plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] loaded plugin geoip ( geoip ) from plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] attempting to load plugin from plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] plugin geoip already loaded with InitFilter [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on : 9911 [ APP ] INFO [ 0000 ] proxy listener on : 9090 [ APP ] INFO [ 0000 ] route settings , reset , route : : * -> geoip () -> \" http : // 127.0 . 0.1 : 9000 \" [ APP ] INFO [ 0000 ] certPathTLS or keyPathTLS not found , defaulting to HTTP [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied Use a client to lookup geoip: % curl -H\"X-Forwarded-For: 107.12.53.5\" localhost:9090/ ^ C pseudo backend should show X-Geoip-Country header: # nc -l 9000 GET / HTTP/1.1 Host: 127.0.0.1:9000 User-Agent: curl/7.49.0 Accept: */* X-Forwarded-For: 107.12.53.5 X-Geoip-Country: US Accept-Encoding: gzip ^C skipper should show additional log lines, because of the CTRL-C: [APP]ERRO[0082] error while proxying, route with backend http://127.0.0.1:9000, status code 500: dialing failed false: EOF 107.12.53.5 - - [28/Nov/2018:14:39:40 +0100] \"GET / HTTP/1.1\" 500 22 \"-\" \"curl/7.49.0\" 2753 localhost:9090 - - Filter plugins \u00b6 All plugins must have a function named InitFilter with the following signature func([]string) (filters.Spec, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -filter-plugin parameter. E.g. when the -filter-plugin parameter is myfilter,datafile=/path/to/file,foo=bar the myfilter plugin will receive []string{\"datafile=/path/to/file\", \"foo=bar\"} as arguments. The filter plugin implementation is responsible to parse the received arguments. Filter plugins can be found in the filter repo Example filter plugin \u00b6 An example noop plugin looks like package main import ( \"github.com/zalando/skipper/filters\" ) type noopSpec struct {} func InitFilter ( opts [] string ) ( filters . Spec , error ) { return noopSpec {}, nil } func ( s noopSpec ) Name () string { return \"noop\" } func ( s noopSpec ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { return noopFilter {}, nil } type noopFilter struct {} func ( f noopFilter ) Request ( filters . FilterContext ) {} func ( f noopFilter ) Response ( filters . FilterContext ) {} Predicate plugins \u00b6 All plugins must have a function named InitPredicate with the following signature func([]string) (routing.PredicateSpec, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -predicate-plugin parameter. E.g. when the -predicate-plugin parameter is mypred,datafile=/path/to/file,foo=bar the mypred plugin will receive []string{\"datafile=/path/to/file\", \"foo=bar\"} as arguments. The predicate plugin implementation is responsible to parse the received arguments. Predicate plugins can be found in the predicate repo Example predicate plugin \u00b6 An example MatchAll plugin looks like package main import ( \"github.com/zalando/skipper/routing\" \"net/http\" ) type noopSpec struct {} func InitPredicate ( opts [] string ) ( routing . PredicateSpec , error ) { return noopSpec {}, nil } func ( s noopSpec ) Name () string { return \"MatchAll\" } func ( s noopSpec ) Create ( config [] interface {}) ( routing . Predicate , error ) { return noopPredicate {}, nil } type noopPredicate struct {} func ( p noopPredicate ) Match ( * http . Request ) bool { return true } DataClient plugins \u00b6 Similar to the above predicate and filter plugins. The command line option for data client plugins is -dataclient-plugin . The module must have a InitDataClient function with the signature func([]string) (routing.DataClient, error) A noop data client looks like package main import ( \"github.com/zalando/skipper/eskip\" \"github.com/zalando/skipper/routing\" ) func InitDataClient ([] string ) ( routing . DataClient , error ) { var dc DataClient = \"\" return dc , nil } type DataClient string func ( dc DataClient ) LoadAll () ([] * eskip . Route , error ) { return eskip . Parse ( string ( dc )) } func ( dc DataClient ) LoadUpdate () ([] * eskip . Route , [] string , error ) { return nil , nil , nil } MultiType plugins \u00b6 Sometimes it is necessary to combine multiple plugin types into one module. This can be done with this kind of plugin. Note that these modules are not auto loaded, these need an explicit -multi-plugin name,arg1,arg2 command line switch for skipper. The module must have a InitPlugin function with the signature func([]string) ([]filters.Spec, []routing.PredicateSpec, []routing.DataClient, error) Any of the returned types may be nil, so you can have e.g. a combined filter / data client plugin or share a filter and a predicate, e.g. like package main import ( \"fmt\" \"net\" \"net/http\" \"strconv\" \"strings\" ot \"github.com/opentracing/opentracing-go\" maxminddb \"github.com/oschwald/maxminddb-golang\" \"github.com/zalando/skipper/filters\" snet \"github.com/zalando/skipper/net\" \"github.com/zalando/skipper/predicates\" \"github.com/zalando/skipper/routing\" ) type geoipSpec struct { db * maxminddb . Reader name string } func InitPlugin ( opts [] string ) ([] filters . Spec , [] routing . PredicateSpec , [] routing . DataClient , error ) { var db string for _ , o := range opts { switch { case strings . HasPrefix ( o , \"db=\" ): db = o [ 3 :] } } if db == \"\" { return nil , nil , nil , fmt . Errorf ( \"missing db= parameter for geoip plugin\" ) } reader , err := maxminddb . Open ( db ) if err != nil { return nil , nil , nil , fmt . Errorf ( \"failed to open db %s: %s\" , db , err ) } return [] filters . Spec { & geoipSpec { db : reader , name : \"geoip\" }}, [] routing . PredicateSpec { & geoipSpec { db : reader , name : \"GeoIP\" }}, nil , nil } func ( s * geoipSpec ) Name () string { return s . name } func ( s * geoipSpec ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { var fromLast bool header := \"X-GeoIP-Country\" var err error for _ , c := range config { if s , ok := c .( string ); ok { switch { case strings . HasPrefix ( s , \"from_last=\" ): fromLast , err = strconv . ParseBool ( s [ 10 :]) if err != nil { return nil , filters . ErrInvalidFilterParameters } case strings . HasPrefix ( s , \"header=\" ): header = s [ 7 :] } } } return & geoip { db : s . db , fromLast : fromLast , header : header }, nil } func ( s * geoipSpec ) Create ( config [] interface {}) ( routing . Predicate , error ) { var fromLast bool var err error countries := make ( map [ string ] struct {}) for _ , c := range config { if s , ok := c .( string ); ok { switch { case strings . HasPrefix ( s , \"from_last=\" ): fromLast , err = strconv . ParseBool ( s [ 10 :]) if err != nil { return nil , predicates . ErrInvalidPredicateParameters } default : countries [ strings . ToUpper ( s )] = struct {}{} } } } return & geoip { db : s . db , fromLast : fromLast , countries : countries }, nil } type geoip struct { db * maxminddb . Reader fromLast bool header string countries map [ string ] struct {} } type countryRecord struct { Country struct { ISOCode string `maxminddb:\"iso_code\"` } `maxminddb:\"country\"` } func ( g * geoip ) lookup ( r * http . Request ) string { var src net . IP if g . fromLast { src = snet . RemoteHostFromLast ( r ) } else { src = snet . RemoteHost ( r ) } record := countryRecord {} err := g . db . Lookup ( src , & record ) if err != nil { fmt . Printf ( \"geoip(): failed to lookup %s: %s\" , src , err ) } if record . Country . ISOCode == \"\" { return \"UNKNOWN\" } return record . Country . ISOCode } func ( g * geoip ) Request ( c filters . FilterContext ) { c . Request (). Header . Set ( g . header , g . lookup ( c . Request ())) } func ( g * geoip ) Response ( c filters . FilterContext ) {} func ( g * geoip ) Match ( r * http . Request ) bool { span := ot . SpanFromContext ( r . Context ()) if span != nil { span . LogKV ( \"GeoIP\" , \"start\" ) } code := g . lookup ( r ) _ , ok := g . countries [ code ] if span != nil { span . LogKV ( \"GeoIP\" , code ) } return ok } OpenTracing plugins \u00b6 The tracers, except for noop , are built as Go Plugins. A tracing plugin can be loaded with -opentracing NAME as parameter to skipper. Implementations of OpenTracing API can be found in the https://github.com/skipper-plugins/opentracing repository. All plugins must have a function named InitTracer with the following signature func([]string) (opentracing.Tracer, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -opentracing parameter. E.g. when the -opentracing parameter is mytracer foo=bar token=xxx somename=bla:3 the \u201cmytracer\u201d plugin will receive []string{\"foo=bar\", \"token=xxx\", \"somename=bla:3\"} as arguments. The tracer plugin implementation is responsible to parse the received arguments. An example plugin looks like package main import ( basic \"github.com/opentracing/basictracer-go\" opentracing \"github.com/opentracing/opentracing-go\" ) func InitTracer ( opts [] string ) ( opentracing . Tracer , error ) { return basic . NewTracerWithOptions ( basic . Options { Recorder : basic . NewInMemoryRecorder (), ShouldSample : func ( traceID uint64 ) bool { return traceID % 64 == 0 }, MaxLogsPerSpan : 25 , }), nil }","title":"Plugins"},{"location":"reference/plugins/#skipper-plugins","text":"Skipper may be extended with functionality not present in the core. These additions can be built as go plugin, so they do not have to be present in the main skipper repository. Note the warning from Go\u2019s plugin.go: // The plugin support is currently incomplete, only supports Linux, // and has known bugs. Please report any issues. Note the known problem of using plugins together with vendoring, best described here: https://github.com/golang/go/issues/20481","title":"Skipper plugins"},{"location":"reference/plugins/#plugin-directories","text":"Plugins are loaded from sub directories of the plugin directories. By default the plugin directory is set to ./plugins (i.e. relative to skipper\u2019s working directory). An additional directory may be given with the -plugindir=/path/to/dir option to skipper. Any file with the suffix .so found below the plugin directories (also in sub directories) is attempted to load without any arguments. When a plugin needs an argument, this must be explicitly loaded and the arguments passed, e.g. with -filter-plugin geoip,db=/path/to/db .","title":"Plugin directories"},{"location":"reference/plugins/#building-a-plugin","text":"Each plugin should be built with Go version >= 1.11, enabled Go modules support similar to the following build command line: GO111MODULE=on go build -buildmode=plugin -o example.so example.go There are some pitfalls: packages which are shared between skipper and the plugin must not be in a vendor/ directory, otherwise the plugin will fail to load or in some cases give wrong results (e.g. an opentracing span cannot be found in the context even if it is present). This also means: Do not vendor skipper in a plugin repo\u2026 plugins must be rebuilt when skipper is rebuilt do not attempt to rebuild a module and copy it over a loaded plugin, that will crash skipper immediately\u2026","title":"Building a plugin"},{"location":"reference/plugins/#use-a-plugin","text":"In this example we use a geoip database, that you need to find and download. We expect that you did a git clone git@github.com:zalando/skipper.git and entered the directory. Build skipper: % make skipper Install filter plugins: % mkdir plugins % git clone git@github.com:skipper-plugins/filters.git plugins/filters % ls plugins/filters geoip / glide . lock glide . yaml ldapauth / Makefile noop / plugin_test . go % cd plugins/filters/geoip % GO111MODULE=on go build -buildmode=plugin -o geoip.so geoip.go % cd - ~/ go / src / github . com / zalando / skipper Start a pseudo backend that shows all headers in plain: % nc -l 9000 Run the proxy with geoip database: % ./bin/skipper -filter-plugin geoip,db=$HOME/Downloads/GeoLite2-City_20181127/GeoLite2-City.mmdb -inline-routes '* -> geoip() -> \"http://127.0.0.1:9000\"' [ APP ] INFO [ 0000 ] found plugin geoip at plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] loaded plugin geoip ( geoip ) from plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] attempting to load plugin from plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] plugin geoip already loaded with InitFilter [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on : 9911 [ APP ] INFO [ 0000 ] proxy listener on : 9090 [ APP ] INFO [ 0000 ] route settings , reset , route : : * -> geoip () -> \" http : // 127.0 . 0.1 : 9000 \" [ APP ] INFO [ 0000 ] certPathTLS or keyPathTLS not found , defaulting to HTTP [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied Use a client to lookup geoip: % curl -H\"X-Forwarded-For: 107.12.53.5\" localhost:9090/ ^ C pseudo backend should show X-Geoip-Country header: # nc -l 9000 GET / HTTP/1.1 Host: 127.0.0.1:9000 User-Agent: curl/7.49.0 Accept: */* X-Forwarded-For: 107.12.53.5 X-Geoip-Country: US Accept-Encoding: gzip ^C skipper should show additional log lines, because of the CTRL-C: [APP]ERRO[0082] error while proxying, route with backend http://127.0.0.1:9000, status code 500: dialing failed false: EOF 107.12.53.5 - - [28/Nov/2018:14:39:40 +0100] \"GET / HTTP/1.1\" 500 22 \"-\" \"curl/7.49.0\" 2753 localhost:9090 - -","title":"Use a plugin"},{"location":"reference/plugins/#filter-plugins","text":"All plugins must have a function named InitFilter with the following signature func([]string) (filters.Spec, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -filter-plugin parameter. E.g. when the -filter-plugin parameter is myfilter,datafile=/path/to/file,foo=bar the myfilter plugin will receive []string{\"datafile=/path/to/file\", \"foo=bar\"} as arguments. The filter plugin implementation is responsible to parse the received arguments. Filter plugins can be found in the filter repo","title":"Filter plugins"},{"location":"reference/plugins/#example-filter-plugin","text":"An example noop plugin looks like package main import ( \"github.com/zalando/skipper/filters\" ) type noopSpec struct {} func InitFilter ( opts [] string ) ( filters . Spec , error ) { return noopSpec {}, nil } func ( s noopSpec ) Name () string { return \"noop\" } func ( s noopSpec ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { return noopFilter {}, nil } type noopFilter struct {} func ( f noopFilter ) Request ( filters . FilterContext ) {} func ( f noopFilter ) Response ( filters . FilterContext ) {}","title":"Example filter plugin"},{"location":"reference/plugins/#predicate-plugins","text":"All plugins must have a function named InitPredicate with the following signature func([]string) (routing.PredicateSpec, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -predicate-plugin parameter. E.g. when the -predicate-plugin parameter is mypred,datafile=/path/to/file,foo=bar the mypred plugin will receive []string{\"datafile=/path/to/file\", \"foo=bar\"} as arguments. The predicate plugin implementation is responsible to parse the received arguments. Predicate plugins can be found in the predicate repo","title":"Predicate plugins"},{"location":"reference/plugins/#example-predicate-plugin","text":"An example MatchAll plugin looks like package main import ( \"github.com/zalando/skipper/routing\" \"net/http\" ) type noopSpec struct {} func InitPredicate ( opts [] string ) ( routing . PredicateSpec , error ) { return noopSpec {}, nil } func ( s noopSpec ) Name () string { return \"MatchAll\" } func ( s noopSpec ) Create ( config [] interface {}) ( routing . Predicate , error ) { return noopPredicate {}, nil } type noopPredicate struct {} func ( p noopPredicate ) Match ( * http . Request ) bool { return true }","title":"Example predicate plugin"},{"location":"reference/plugins/#dataclient-plugins","text":"Similar to the above predicate and filter plugins. The command line option for data client plugins is -dataclient-plugin . The module must have a InitDataClient function with the signature func([]string) (routing.DataClient, error) A noop data client looks like package main import ( \"github.com/zalando/skipper/eskip\" \"github.com/zalando/skipper/routing\" ) func InitDataClient ([] string ) ( routing . DataClient , error ) { var dc DataClient = \"\" return dc , nil } type DataClient string func ( dc DataClient ) LoadAll () ([] * eskip . Route , error ) { return eskip . Parse ( string ( dc )) } func ( dc DataClient ) LoadUpdate () ([] * eskip . Route , [] string , error ) { return nil , nil , nil }","title":"DataClient plugins"},{"location":"reference/plugins/#multitype-plugins","text":"Sometimes it is necessary to combine multiple plugin types into one module. This can be done with this kind of plugin. Note that these modules are not auto loaded, these need an explicit -multi-plugin name,arg1,arg2 command line switch for skipper. The module must have a InitPlugin function with the signature func([]string) ([]filters.Spec, []routing.PredicateSpec, []routing.DataClient, error) Any of the returned types may be nil, so you can have e.g. a combined filter / data client plugin or share a filter and a predicate, e.g. like package main import ( \"fmt\" \"net\" \"net/http\" \"strconv\" \"strings\" ot \"github.com/opentracing/opentracing-go\" maxminddb \"github.com/oschwald/maxminddb-golang\" \"github.com/zalando/skipper/filters\" snet \"github.com/zalando/skipper/net\" \"github.com/zalando/skipper/predicates\" \"github.com/zalando/skipper/routing\" ) type geoipSpec struct { db * maxminddb . Reader name string } func InitPlugin ( opts [] string ) ([] filters . Spec , [] routing . PredicateSpec , [] routing . DataClient , error ) { var db string for _ , o := range opts { switch { case strings . HasPrefix ( o , \"db=\" ): db = o [ 3 :] } } if db == \"\" { return nil , nil , nil , fmt . Errorf ( \"missing db= parameter for geoip plugin\" ) } reader , err := maxminddb . Open ( db ) if err != nil { return nil , nil , nil , fmt . Errorf ( \"failed to open db %s: %s\" , db , err ) } return [] filters . Spec { & geoipSpec { db : reader , name : \"geoip\" }}, [] routing . PredicateSpec { & geoipSpec { db : reader , name : \"GeoIP\" }}, nil , nil } func ( s * geoipSpec ) Name () string { return s . name } func ( s * geoipSpec ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { var fromLast bool header := \"X-GeoIP-Country\" var err error for _ , c := range config { if s , ok := c .( string ); ok { switch { case strings . HasPrefix ( s , \"from_last=\" ): fromLast , err = strconv . ParseBool ( s [ 10 :]) if err != nil { return nil , filters . ErrInvalidFilterParameters } case strings . HasPrefix ( s , \"header=\" ): header = s [ 7 :] } } } return & geoip { db : s . db , fromLast : fromLast , header : header }, nil } func ( s * geoipSpec ) Create ( config [] interface {}) ( routing . Predicate , error ) { var fromLast bool var err error countries := make ( map [ string ] struct {}) for _ , c := range config { if s , ok := c .( string ); ok { switch { case strings . HasPrefix ( s , \"from_last=\" ): fromLast , err = strconv . ParseBool ( s [ 10 :]) if err != nil { return nil , predicates . ErrInvalidPredicateParameters } default : countries [ strings . ToUpper ( s )] = struct {}{} } } } return & geoip { db : s . db , fromLast : fromLast , countries : countries }, nil } type geoip struct { db * maxminddb . Reader fromLast bool header string countries map [ string ] struct {} } type countryRecord struct { Country struct { ISOCode string `maxminddb:\"iso_code\"` } `maxminddb:\"country\"` } func ( g * geoip ) lookup ( r * http . Request ) string { var src net . IP if g . fromLast { src = snet . RemoteHostFromLast ( r ) } else { src = snet . RemoteHost ( r ) } record := countryRecord {} err := g . db . Lookup ( src , & record ) if err != nil { fmt . Printf ( \"geoip(): failed to lookup %s: %s\" , src , err ) } if record . Country . ISOCode == \"\" { return \"UNKNOWN\" } return record . Country . ISOCode } func ( g * geoip ) Request ( c filters . FilterContext ) { c . Request (). Header . Set ( g . header , g . lookup ( c . Request ())) } func ( g * geoip ) Response ( c filters . FilterContext ) {} func ( g * geoip ) Match ( r * http . Request ) bool { span := ot . SpanFromContext ( r . Context ()) if span != nil { span . LogKV ( \"GeoIP\" , \"start\" ) } code := g . lookup ( r ) _ , ok := g . countries [ code ] if span != nil { span . LogKV ( \"GeoIP\" , code ) } return ok }","title":"MultiType plugins"},{"location":"reference/plugins/#opentracing-plugins","text":"The tracers, except for noop , are built as Go Plugins. A tracing plugin can be loaded with -opentracing NAME as parameter to skipper. Implementations of OpenTracing API can be found in the https://github.com/skipper-plugins/opentracing repository. All plugins must have a function named InitTracer with the following signature func([]string) (opentracing.Tracer, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -opentracing parameter. E.g. when the -opentracing parameter is mytracer foo=bar token=xxx somename=bla:3 the \u201cmytracer\u201d plugin will receive []string{\"foo=bar\", \"token=xxx\", \"somename=bla:3\"} as arguments. The tracer plugin implementation is responsible to parse the received arguments. An example plugin looks like package main import ( basic \"github.com/opentracing/basictracer-go\" opentracing \"github.com/opentracing/opentracing-go\" ) func InitTracer ( opts [] string ) ( opentracing . Tracer , error ) { return basic . NewTracerWithOptions ( basic . Options { Recorder : basic . NewInMemoryRecorder (), ShouldSample : func ( traceID uint64 ) bool { return traceID % 64 == 0 }, MaxLogsPerSpan : 25 , }), nil }","title":"OpenTracing plugins"},{"location":"reference/predicates/","text":"Skipper Predicates \u00b6 The parameters can be strings, regex or float64 / int string is a string surrounded by double quotes ( \" ) regex is a re2 regular expression , surrounded by / , e.g. /^www\\.example\\.org(:\\d+)?$/ int / float64 are usual (decimal) numbers like 401 or 1.23456 time is a string in double quotes, parseable by time.Duration ) Predicates are a generic tool and can change the route matching behavior. Predicates can be chained using the double ampersand operator && . Example route with a Host, Method and Path match predicates and a backend: all : Host (/^ my - host - header \\. example \\. org$ /) && Method(\"GET\") && Path(\"/hello\") -> \"http://127.0.0.1:1234/ \" ; Path \u00b6 The route definitions may contain a single path condition, optionally with wildcards, used for looking up routes in the lookup tree. Parameters: Path (string) can contain a wildcard * or a named :wildcard Examples: Path(\"/foo/bar\") Path(\"/foo/:bar\") Path(\"/foo*\") Path(\"/foo/*\") Path(\"/foo/**\") PathSubtree \u00b6 Similar to Path, but used to match full subtrees including the path of the definition. PathSubtree(\u201c/foo\u201d) predicate is equivalent to having routes with Path(\u201c/foo\u201d), Path(\u201c/foo/\u201d) and Path(\u201c/foo/**\u201d) predicates. Parameters: PathSubtree (string) Examples: PathSubtree(\"/foo/bar\") PathSubtree(\"/\") PathSubtree(\"/foo*\") PathRegexp \u00b6 Regular expressions to match the path. It uses Go\u2019s standard library regexp package to match, which is based on re2 regular expression syntax . Parameters: PathRegexp (regex) Examples: PathRegexp(\"^/foo/bar\") PathRegexp(\"/foo/bar$\") PathRegexp(\"/foo/bar/\") PathRegexp(\"^/foo/(bar|qux)\") Host \u00b6 Regular expressions that the host header in the request must match. Parameters: Host (regex) Examples: Host(/^my-host-header\\.example\\.org$/) Host(/header\\.example\\.org$/) Method \u00b6 The HTTP method that the request must match. HTTP methods are one of GET, HEAD, PATCH, POST, PUT, DELETE, OPTIONS, CONNECT. Parameters: Method (string) Examples: Method(\"GET\") Method(\"OPTIONS\") Header \u00b6 A header key and exact value that must be present in the request. Note that Header(\u201cKey\u201d, \u201cValue\u201d) is equivalent to HeaderRegexp(\u201cKey\u201d, \u201c^Value$\u201d). Parameters: Header (string, string) Examples: Header(\"X-Forwarded-For\", \"192.168.0.2\") Header(\"Accept\", \"application/json\") HeaderRegexp \u00b6 A header key and a regular expression, where the key must be present in the request and one of the associated values must match the expression. Parameters: HeaderRegexp (string, regex) Examples: HeaderRegexp(\"X-Forwarded-For\", \"^192\\.168\\.0\\.[0-2]?[0-9]?[0-9] \") HeaderRegexp(\"Accept\", \"application/(json|xml)\") Cookie \u00b6 Matches if the specified cookie is set in the request. Parameters: Cookie (string, regex) name and value match Examples: Cookie(\"alpha\", /^enabled$/) Auth \u00b6 Authorization header based match. JWTPayloadAnyKV \u00b6 Match the route if at least one of the base64 decoded JWT content matches the key value configuration. Parameters: Key-Value pairs (\u2026string), odd index is the key of the JWT content and even index is the value of the JWT content Examples: JWTPayloadAnyKV(\"iss\", \"https://accounts.google.com\") JWTPayloadAnyKV(\"iss\", \"https://accounts.google.com\", \"email\", \"skipper-router@googlegroups.com\") JWTPayloadAllKV \u00b6 Match the route if all of the base64 decoded JWT content matches the key value configuration. Parameters: Key-Value pairs (\u2026string), odd index is the key of the JWT content and even index is the value of the JWT content Examples: JWTPayloadAllKV(\"iss\", \"https://accounts.google.com\") JWTPayloadAllKV(\"iss\", \"https://accounts.google.com\", \"email\", \"skipper-router@googlegroups.com\") Interval \u00b6 An interval implements custom predicates to match routes only during some period of time. There are three predicates: Between, Before and After. All predicates can be created using the date represented as a string in RFC3339 format (see https://golang.org/pkg/time/#pkg-constants ), int64 or float64 number. float64 number will be converted into int64 number. After \u00b6 Matches if the request is after the specified time Parameters: After (string) date string After (int) unixtime Examples: After(\"2016-01-01T12:00:00+02:00\") After(1451642400) Before \u00b6 Matches if the request is before the specified time Parameters: Before (string) date string Before (int) unixtime Examples: Before(\"2016-01-01T12:00:00+02:00\") Before(1451642400) Between \u00b6 Matches if the request is between the specified timeframe Parameters: Between (string, string) date string, from - till Between (int, int) unixtime, from - till Examples: Between(\"2016-01-01T12:00:00+02:00\", \"2016-02-01T12:00:00+02:00\") Between(1451642400, 1454320800) QueryParam \u00b6 Match request based on the Query Params in URL Parameters: QueryParam (string) name QueryParam (string, regex) name and value match Examples: // matches http://example.org?bb=a&query=withvalue QueryParam(\"query\") // Even a query param without a value // matches http://example.org?bb=a&query= QueryParam(\"query\") // matches with regexp // matches http://example.org?bb=a&query=example QueryParam(\"query\", \"^example$\") // matches with regexp and multiple values of query param // matches http://example.org?bb=a&query=testing&query=example QueryParam(\"query\", \"^example$\") Source \u00b6 Source implements a custom predicate to match routes based on the source IP or X-Forwarded-For header of a request. Parameters: Source (string, ..) varargs with IPs or CIDR Examples: // only match requests from 1.2.3.4 Source(\"1.2.3.4\") // only match requests from 1.2.3.0 - 1.2.3.255 Source(\"1.2.3.0/24\") // only match requests from 1.2.3.4 and the 2.2.2.0/24 network Source(\"1.2.3.4\", \"2.2.2.0/24\") SourceFromLast \u00b6 The same as Source , but use the last part of the X-Forwarded-For header to match the network. This seems to be only used in the popular loadbalancers from AWS, ELB and ALB, because they put the client-IP as last part of the X-Forwarded-For headers. Parameters: SourceFromLast (string, ..) varargs with IPs or CIDR Examples: SourceFromLast(\"1.2.3.4\", \"2.2.2.0/24\") Traffic \u00b6 Traffic implements a predicate to control the matching probability for a given route by setting its weight. The probability for matching a route is defined by the mandatory first parameter, that must be a decimal number between 0.0 and 1.0 (both exclusive). The optional second argument is used to specify the cookie name for the traffic group, in case you want to use stickiness. Stickiness allows all subsequent requests from the same client to match the same route. Stickiness of traffic is supported by the optional third parameter, indicating whether the request being matched belongs to the traffic group of the current route. If yes, the predicate matches ignoring the chance argument. Parameters: Traffic (decimal) valid values [0.0, 1.0] Traffic (decimal, string, string) session stickyness Examples: non-sticky: // hit by 10 % percent chance v2 : Traffic ( . 1 ) - > \"https://api-test-green\" ; // hit by remaining chance v1 : \"https://api-test-blue\" ; stickyness: // hit by 5 % percent chance cartTest : Traffic ( . 05 , \"cart-test\" , \"test\" ) && Path ( \"/cart\" ) - > responseCookie ( \"cart-test\" , \"test\" ) - > \"https://cart-test\" ; // hit by remaining chance cart : Path ( \"/cart\" ) - > responseCookie ( \"cart-test\" , \"default\" ) - > \"https://cart\" ; // hit by 15 % percent chance catalogTestA : Traffic ( . 15 , \"catalog-test\" , \"A\" ) - > responseCookie ( \"catalog-test\" , \"A\" ) - > \"https://catalog-test-a\" ; // hit by 30 % percent chance catalogTestB : Traffic ( . 3 , \"catalog-test\" , \"B\" ) - > responseCookie ( \"catalog-test\" , \"B\" ) - > \"https://catalog-test-b\" ; // hit by remaining chance catalog : * - > responseCookie ( \"catalog-test\" , \"default\" ) - > \"https://catalog\" ;","title":"Predicates"},{"location":"reference/predicates/#skipper-predicates","text":"The parameters can be strings, regex or float64 / int string is a string surrounded by double quotes ( \" ) regex is a re2 regular expression , surrounded by / , e.g. /^www\\.example\\.org(:\\d+)?$/ int / float64 are usual (decimal) numbers like 401 or 1.23456 time is a string in double quotes, parseable by time.Duration ) Predicates are a generic tool and can change the route matching behavior. Predicates can be chained using the double ampersand operator && . Example route with a Host, Method and Path match predicates and a backend: all : Host (/^ my - host - header \\. example \\. org$ /) && Method(\"GET\") && Path(\"/hello\") -> \"http://127.0.0.1:1234/ \" ;","title":"Skipper Predicates"},{"location":"reference/predicates/#path","text":"The route definitions may contain a single path condition, optionally with wildcards, used for looking up routes in the lookup tree. Parameters: Path (string) can contain a wildcard * or a named :wildcard Examples: Path(\"/foo/bar\") Path(\"/foo/:bar\") Path(\"/foo*\") Path(\"/foo/*\") Path(\"/foo/**\")","title":"Path"},{"location":"reference/predicates/#pathsubtree","text":"Similar to Path, but used to match full subtrees including the path of the definition. PathSubtree(\u201c/foo\u201d) predicate is equivalent to having routes with Path(\u201c/foo\u201d), Path(\u201c/foo/\u201d) and Path(\u201c/foo/**\u201d) predicates. Parameters: PathSubtree (string) Examples: PathSubtree(\"/foo/bar\") PathSubtree(\"/\") PathSubtree(\"/foo*\")","title":"PathSubtree"},{"location":"reference/predicates/#pathregexp","text":"Regular expressions to match the path. It uses Go\u2019s standard library regexp package to match, which is based on re2 regular expression syntax . Parameters: PathRegexp (regex) Examples: PathRegexp(\"^/foo/bar\") PathRegexp(\"/foo/bar$\") PathRegexp(\"/foo/bar/\") PathRegexp(\"^/foo/(bar|qux)\")","title":"PathRegexp"},{"location":"reference/predicates/#host","text":"Regular expressions that the host header in the request must match. Parameters: Host (regex) Examples: Host(/^my-host-header\\.example\\.org$/) Host(/header\\.example\\.org$/)","title":"Host"},{"location":"reference/predicates/#method","text":"The HTTP method that the request must match. HTTP methods are one of GET, HEAD, PATCH, POST, PUT, DELETE, OPTIONS, CONNECT. Parameters: Method (string) Examples: Method(\"GET\") Method(\"OPTIONS\")","title":"Method"},{"location":"reference/predicates/#header","text":"A header key and exact value that must be present in the request. Note that Header(\u201cKey\u201d, \u201cValue\u201d) is equivalent to HeaderRegexp(\u201cKey\u201d, \u201c^Value$\u201d). Parameters: Header (string, string) Examples: Header(\"X-Forwarded-For\", \"192.168.0.2\") Header(\"Accept\", \"application/json\")","title":"Header"},{"location":"reference/predicates/#headerregexp","text":"A header key and a regular expression, where the key must be present in the request and one of the associated values must match the expression. Parameters: HeaderRegexp (string, regex) Examples: HeaderRegexp(\"X-Forwarded-For\", \"^192\\.168\\.0\\.[0-2]?[0-9]?[0-9] \") HeaderRegexp(\"Accept\", \"application/(json|xml)\")","title":"HeaderRegexp"},{"location":"reference/predicates/#cookie","text":"Matches if the specified cookie is set in the request. Parameters: Cookie (string, regex) name and value match Examples: Cookie(\"alpha\", /^enabled$/)","title":"Cookie"},{"location":"reference/predicates/#auth","text":"Authorization header based match.","title":"Auth"},{"location":"reference/predicates/#jwtpayloadanykv","text":"Match the route if at least one of the base64 decoded JWT content matches the key value configuration. Parameters: Key-Value pairs (\u2026string), odd index is the key of the JWT content and even index is the value of the JWT content Examples: JWTPayloadAnyKV(\"iss\", \"https://accounts.google.com\") JWTPayloadAnyKV(\"iss\", \"https://accounts.google.com\", \"email\", \"skipper-router@googlegroups.com\")","title":"JWTPayloadAnyKV"},{"location":"reference/predicates/#jwtpayloadallkv","text":"Match the route if all of the base64 decoded JWT content matches the key value configuration. Parameters: Key-Value pairs (\u2026string), odd index is the key of the JWT content and even index is the value of the JWT content Examples: JWTPayloadAllKV(\"iss\", \"https://accounts.google.com\") JWTPayloadAllKV(\"iss\", \"https://accounts.google.com\", \"email\", \"skipper-router@googlegroups.com\")","title":"JWTPayloadAllKV"},{"location":"reference/predicates/#interval","text":"An interval implements custom predicates to match routes only during some period of time. There are three predicates: Between, Before and After. All predicates can be created using the date represented as a string in RFC3339 format (see https://golang.org/pkg/time/#pkg-constants ), int64 or float64 number. float64 number will be converted into int64 number.","title":"Interval"},{"location":"reference/predicates/#after","text":"Matches if the request is after the specified time Parameters: After (string) date string After (int) unixtime Examples: After(\"2016-01-01T12:00:00+02:00\") After(1451642400)","title":"After"},{"location":"reference/predicates/#before","text":"Matches if the request is before the specified time Parameters: Before (string) date string Before (int) unixtime Examples: Before(\"2016-01-01T12:00:00+02:00\") Before(1451642400)","title":"Before"},{"location":"reference/predicates/#between","text":"Matches if the request is between the specified timeframe Parameters: Between (string, string) date string, from - till Between (int, int) unixtime, from - till Examples: Between(\"2016-01-01T12:00:00+02:00\", \"2016-02-01T12:00:00+02:00\") Between(1451642400, 1454320800)","title":"Between"},{"location":"reference/predicates/#queryparam","text":"Match request based on the Query Params in URL Parameters: QueryParam (string) name QueryParam (string, regex) name and value match Examples: // matches http://example.org?bb=a&query=withvalue QueryParam(\"query\") // Even a query param without a value // matches http://example.org?bb=a&query= QueryParam(\"query\") // matches with regexp // matches http://example.org?bb=a&query=example QueryParam(\"query\", \"^example$\") // matches with regexp and multiple values of query param // matches http://example.org?bb=a&query=testing&query=example QueryParam(\"query\", \"^example$\")","title":"QueryParam"},{"location":"reference/predicates/#source","text":"Source implements a custom predicate to match routes based on the source IP or X-Forwarded-For header of a request. Parameters: Source (string, ..) varargs with IPs or CIDR Examples: // only match requests from 1.2.3.4 Source(\"1.2.3.4\") // only match requests from 1.2.3.0 - 1.2.3.255 Source(\"1.2.3.0/24\") // only match requests from 1.2.3.4 and the 2.2.2.0/24 network Source(\"1.2.3.4\", \"2.2.2.0/24\")","title":"Source"},{"location":"reference/predicates/#sourcefromlast","text":"The same as Source , but use the last part of the X-Forwarded-For header to match the network. This seems to be only used in the popular loadbalancers from AWS, ELB and ALB, because they put the client-IP as last part of the X-Forwarded-For headers. Parameters: SourceFromLast (string, ..) varargs with IPs or CIDR Examples: SourceFromLast(\"1.2.3.4\", \"2.2.2.0/24\")","title":"SourceFromLast"},{"location":"reference/predicates/#traffic","text":"Traffic implements a predicate to control the matching probability for a given route by setting its weight. The probability for matching a route is defined by the mandatory first parameter, that must be a decimal number between 0.0 and 1.0 (both exclusive). The optional second argument is used to specify the cookie name for the traffic group, in case you want to use stickiness. Stickiness allows all subsequent requests from the same client to match the same route. Stickiness of traffic is supported by the optional third parameter, indicating whether the request being matched belongs to the traffic group of the current route. If yes, the predicate matches ignoring the chance argument. Parameters: Traffic (decimal) valid values [0.0, 1.0] Traffic (decimal, string, string) session stickyness Examples: non-sticky: // hit by 10 % percent chance v2 : Traffic ( . 1 ) - > \"https://api-test-green\" ; // hit by remaining chance v1 : \"https://api-test-blue\" ; stickyness: // hit by 5 % percent chance cartTest : Traffic ( . 05 , \"cart-test\" , \"test\" ) && Path ( \"/cart\" ) - > responseCookie ( \"cart-test\" , \"test\" ) - > \"https://cart-test\" ; // hit by remaining chance cart : Path ( \"/cart\" ) - > responseCookie ( \"cart-test\" , \"default\" ) - > \"https://cart\" ; // hit by 15 % percent chance catalogTestA : Traffic ( . 15 , \"catalog-test\" , \"A\" ) - > responseCookie ( \"catalog-test\" , \"A\" ) - > \"https://catalog-test-a\" ; // hit by 30 % percent chance catalogTestB : Traffic ( . 3 , \"catalog-test\" , \"B\" ) - > responseCookie ( \"catalog-test\" , \"B\" ) - > \"https://catalog-test-b\" ; // hit by remaining chance catalog : * - > responseCookie ( \"catalog-test\" , \"default\" ) - > \"https://catalog\" ;","title":"Traffic"},{"location":"reference/scripts/","text":"Lua filter scripts \u00b6 LUA scripts can be used as filters in skipper. The current implementation supports Lua 5.1 . Route filters \u00b6 The lua scripts can be added to a route description with the lua() filter, the first parameter for the filter is the script. This can be either a file name (ending with .lua ) or inline code, e.g. as file lua(\"/path/to/file.lua\") - if a file path is not absolute, the path is relative to skipper\u2019s working directory. inline lua(\"function request(c, p); print(c.request.url); end\") Any other additional parameters for the filter must be key=value strings. These will be passed as table to the called functions as second parameter. NOTE : Any parameter starting with \u201clua-\u201d should not be used to pass values for the script - those will be used for configuring the filter. Script requirements \u00b6 A filter script needs at least one global function: request or response . If present, they are called with a skipper filter context and the params passed in the route as table like -- route looks like -- -- any: * -> lua(\"./test.lua\", \"myparam=foo\", \"other=bar\") -> <shunt> -- function request ( ctx , params ) print ( ctx . request . method .. \" \" .. ctx . request . url .. \" -> \" .. params . myparam ) end Available lua modules \u00b6 Besides the standard modules - except for debug - the following modules have been preloaded and can be used with e.g. local http = require(\"http\") , see also the examples below http gluahttp - TODO: configurable with something different than &http.Client{} url gluaurl json gopher-json base64 lua base64 For differences between the standard modules and the gopher-lua implementation check the gopher-lua documentation . Any other module can be loaded in non-byte code form from the lua path (by default for require(\"mod\") this is ./mod.lua , /usr/local/share/lua/5.1/mod.lua and /usr/local/share/lua/5.1/mod/init.lua ). Lua states \u00b6 There is no guarantee that the request() and response() functions of a lua script run in the same lua state during one request. Setting a variable in the request and accessing it in the response will most likely fail and lead to hard debuggable errors. Use the ctx.state_bag to propagate values from request to response - and any other filter in the chain. Request \u00b6 The request() function is run for an incoming request. Headers \u00b6 Request headers can be accessed by accessing the ctx.request.header map like ua = ctx . request . header [ \"user-agent\" ] Header names are normalized by the net/http go module like usual . Setting a header is done by assigning to the headers map. Setting a header to nil or an empty string deletes the header - setting to nil is preferred. ctx . request . header [ \"user-agent\" ] = \"skipper.lua/0.0.1\" ctx . request . header [ \"Authorization\" ] = nil -- delete authorization header Response headers work the same way by accessing / assigning to ctx.response.header - this is of course only valid in the response() phase. Other request fields \u00b6 backend_url - (read only) returns the backend url specified in the route or an empty value in case it\u2019s a shunt or loopback outgoing_host - (read/write) the host that will be set for the outgoing proxy request as the \u2018Host\u2019 header. remote_addr - (read only) the remote host, usually IP:port content_length - (read only) content length proto - (read only) something like \u201cHTTP/1.1\u201d method - (read only) request method, e.g. \u201cGET\u201d or \u201cPOST\u201d url - (read/write) request URL as string Serving requests from lua \u00b6 Requests can be served with ctx.serve(table) , you must return after this call. Possible keys for the table: status_code (number) - required (but currently not enforced) header (table) body (string) See also redirect and internal server error examples below StateBag \u00b6 The state bag can be used to pass values from one filter to another in the same chain. It is shared by all filters in one request. function request ( ctx , params ) -- the value of \"mykey\" will be available to all filters in the chain now: ctx . state_bag [ \"mykey\" ] = \"foo\" end function response ( ctx , params ) print ( ctx . state_bag [ \"mykey\" ]) end Examples \u00b6 Note: the examples serve as examples. If there is a go based plugin available, use that instead. The overhead of calling lua is 4-5 times slower than pure go. OAuth2 token as basic auth password \u00b6 local base64 = require ( \"base64\" ) function request ( ctx , params ) token = string.gsub ( ctx . request . header [ \"Authorization\" ], \"^%s*[Bb]earer%s+\" , \"\" , 1 ) user = ctx . request . header [ \"x-username\" ] if user == \"\" then user = params . username end ctx . request . header [ \"Authorization\" ] = \"Basic \" .. base64 . encode ( user .. \":\" .. token ) -- print(ctx.request.header[\"Authorization\"]) end validate token \u00b6 local http = require ( \"http\" ) function request ( ctx , params ) token = string.gsub ( ctx . request . header [ \"Authorization\" ], \"^%s*[Bb]earer%s+\" , \"\" , 1 ) if token == \"\" then ctx . serve ({ status_code = 401 , body = \"Missing Token\" }) return end res , err = http . get ( \"https://auth.example.com/oauth2/tokeninfo?access_token=\" .. token ) if err ~= nil then print ( \"Failed to get tokeninfo: \" .. err ) ctx . serve ({ status_code = 401 , body = \"Failed to validate token: \" .. err }) return end if res . status_code ~= 200 then ctx . serve ({ status_code = 401 , body = \"Invalid token\" }) return end end strip query \u00b6 function request ( ctx , params ) ctx . request . url = string.gsub ( ctx . request . url , \"%?.*$\" , \"\" ) -- print(\"URL=\"..ctx.request.url) end redirect \u00b6 function request ( ctx , params ) ctx . serve ({ status_code = 302 , header = { location = \"http://www.example.org/\" , }, }) end internal server error \u00b6 function request ( ctx , params ) -- let 10% of all requests fail with 500 if math.random () < 0.1 then ctx . serve ({ status_code = 500 , body = \"Internal Server Error. \\n \" , }) end end Benchmark \u00b6 redirectTo vs lua redirect \u00b6 See skptesting/benchmark-lua.sh Route for \u201cskipper\u201d is * -> redirectTo(\"http://localhost:9980\") -> <shunt> , route for \u201clua\u201d is * -> lua(\"function request(c,p); c.serve({status_code=302, header={location='http://localhost:9980'}});end\") -> <shunt> [benchmarking skipper] Running 12s test @ http://127.0.0.1:9990/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 6.75ms 14.22ms 260.28ms 92.19% Req/Sec 23.87k 2.93k 32.22k 70.42% 572695 requests in 12.06s, 100.49MB read Non-2xx or 3xx responses: 572695 Requests/sec: 47474.31 Transfer/sec: 8.33MB [benchmarking skipper done] [benchmarking lua] Running 12s test @ http://127.0.0.1:9991/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 38.31ms 53.48ms 580.80ms 83.69% Req/Sec 5.44k 1.03k 8.23k 71.25% 130123 requests in 12.01s, 20.97MB read Requests/sec: 10831.94 Transfer/sec: 1.75MB [benchmarking lua done] The benchmark was run with the default pool size of script.InitialPoolSize = 3; script.MaxPoolSize = 10 . With script.InitialPoolSize = 128; script.MaxPoolSize = 128 (tweaked for this benchmark) you get about 12k req/s in lua. Similar results are achieved when testing stripQuery() vs the lua version from above.","title":"Scripts"},{"location":"reference/scripts/#lua-filter-scripts","text":"LUA scripts can be used as filters in skipper. The current implementation supports Lua 5.1 .","title":"Lua filter scripts"},{"location":"reference/scripts/#route-filters","text":"The lua scripts can be added to a route description with the lua() filter, the first parameter for the filter is the script. This can be either a file name (ending with .lua ) or inline code, e.g. as file lua(\"/path/to/file.lua\") - if a file path is not absolute, the path is relative to skipper\u2019s working directory. inline lua(\"function request(c, p); print(c.request.url); end\") Any other additional parameters for the filter must be key=value strings. These will be passed as table to the called functions as second parameter. NOTE : Any parameter starting with \u201clua-\u201d should not be used to pass values for the script - those will be used for configuring the filter.","title":"Route filters"},{"location":"reference/scripts/#script-requirements","text":"A filter script needs at least one global function: request or response . If present, they are called with a skipper filter context and the params passed in the route as table like -- route looks like -- -- any: * -> lua(\"./test.lua\", \"myparam=foo\", \"other=bar\") -> <shunt> -- function request ( ctx , params ) print ( ctx . request . method .. \" \" .. ctx . request . url .. \" -> \" .. params . myparam ) end","title":"Script requirements"},{"location":"reference/scripts/#available-lua-modules","text":"Besides the standard modules - except for debug - the following modules have been preloaded and can be used with e.g. local http = require(\"http\") , see also the examples below http gluahttp - TODO: configurable with something different than &http.Client{} url gluaurl json gopher-json base64 lua base64 For differences between the standard modules and the gopher-lua implementation check the gopher-lua documentation . Any other module can be loaded in non-byte code form from the lua path (by default for require(\"mod\") this is ./mod.lua , /usr/local/share/lua/5.1/mod.lua and /usr/local/share/lua/5.1/mod/init.lua ).","title":"Available lua modules"},{"location":"reference/scripts/#lua-states","text":"There is no guarantee that the request() and response() functions of a lua script run in the same lua state during one request. Setting a variable in the request and accessing it in the response will most likely fail and lead to hard debuggable errors. Use the ctx.state_bag to propagate values from request to response - and any other filter in the chain.","title":"Lua states"},{"location":"reference/scripts/#request","text":"The request() function is run for an incoming request.","title":"Request"},{"location":"reference/scripts/#headers","text":"Request headers can be accessed by accessing the ctx.request.header map like ua = ctx . request . header [ \"user-agent\" ] Header names are normalized by the net/http go module like usual . Setting a header is done by assigning to the headers map. Setting a header to nil or an empty string deletes the header - setting to nil is preferred. ctx . request . header [ \"user-agent\" ] = \"skipper.lua/0.0.1\" ctx . request . header [ \"Authorization\" ] = nil -- delete authorization header Response headers work the same way by accessing / assigning to ctx.response.header - this is of course only valid in the response() phase.","title":"Headers"},{"location":"reference/scripts/#other-request-fields","text":"backend_url - (read only) returns the backend url specified in the route or an empty value in case it\u2019s a shunt or loopback outgoing_host - (read/write) the host that will be set for the outgoing proxy request as the \u2018Host\u2019 header. remote_addr - (read only) the remote host, usually IP:port content_length - (read only) content length proto - (read only) something like \u201cHTTP/1.1\u201d method - (read only) request method, e.g. \u201cGET\u201d or \u201cPOST\u201d url - (read/write) request URL as string","title":"Other request fields"},{"location":"reference/scripts/#serving-requests-from-lua","text":"Requests can be served with ctx.serve(table) , you must return after this call. Possible keys for the table: status_code (number) - required (but currently not enforced) header (table) body (string) See also redirect and internal server error examples below","title":"Serving requests from lua"},{"location":"reference/scripts/#statebag","text":"The state bag can be used to pass values from one filter to another in the same chain. It is shared by all filters in one request. function request ( ctx , params ) -- the value of \"mykey\" will be available to all filters in the chain now: ctx . state_bag [ \"mykey\" ] = \"foo\" end function response ( ctx , params ) print ( ctx . state_bag [ \"mykey\" ]) end","title":"StateBag"},{"location":"reference/scripts/#examples","text":"Note: the examples serve as examples. If there is a go based plugin available, use that instead. The overhead of calling lua is 4-5 times slower than pure go.","title":"Examples"},{"location":"reference/scripts/#oauth2-token-as-basic-auth-password","text":"local base64 = require ( \"base64\" ) function request ( ctx , params ) token = string.gsub ( ctx . request . header [ \"Authorization\" ], \"^%s*[Bb]earer%s+\" , \"\" , 1 ) user = ctx . request . header [ \"x-username\" ] if user == \"\" then user = params . username end ctx . request . header [ \"Authorization\" ] = \"Basic \" .. base64 . encode ( user .. \":\" .. token ) -- print(ctx.request.header[\"Authorization\"]) end","title":"OAuth2 token as basic auth password"},{"location":"reference/scripts/#validate-token","text":"local http = require ( \"http\" ) function request ( ctx , params ) token = string.gsub ( ctx . request . header [ \"Authorization\" ], \"^%s*[Bb]earer%s+\" , \"\" , 1 ) if token == \"\" then ctx . serve ({ status_code = 401 , body = \"Missing Token\" }) return end res , err = http . get ( \"https://auth.example.com/oauth2/tokeninfo?access_token=\" .. token ) if err ~= nil then print ( \"Failed to get tokeninfo: \" .. err ) ctx . serve ({ status_code = 401 , body = \"Failed to validate token: \" .. err }) return end if res . status_code ~= 200 then ctx . serve ({ status_code = 401 , body = \"Invalid token\" }) return end end","title":"validate token"},{"location":"reference/scripts/#strip-query","text":"function request ( ctx , params ) ctx . request . url = string.gsub ( ctx . request . url , \"%?.*$\" , \"\" ) -- print(\"URL=\"..ctx.request.url) end","title":"strip query"},{"location":"reference/scripts/#redirect","text":"function request ( ctx , params ) ctx . serve ({ status_code = 302 , header = { location = \"http://www.example.org/\" , }, }) end","title":"redirect"},{"location":"reference/scripts/#internal-server-error","text":"function request ( ctx , params ) -- let 10% of all requests fail with 500 if math.random () < 0.1 then ctx . serve ({ status_code = 500 , body = \"Internal Server Error. \\n \" , }) end end","title":"internal server error"},{"location":"reference/scripts/#benchmark","text":"","title":"Benchmark"},{"location":"reference/scripts/#redirectto-vs-lua-redirect","text":"See skptesting/benchmark-lua.sh Route for \u201cskipper\u201d is * -> redirectTo(\"http://localhost:9980\") -> <shunt> , route for \u201clua\u201d is * -> lua(\"function request(c,p); c.serve({status_code=302, header={location='http://localhost:9980'}});end\") -> <shunt> [benchmarking skipper] Running 12s test @ http://127.0.0.1:9990/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 6.75ms 14.22ms 260.28ms 92.19% Req/Sec 23.87k 2.93k 32.22k 70.42% 572695 requests in 12.06s, 100.49MB read Non-2xx or 3xx responses: 572695 Requests/sec: 47474.31 Transfer/sec: 8.33MB [benchmarking skipper done] [benchmarking lua] Running 12s test @ http://127.0.0.1:9991/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 38.31ms 53.48ms 580.80ms 83.69% Req/Sec 5.44k 1.03k 8.23k 71.25% 130123 requests in 12.01s, 20.97MB read Requests/sec: 10831.94 Transfer/sec: 1.75MB [benchmarking lua done] The benchmark was run with the default pool size of script.InitialPoolSize = 3; script.MaxPoolSize = 10 . With script.InitialPoolSize = 128; script.MaxPoolSize = 128 (tweaked for this benchmark) you get about 12k req/s in lua. Similar results are achieved when testing stripQuery() vs the lua version from above.","title":"redirectTo vs lua redirect"},{"location":"tutorials/auth/","text":"Basic auth \u00b6 Basic Auth is defined in RFC7617 . Install htpasswd command line tool, we assume Debian based system. Please refer the documentation of your Operating System or package management vendor how to install htpasswd : apt-get install apache2-utils Create a htpasswd file foo.passwd and use captain with password apassword : htpasswd -bcB foo.passwd captain apassword Start skipper with a basicAuth filter referencing the just created htpasswd file: ./bin/skipper -address :8080 -inline-routes 'r: * -> basicAuth(\"foo.passwd\") -> status(200) -> <shunt>' A client request without login credentials or wrong credentials: % curl localhost:8080/ -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 401 Unauthorized < Server : Skipper < Www - Authenticate : Basic realm = \" Basic Realm \" < Date : Thu , 01 Nov 2018 21 : 27 : 18 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact A client request with the correct credentials: % curl captain:apassword@localhost:8080/ -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) * Server auth using Basic with user 'captain' > GET / HTTP / 1.1 > Host : localhost : 8080 > Authorization : Basic Y2FwdGFpbjphcGFzc3dvcmQ = > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 200 OK < Server : Skipper < Date : Thu , 01 Nov 2018 21 : 29 : 21 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact Token service-to-service \u00b6 Service to service authentication and authorization is often done by using the HTTP Authorization header with the content prefix \u201cBearer \u201c, for example \u201cAuthorization: Bearer mytoken\u201d. Supported token formats OAuth2 access tokens JWT Tokeninfo \u00b6 Tokeninfo is a common, but not specified protocol, only supporting Bearer tokens in the Authorization header. In most cases you would have to have your own OAuth2 token infrastructure, that can return JWT or OAuth2 access tokens to authenticated parties and validate tokens with their custom tokeninfo endpoint. In case of JWT the access token is signed and can be validated without a central tokeninfo endpoint. Example route: all : Path ( \"/\" ) -> oauthTokeninfoAnyScope ( \"read-X\" , \"readwrite-X\" ) -> \"http://localhost:9090/\" The access token should be passed from the client as Bearer token in the Authorization header. Skipper will send this token unchanged as Bearer token in the Authorization header to the Tokeninfo endpoint. The request flow with a Tokeninfo setup is shown in the following picture: Tokenintrospection RFC7662 \u00b6 Tokenintrospection service to service authentication and authorization is specified by RFC7662 . Skipper uses RFC Draft for discovering token infrastructure configuration , to find the introspection_endpoint . Example route: all : * - > oauthTokenintrospectionAnyKV ( \"https://identity.example.com/managed-id\" , \"jdoe\" ) - > \"http://localhost:9090/\" ; The access token should be passed from the client as Bearer token in the Authorization header. Skipper will send this token as defined in RFC7662 in a POST request \u201capplication/x-www-form-urlencoded\u201d as value for key token to the Tokenintrospection endpoint. The request flow with Tokenintrospection setup is shown in the following picture: OpenID Connect \u00b6 OpenID Connect is an OAuth2.0 based authentication and authorization mechanism supported by several providers. Skipper can act as a proxy for backend server which requires authenticated clients. Skipper handles the authentication with the provider and upon sucessful completion of authentication passes subsequent requests to the backend server. Skipper\u2019s implementation of OpenID Connect Client works as follows: Filter is initialized with the following parameters: Secrets file with keys used for encrypting the token in a cookie and also for generating shared secret. OpenID Connect Provider URL The Client ID The Client Secret The Callback URL for the client when a user successfully authenticates and is returned. The Scopes to be requested along with the openid scope The claims that should be present in the token or the fields need in the user information. The user makes a request to a backend which is covered by an OpenID filter. Skipper checks if a cookie is set with any previous successfully completed OpenID authentication. If the cookie is valid then Skipper passes the request to the backend. If the cookie is not valid then Skipper redirects the user to the OpenID provider with its Client ID and a callback URL. When the user successfully completes authentication the provider redirects the user to the callback URL with a token. Skipper receives this token and makes a backend channel call to get an ID token and other required information. If all the user information/claims are present then it encrypts this and sets a cookie which is encrypted and redirects the user to the originally requested URL. To use OpenID define a filter for a backend which needs to be covered by OpenID Connection authentication. oauthOidcAllClaims ( \"https://accounts.identity-provider.com\" , \"some-client-id\" , \"some-client-secret\" , \"http://callback.com/auth/provider/callback\" , \"scope1 scope2\" , \"claim1 claim2\" ) - > \"https://internal.example.org\" ; Here scope1 scope2 are the scopes that should be included which requesting authentication from the OpenID provider. Any number of scopes can be specified here. The openid scope is added automatically by the filter. The other fields which need to be specified are the URL of the provider which in the above example is https://accounts.identity-provider.com . The client ID and the client secret. The callback URL which is specified while generating the client id and client secret. Then the scopes and finally the claims which should be present along with the return id token. oauthOIDCUserInfo ( \"https://oidc-provider.example.com\" , \"client_id\" , \"client_secret\" , \"http://target.example.com/subpath/callback\" , \"email profile\" , \"name email picture\" ) - > \"https://internal.example.org\" ; This filter is similar but it verifies that the token has certain user information information fields accesible with the token return by the provider. The fields can be specified at the end like in the example above where the fields name , email and picture are requested. Upon sucessful authentication Skipper will start allowing the user requests through to the backend. Along with the orginal request to the backend Skipper will include information which it obtained from the provider. The information is in JSON format with the header name Skipper-Oidc-Info . In the case of the claims container the header value is in the format. { \"oauth2token\" : \"xxx\" , \"claims\" : { \"claim1\" : \"val1\" , \"claim2\" : \"val2\" }, \"subject\" : \"subj\" } In the case of a user info filter the payload is in the format: { \"oauth2token\" : \"xxx\" , \"userInfo\" : { \"sub\" : \"sub\" , \"profile\" : \"prof\" , \"email\" : \"abc@example.com\" , \"email_verified\" : \"abc@example.com\" }, \"subject\" : \"subj\" } Skipper encrypts the cookies and also generates a nonce during the OAuth2.0 flow for which it needs a secret key. This key is in a file which can be rotated periodically because it is reread by Skipper. The path to this file can be passed with the flag -oidc-secret-file when Skipper is started.","title":"Authentication and Autorization"},{"location":"tutorials/auth/#basic-auth","text":"Basic Auth is defined in RFC7617 . Install htpasswd command line tool, we assume Debian based system. Please refer the documentation of your Operating System or package management vendor how to install htpasswd : apt-get install apache2-utils Create a htpasswd file foo.passwd and use captain with password apassword : htpasswd -bcB foo.passwd captain apassword Start skipper with a basicAuth filter referencing the just created htpasswd file: ./bin/skipper -address :8080 -inline-routes 'r: * -> basicAuth(\"foo.passwd\") -> status(200) -> <shunt>' A client request without login credentials or wrong credentials: % curl localhost:8080/ -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 401 Unauthorized < Server : Skipper < Www - Authenticate : Basic realm = \" Basic Realm \" < Date : Thu , 01 Nov 2018 21 : 27 : 18 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact A client request with the correct credentials: % curl captain:apassword@localhost:8080/ -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) * Server auth using Basic with user 'captain' > GET / HTTP / 1.1 > Host : localhost : 8080 > Authorization : Basic Y2FwdGFpbjphcGFzc3dvcmQ = > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 200 OK < Server : Skipper < Date : Thu , 01 Nov 2018 21 : 29 : 21 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"Basic auth"},{"location":"tutorials/auth/#token-service-to-service","text":"Service to service authentication and authorization is often done by using the HTTP Authorization header with the content prefix \u201cBearer \u201c, for example \u201cAuthorization: Bearer mytoken\u201d. Supported token formats OAuth2 access tokens JWT","title":"Token service-to-service"},{"location":"tutorials/auth/#tokeninfo","text":"Tokeninfo is a common, but not specified protocol, only supporting Bearer tokens in the Authorization header. In most cases you would have to have your own OAuth2 token infrastructure, that can return JWT or OAuth2 access tokens to authenticated parties and validate tokens with their custom tokeninfo endpoint. In case of JWT the access token is signed and can be validated without a central tokeninfo endpoint. Example route: all : Path ( \"/\" ) -> oauthTokeninfoAnyScope ( \"read-X\" , \"readwrite-X\" ) -> \"http://localhost:9090/\" The access token should be passed from the client as Bearer token in the Authorization header. Skipper will send this token unchanged as Bearer token in the Authorization header to the Tokeninfo endpoint. The request flow with a Tokeninfo setup is shown in the following picture:","title":"Tokeninfo"},{"location":"tutorials/auth/#tokenintrospection-rfc7662","text":"Tokenintrospection service to service authentication and authorization is specified by RFC7662 . Skipper uses RFC Draft for discovering token infrastructure configuration , to find the introspection_endpoint . Example route: all : * - > oauthTokenintrospectionAnyKV ( \"https://identity.example.com/managed-id\" , \"jdoe\" ) - > \"http://localhost:9090/\" ; The access token should be passed from the client as Bearer token in the Authorization header. Skipper will send this token as defined in RFC7662 in a POST request \u201capplication/x-www-form-urlencoded\u201d as value for key token to the Tokenintrospection endpoint. The request flow with Tokenintrospection setup is shown in the following picture:","title":"Tokenintrospection RFC7662"},{"location":"tutorials/auth/#openid-connect","text":"OpenID Connect is an OAuth2.0 based authentication and authorization mechanism supported by several providers. Skipper can act as a proxy for backend server which requires authenticated clients. Skipper handles the authentication with the provider and upon sucessful completion of authentication passes subsequent requests to the backend server. Skipper\u2019s implementation of OpenID Connect Client works as follows: Filter is initialized with the following parameters: Secrets file with keys used for encrypting the token in a cookie and also for generating shared secret. OpenID Connect Provider URL The Client ID The Client Secret The Callback URL for the client when a user successfully authenticates and is returned. The Scopes to be requested along with the openid scope The claims that should be present in the token or the fields need in the user information. The user makes a request to a backend which is covered by an OpenID filter. Skipper checks if a cookie is set with any previous successfully completed OpenID authentication. If the cookie is valid then Skipper passes the request to the backend. If the cookie is not valid then Skipper redirects the user to the OpenID provider with its Client ID and a callback URL. When the user successfully completes authentication the provider redirects the user to the callback URL with a token. Skipper receives this token and makes a backend channel call to get an ID token and other required information. If all the user information/claims are present then it encrypts this and sets a cookie which is encrypted and redirects the user to the originally requested URL. To use OpenID define a filter for a backend which needs to be covered by OpenID Connection authentication. oauthOidcAllClaims ( \"https://accounts.identity-provider.com\" , \"some-client-id\" , \"some-client-secret\" , \"http://callback.com/auth/provider/callback\" , \"scope1 scope2\" , \"claim1 claim2\" ) - > \"https://internal.example.org\" ; Here scope1 scope2 are the scopes that should be included which requesting authentication from the OpenID provider. Any number of scopes can be specified here. The openid scope is added automatically by the filter. The other fields which need to be specified are the URL of the provider which in the above example is https://accounts.identity-provider.com . The client ID and the client secret. The callback URL which is specified while generating the client id and client secret. Then the scopes and finally the claims which should be present along with the return id token. oauthOIDCUserInfo ( \"https://oidc-provider.example.com\" , \"client_id\" , \"client_secret\" , \"http://target.example.com/subpath/callback\" , \"email profile\" , \"name email picture\" ) - > \"https://internal.example.org\" ; This filter is similar but it verifies that the token has certain user information information fields accesible with the token return by the provider. The fields can be specified at the end like in the example above where the fields name , email and picture are requested. Upon sucessful authentication Skipper will start allowing the user requests through to the backend. Along with the orginal request to the backend Skipper will include information which it obtained from the provider. The information is in JSON format with the header name Skipper-Oidc-Info . In the case of the claims container the header value is in the format. { \"oauth2token\" : \"xxx\" , \"claims\" : { \"claim1\" : \"val1\" , \"claim2\" : \"val2\" }, \"subject\" : \"subj\" } In the case of a user info filter the payload is in the format: { \"oauth2token\" : \"xxx\" , \"userInfo\" : { \"sub\" : \"sub\" , \"profile\" : \"prof\" , \"email\" : \"abc@example.com\" , \"email_verified\" : \"abc@example.com\" }, \"subject\" : \"subj\" } Skipper encrypts the cookies and also generates a nonce during the OAuth2.0 flow for which it needs a secret key. This key is in a file which can be rotated periodically because it is reread by Skipper. The path to this file can be passed with the flag -oidc-secret-file when Skipper is started.","title":"OpenID Connect"},{"location":"tutorials/basics/","text":"Architecture \u00b6 The core business of skipper is routing based on HTTP. It performs and scales well, for example it handles more than 800000 routes in production with 60000 requests per second. Skipper is written as a library and is also a multi binary project with 2 binaries, named skipper and eskip . Skipper is the HTTP proxy and eskip is a CLI application to verify, print, update or delete Skipper routes. Skipper\u2019s internal architecture is split into different packages. The skipper package has connections to multiple dataclient , that pull information from different sources, for example local routes from an eskip file or dynamic routes from Kubernetes ingress objects. The proxy package gets the routes populated by skipper and has always a current routing table which will be replaced on change. A route is one entry in the routing table. A route consists of one or more predicate , that are used to find a route for a given HTTP request. A route can also have one or more filter , that can modify the content of the request or response. A route can point to a backend, it can be a <shunt> , meaning that skipper serves the requests for the route, a <loopback> , meaning that the requests will be matched against the routing table again after filters have modified them, or a <dynamic> , meaning that the target backend must be set in a filter. Opentracing API is supported via tracers and you can find all of them in ./tracing/tracers/ . For example Jaeger is supported. Skipper has a rich set of metrics that are exposed as json, but can also be exported in Prometheus format. Concepts \u00b6 Route definition \u00b6 A route consists of an ID, predicates, filters and a backend and is most often written in eskip syntax . Syntax: ID : Predicate1 () && .. && PredicateN () -> filter1 () ... -> filterN () -> BACKEND An example routing configuration: baidu : Path ( \"/baidu\" ) -> setRequestHeader ( \"Host\" , \"www.baidu.com\" ) -> setPath ( \"/s\" ) -> setQuery ( \"wd\" , \"godoc skipper\" ) -> \"http://www.baidu.com\" ; google : * -> setPath ( \"/search\" ) -> setQuery ( \"q\" , \"godoc skipper\" ) -> \"https://www.google.com\" ; yandex : * && Cookie ( \"yandex\" , \"true\" ) -> setPath ( \"/search/\" ) -> setQuery ( \"text\" , \"godoc skipper\" ) -> tee ( \"http://127.0.0.1:12345/\" ) -> \"https://yandex.ru\" ; Predicate \u00b6 A Predicate adds a matching rule to a route. For example the Cookie predicate, Cookie(\"yandex\", \"true\") , matched if there is a cookie in the request with name \u201cyandex\u201d and the value is \u201ctrue\u201d, else the route processing will go on and try to find another matching route for the given request. Multiple predicates can be combined by && which means a logical AND . If you need a logical OR , you have to create another route. Special Predicates: * catch all is always true Path() reduces the number of routes in O(log n) time to scan afterwards a subset in linear time PathSubtree() reduces the number of routes O(log n) time to scan afterwards a subset in linear time Predicate and routing table \u00b6 A routing table consists of a number of routes. A route has a list of predicates and filters. Predicates match an incoming request to a specific, best matching, route. Each route has a set of filters. Filter \u00b6 A filter changes a HTTP request or response or both. Multiple filters can be concatenated by -> . Some special filters are: inlineContent() sets the HTTP response body, should be used with status() filter and backend static() serves static files and should be used with backend status() sets HTTP status code to a given value, should be used with backend tee() clones request to given target Filter in context of an HTTP request \u00b6 The picture shows the transformation of the requests and responses Backend \u00b6 The last entry of a route is the backend definition, that will be called with the result request after filter processing. Normally this is an URL string. Special backends: <loopback> restart route processing with the possibly changed request <shunt> stops processing, used for fast returns <dynamic> target is set dynamically in a filter <$algorithm, \"be1\", \"be2\", ..., \"beN\"> load balanced backend with N backends See more about backends in backend references . Dataclient \u00b6 Dataclients are used to pull route information from a data source. The data will be used to create routes according to the dataclient. As a special case, for example kubernetes dataclient automatically adds HTTP->HTTPS redirects if skipper is started with -kubernetes-https-redirect . Dataclients: eskip-file route string kubernetes etcd Route processing \u00b6 Package skipper has a Go http.Server and does the ListenAndServe call with the loggingHandler wrapped proxy . The loggingHandler is basically a middleware for the proxy providing access logs and both implement the plain Go http.Handler interface . For each incoming http.Request the proxy will create a request context and enhance it with an Opentracing API Span. It will check proxy global ratelimits first and after that lookup the route in the routing table. After that skipper will apply all request filters, that can modify the http.Request . It will then check the route local ratelimits, the circuitbreakers and do the backend call. If the backend call got a TCP or TLS connection error in a loadbalanced route, skipper will do a retry to another backend of that loadbalanced group automatically. Just before the response to the caller, skipper will process the response filters, that can change the http.Response . In two special cases, skipper doesn\u2019t forward the request to the backend. When the route is shunted ( <shunt> ), skipper serves the request alone, by using only the filters. When the route is a <loopback> , the request is passed to the routing table for finding another route, based on the changes that the filters made to the request. In case it will always find a <loopback> route it will stop after maximum number of loopbacks is reached and logs an error. Routing mechanism \u00b6 The routing executes the following steps in the typical case: Select the best fitting route by matching the request against the predicates. When no route found, respond with 404 (unless the default status code is configured to a different value). Execute the filters defined in the route in normal order on the request. The filters may or may not alter the request. Forward the request to the backend defined by the route and receive a response. Execute the filters defined in the route in reverse order on the response. The filters may or may not alter the response. Respond to the incoming request with the resulting response. Route matching \u00b6 Skipper can handle a relatively large number of routes with acceptable performance, while being able to use any attribute of the incoming HTTP requests to distinguish between them. In order to be able to do so, the path matching predicates ( Path() and PathSubtree() but not PathRegexp() ) have a special role during route matching, which is a tradeoff by design, and needs to be kept in mind to understand in some cases why a certain route was matched for a request instead of another. The route matching logic can be summed up as follows: Lookup in the path tree based on the Path() and the PathSubtree() predicates, using the path component of the incoming request\u2019s URI. Then the remaining predicates of the found route(s) are evaluated. the path lookup is a radix tree with O(log(n)) time complexity in case of intersecting paths, the more specific path is matched in the tree PathRegexp() is not used in the tree, but it is evaluated only after Path() or PathSubtree() , just like e.g. Method() or Host() . If step #1 matches multiple routes, which means there are multiple routes in the same position of the path tree, and all other predicates match the request, too, then the route with the most defined predicates is matched. this is an O(n) lookup, but only on the same leaf the root of the tree is considered a single leaf, so if not using the Path() or PathSubtree() predicates, the entire lookup will become O(n) over all the routes. If #2 results in multiple matching routes, then one route will be selected. It is unspecified which one. Building skipper \u00b6 We use Go modules to build skipper, therefore you need Go version >= 1.11 . Local build \u00b6 To get a local build of skipper for your CPU architecture, you can run make skipper . To cross compile to non Linux platforms you can use: make build.osx for Mac OS X (amd64) make build.windows for Windows (amd64) The local build will write into ./bin/ directory. CI build \u00b6 The current used CI flow to build the official docker container, you can see in delivery.yaml . Official release versions you will find at registry.opensource.zalan.do/pathfinder/skipper:${RELEASE_VERSION} , where ${RELEASE_VERSION} is the git tag got by $(git describe --tags --always --dirty) . Test versions are released at registry.opensource.zalan.do/pathfinder/skipper-test:${CDP_BUILD_VERSION} for every pull request, limited to only repository members, because of compliance and security reasons. Testing routes \u00b6 To test routes you can use a local build of skipper and pass arguments -inline-routes=<route string> or for more complex ones use a local eskip file on disk and use -routes-file=<filepath> . Example: ./bin/skipper -address :9999 -inline-routes 'r: * -> setQuery(\"lang\", \"pt\") -> \"http://127.0.0.1:8080/\"' Now you have a proxy running that will set a query to your request URL and call http://127.0.0.1:8080/?lang=pt The simplest way of testing a proxy is using a local backend and a local browser. Local backend example: ./bin/skipper -address :8080 -inline-routes 'r: * -> inlineContent(\"Hello world!\") -> status(200) -> <shunt>' If you want to do the request and see the response in detail, you can use curl as a browser, which should be installed on most Linux and Mac OS X computers. Example client call to our defined proxy: % curl localhost:8080 -v * Rebuilt URL to : localhost : 8080 / * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 200 OK < Content - Length : 12 < Content - Type : text / plain ; charset = utf - 8 < Server : Skipper < Date : Thu , 01 Nov 2018 15 : 54 : 13 GMT < * Connection # 0 to host localhost left intact Hello world ! Current routing table \u00b6 To investigate the current routing table skipper has loaded into its memory, you can use the -support-listener , which defaults to port 9911 and you have to do a GET request to the /routes endpoint. Example: % curl localhost:9911/routes r : * -> setQuery ( \" lang \" , \" pt \" ) -> \" http : // 127.0 . 0.1 : 8000 \" ; If you do not see your route, then you have most probably a syntax error in your route definition, such that the route was not loaded into memory. To print the number of routes, X-Count header, and the last update timestamp, X-Timestamp header, you can use a HEAD request to the support listener /routes endpoint: % curl -I localhost:9911/routes HTTP/1.1 200 OK Content-Type: text/plain X-Count: 1 X-Timestamp: 1541086036 Date: Fri, 02 Nov 2018 00 :30:43 GMT For skipper operators the number of routes can be interesting for statistics and the timestamp to detect skipper instances that have not updated its routing table. If there is more than 1024 routes used, then the paging the results is possible with the offset and limit query parameters: curl locahost:9911/routes?offset=2048&limit=512 Route IDs \u00b6 In the following example rid is the route ID: % curl localhost:9911/routes rid : * -> setQuery ( \" lang \" , \" pt \" ) -> \" http : // 127.0 . 0.1 : 8000 \" ; If the route ID has a prefix kube_ , then it is a route created by the Kubernetes dataclient. We do not disallow that you create manually routes with kube_ prefix, but most of the time you should not use it in other routes to differentiate the routes created by other dataclients, in case you use multiple at the same time.","title":"Basics"},{"location":"tutorials/basics/#architecture","text":"The core business of skipper is routing based on HTTP. It performs and scales well, for example it handles more than 800000 routes in production with 60000 requests per second. Skipper is written as a library and is also a multi binary project with 2 binaries, named skipper and eskip . Skipper is the HTTP proxy and eskip is a CLI application to verify, print, update or delete Skipper routes. Skipper\u2019s internal architecture is split into different packages. The skipper package has connections to multiple dataclient , that pull information from different sources, for example local routes from an eskip file or dynamic routes from Kubernetes ingress objects. The proxy package gets the routes populated by skipper and has always a current routing table which will be replaced on change. A route is one entry in the routing table. A route consists of one or more predicate , that are used to find a route for a given HTTP request. A route can also have one or more filter , that can modify the content of the request or response. A route can point to a backend, it can be a <shunt> , meaning that skipper serves the requests for the route, a <loopback> , meaning that the requests will be matched against the routing table again after filters have modified them, or a <dynamic> , meaning that the target backend must be set in a filter. Opentracing API is supported via tracers and you can find all of them in ./tracing/tracers/ . For example Jaeger is supported. Skipper has a rich set of metrics that are exposed as json, but can also be exported in Prometheus format.","title":"Architecture"},{"location":"tutorials/basics/#concepts","text":"","title":"Concepts"},{"location":"tutorials/basics/#route-definition","text":"A route consists of an ID, predicates, filters and a backend and is most often written in eskip syntax . Syntax: ID : Predicate1 () && .. && PredicateN () -> filter1 () ... -> filterN () -> BACKEND An example routing configuration: baidu : Path ( \"/baidu\" ) -> setRequestHeader ( \"Host\" , \"www.baidu.com\" ) -> setPath ( \"/s\" ) -> setQuery ( \"wd\" , \"godoc skipper\" ) -> \"http://www.baidu.com\" ; google : * -> setPath ( \"/search\" ) -> setQuery ( \"q\" , \"godoc skipper\" ) -> \"https://www.google.com\" ; yandex : * && Cookie ( \"yandex\" , \"true\" ) -> setPath ( \"/search/\" ) -> setQuery ( \"text\" , \"godoc skipper\" ) -> tee ( \"http://127.0.0.1:12345/\" ) -> \"https://yandex.ru\" ;","title":"Route definition"},{"location":"tutorials/basics/#predicate","text":"A Predicate adds a matching rule to a route. For example the Cookie predicate, Cookie(\"yandex\", \"true\") , matched if there is a cookie in the request with name \u201cyandex\u201d and the value is \u201ctrue\u201d, else the route processing will go on and try to find another matching route for the given request. Multiple predicates can be combined by && which means a logical AND . If you need a logical OR , you have to create another route. Special Predicates: * catch all is always true Path() reduces the number of routes in O(log n) time to scan afterwards a subset in linear time PathSubtree() reduces the number of routes O(log n) time to scan afterwards a subset in linear time","title":"Predicate"},{"location":"tutorials/basics/#predicate-and-routing-table","text":"A routing table consists of a number of routes. A route has a list of predicates and filters. Predicates match an incoming request to a specific, best matching, route. Each route has a set of filters.","title":"Predicate and routing table"},{"location":"tutorials/basics/#filter","text":"A filter changes a HTTP request or response or both. Multiple filters can be concatenated by -> . Some special filters are: inlineContent() sets the HTTP response body, should be used with status() filter and backend static() serves static files and should be used with backend status() sets HTTP status code to a given value, should be used with backend tee() clones request to given target","title":"Filter"},{"location":"tutorials/basics/#filter-in-context-of-an-http-request","text":"The picture shows the transformation of the requests and responses","title":"Filter in context of an HTTP request"},{"location":"tutorials/basics/#backend","text":"The last entry of a route is the backend definition, that will be called with the result request after filter processing. Normally this is an URL string. Special backends: <loopback> restart route processing with the possibly changed request <shunt> stops processing, used for fast returns <dynamic> target is set dynamically in a filter <$algorithm, \"be1\", \"be2\", ..., \"beN\"> load balanced backend with N backends See more about backends in backend references .","title":"Backend"},{"location":"tutorials/basics/#dataclient","text":"Dataclients are used to pull route information from a data source. The data will be used to create routes according to the dataclient. As a special case, for example kubernetes dataclient automatically adds HTTP->HTTPS redirects if skipper is started with -kubernetes-https-redirect . Dataclients: eskip-file route string kubernetes etcd","title":"Dataclient"},{"location":"tutorials/basics/#route-processing","text":"Package skipper has a Go http.Server and does the ListenAndServe call with the loggingHandler wrapped proxy . The loggingHandler is basically a middleware for the proxy providing access logs and both implement the plain Go http.Handler interface . For each incoming http.Request the proxy will create a request context and enhance it with an Opentracing API Span. It will check proxy global ratelimits first and after that lookup the route in the routing table. After that skipper will apply all request filters, that can modify the http.Request . It will then check the route local ratelimits, the circuitbreakers and do the backend call. If the backend call got a TCP or TLS connection error in a loadbalanced route, skipper will do a retry to another backend of that loadbalanced group automatically. Just before the response to the caller, skipper will process the response filters, that can change the http.Response . In two special cases, skipper doesn\u2019t forward the request to the backend. When the route is shunted ( <shunt> ), skipper serves the request alone, by using only the filters. When the route is a <loopback> , the request is passed to the routing table for finding another route, based on the changes that the filters made to the request. In case it will always find a <loopback> route it will stop after maximum number of loopbacks is reached and logs an error.","title":"Route processing"},{"location":"tutorials/basics/#routing-mechanism","text":"The routing executes the following steps in the typical case: Select the best fitting route by matching the request against the predicates. When no route found, respond with 404 (unless the default status code is configured to a different value). Execute the filters defined in the route in normal order on the request. The filters may or may not alter the request. Forward the request to the backend defined by the route and receive a response. Execute the filters defined in the route in reverse order on the response. The filters may or may not alter the response. Respond to the incoming request with the resulting response.","title":"Routing mechanism"},{"location":"tutorials/basics/#route-matching","text":"Skipper can handle a relatively large number of routes with acceptable performance, while being able to use any attribute of the incoming HTTP requests to distinguish between them. In order to be able to do so, the path matching predicates ( Path() and PathSubtree() but not PathRegexp() ) have a special role during route matching, which is a tradeoff by design, and needs to be kept in mind to understand in some cases why a certain route was matched for a request instead of another. The route matching logic can be summed up as follows: Lookup in the path tree based on the Path() and the PathSubtree() predicates, using the path component of the incoming request\u2019s URI. Then the remaining predicates of the found route(s) are evaluated. the path lookup is a radix tree with O(log(n)) time complexity in case of intersecting paths, the more specific path is matched in the tree PathRegexp() is not used in the tree, but it is evaluated only after Path() or PathSubtree() , just like e.g. Method() or Host() . If step #1 matches multiple routes, which means there are multiple routes in the same position of the path tree, and all other predicates match the request, too, then the route with the most defined predicates is matched. this is an O(n) lookup, but only on the same leaf the root of the tree is considered a single leaf, so if not using the Path() or PathSubtree() predicates, the entire lookup will become O(n) over all the routes. If #2 results in multiple matching routes, then one route will be selected. It is unspecified which one.","title":"Route matching"},{"location":"tutorials/basics/#building-skipper","text":"We use Go modules to build skipper, therefore you need Go version >= 1.11 .","title":"Building skipper"},{"location":"tutorials/basics/#local-build","text":"To get a local build of skipper for your CPU architecture, you can run make skipper . To cross compile to non Linux platforms you can use: make build.osx for Mac OS X (amd64) make build.windows for Windows (amd64) The local build will write into ./bin/ directory.","title":"Local build"},{"location":"tutorials/basics/#ci-build","text":"The current used CI flow to build the official docker container, you can see in delivery.yaml . Official release versions you will find at registry.opensource.zalan.do/pathfinder/skipper:${RELEASE_VERSION} , where ${RELEASE_VERSION} is the git tag got by $(git describe --tags --always --dirty) . Test versions are released at registry.opensource.zalan.do/pathfinder/skipper-test:${CDP_BUILD_VERSION} for every pull request, limited to only repository members, because of compliance and security reasons.","title":"CI build"},{"location":"tutorials/basics/#testing-routes","text":"To test routes you can use a local build of skipper and pass arguments -inline-routes=<route string> or for more complex ones use a local eskip file on disk and use -routes-file=<filepath> . Example: ./bin/skipper -address :9999 -inline-routes 'r: * -> setQuery(\"lang\", \"pt\") -> \"http://127.0.0.1:8080/\"' Now you have a proxy running that will set a query to your request URL and call http://127.0.0.1:8080/?lang=pt The simplest way of testing a proxy is using a local backend and a local browser. Local backend example: ./bin/skipper -address :8080 -inline-routes 'r: * -> inlineContent(\"Hello world!\") -> status(200) -> <shunt>' If you want to do the request and see the response in detail, you can use curl as a browser, which should be installed on most Linux and Mac OS X computers. Example client call to our defined proxy: % curl localhost:8080 -v * Rebuilt URL to : localhost : 8080 / * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 200 OK < Content - Length : 12 < Content - Type : text / plain ; charset = utf - 8 < Server : Skipper < Date : Thu , 01 Nov 2018 15 : 54 : 13 GMT < * Connection # 0 to host localhost left intact Hello world !","title":"Testing routes"},{"location":"tutorials/basics/#current-routing-table","text":"To investigate the current routing table skipper has loaded into its memory, you can use the -support-listener , which defaults to port 9911 and you have to do a GET request to the /routes endpoint. Example: % curl localhost:9911/routes r : * -> setQuery ( \" lang \" , \" pt \" ) -> \" http : // 127.0 . 0.1 : 8000 \" ; If you do not see your route, then you have most probably a syntax error in your route definition, such that the route was not loaded into memory. To print the number of routes, X-Count header, and the last update timestamp, X-Timestamp header, you can use a HEAD request to the support listener /routes endpoint: % curl -I localhost:9911/routes HTTP/1.1 200 OK Content-Type: text/plain X-Count: 1 X-Timestamp: 1541086036 Date: Fri, 02 Nov 2018 00 :30:43 GMT For skipper operators the number of routes can be interesting for statistics and the timestamp to detect skipper instances that have not updated its routing table. If there is more than 1024 routes used, then the paging the results is possible with the offset and limit query parameters: curl locahost:9911/routes?offset=2048&limit=512","title":"Current routing table"},{"location":"tutorials/basics/#route-ids","text":"In the following example rid is the route ID: % curl localhost:9911/routes rid : * -> setQuery ( \" lang \" , \" pt \" ) -> \" http : // 127.0 . 0.1 : 8000 \" ; If the route ID has a prefix kube_ , then it is a route created by the Kubernetes dataclient. We do not disallow that you create manually routes with kube_ prefix, but most of the time you should not use it in other routes to differentiate the routes created by other dataclients, in case you use multiple at the same time.","title":"Route IDs"},{"location":"tutorials/common-use-cases/","text":"Common Use Cases \u00b6 To understand common use cases, we assume you read the basics . Redirect handling \u00b6 If you want to do a redirect from a route, you can use the redirectTo() filter in combination with the <shunt> backend. If you do not specify a path in your redirect, then the path from the client will be passed further and not modified by the redirect. Example: % ./bin/skipper -address :8080 -inline-routes 'r: * -> redirectTo(308, \"http://127.0.0.1:9999\") -> <shunt>' :: 1 - - [ 01 / Nov / 2018 : 18 : 42 : 02 + 0100 ] \" GET / HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - :: 1 - - [ 01 / Nov / 2018 : 18 : 42 : 08 + 0100 ] \" GET / foo HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - % curl localhost:8080 -v * Rebuilt URL to : localhost : 8080 / * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 42 : 18 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / foo < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 42 : 14 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact set absolute path \u00b6 If you set a path, in this example / , in your redirect definition, then the path is set to the chosen value. The Location header is set in the response to / , but the client sent /foo . % ./bin/skipper -address :8080 -inline-routes 'r: * -> redirectTo(308, \"http://127.0.0.1:9999/\") -> <shunt>' % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 47 : 17 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact change base path \u00b6 If you want a redirect definition that adds a base path and the specified path by the client should be appended to this base path you can use the modPath filter just before the redirectTo() to modify the base path as you like. % ./bin/skipper -address :8080 -inline-routes 'r: * -> modPath(\"/\", \"/my/new/base/\") -> redirectTo(308, \"http://127.0.0.1:9999\") -> <shunt>' :: 1 - - [ 01 / Nov / 2018 : 18 : 49 : 45 + 0100 ] \" GET / foo HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / my / new / base / foo < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 49 : 45 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"Common Use Cases"},{"location":"tutorials/common-use-cases/#common-use-cases","text":"To understand common use cases, we assume you read the basics .","title":"Common Use Cases"},{"location":"tutorials/common-use-cases/#redirect-handling","text":"If you want to do a redirect from a route, you can use the redirectTo() filter in combination with the <shunt> backend. If you do not specify a path in your redirect, then the path from the client will be passed further and not modified by the redirect. Example: % ./bin/skipper -address :8080 -inline-routes 'r: * -> redirectTo(308, \"http://127.0.0.1:9999\") -> <shunt>' :: 1 - - [ 01 / Nov / 2018 : 18 : 42 : 02 + 0100 ] \" GET / HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - :: 1 - - [ 01 / Nov / 2018 : 18 : 42 : 08 + 0100 ] \" GET / foo HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - % curl localhost:8080 -v * Rebuilt URL to : localhost : 8080 / * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 42 : 18 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / foo < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 42 : 14 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"Redirect handling"},{"location":"tutorials/common-use-cases/#set-absolute-path","text":"If you set a path, in this example / , in your redirect definition, then the path is set to the chosen value. The Location header is set in the response to / , but the client sent /foo . % ./bin/skipper -address :8080 -inline-routes 'r: * -> redirectTo(308, \"http://127.0.0.1:9999/\") -> <shunt>' % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 47 : 17 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"set absolute path"},{"location":"tutorials/common-use-cases/#change-base-path","text":"If you want a redirect definition that adds a base path and the specified path by the client should be appended to this base path you can use the modPath filter just before the redirectTo() to modify the base path as you like. % ./bin/skipper -address :8080 -inline-routes 'r: * -> modPath(\"/\", \"/my/new/base/\") -> redirectTo(308, \"http://127.0.0.1:9999\") -> <shunt>' :: 1 - - [ 01 / Nov / 2018 : 18 : 49 : 45 + 0100 ] \" GET / foo HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / my / new / base / foo < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 49 : 45 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"change base path"},{"location":"tutorials/development/","text":"Docs \u00b6 We have user documentation and developer documentation separated. In docs/ you find the user documentation in mkdocs format and rendered at https://opensource.zalando.com/skipper . Developer documentation for skipper as library users godoc format is used and rendered at https://godoc.org/github.com/zalando/skipper . User documentation \u00b6 local Preview \u00b6 To see rendered documentation locally you need to replace /skipper path with / to see them correctly. This you can easily do with skipper in front of mkdocs serve . The following skipper inline route will do this for you, assuming that you build skipper with make skipper : ./bin/skipper -inline-routes 'r: * -> modPath(\"/skipper\", \"\") -> \"http://127.0.0.1:8000\"' Now you should be able to see the documentation at http://127.0.0.1:9090 . Filters \u00b6 Filters allow to change arbitrary HTTP data in the Request or Response. If you need to read and write the http.Body, please make sure you discuss the use case before creating a pull request. A filter consists of at least two types a filters.Spec and a filters.Filter . Spec consists of everything that is needed and known before a user will instantiate a filter. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the filters.Spec interface Name() string and CreateFilter([]interface{}) (filters.Filter, error) . The actual filter implementation has to satisfy the filter.Filter interface Request(filters.FilterContext) and Response(filters.FilterContext) . If you need to clean up for example a goroutine you can do it in Close() , which will be called on filter shutdown. The simplest filter possible is, if filters.Spec and filters.Filter are the same type: type myFilter struct {} func NewMyFilter () filters . Spec { return & myFilter {} } func ( spec * myFilter ) Name () string { return \"myFilter\" } func ( spec * myFilter ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { return NewMyFilter (), nil } func ( f * myFilter ) Request ( ctx filters . FilterContext ) { // change data in ctx.Request() for example } func ( f * myFilter ) Response ( ctx filters . FilterContext ) { // change data in ctx.Response() for example } Find a detailed example at how to develop a filter . Predicates \u00b6 Predicates allow to match a condition, that can be based on arbitrary HTTP data in the Request. There are also predicates, that use a chance Traffic() or the current local time, for example After() , to match a request and do not use the HTTP data at all. A predicate consists of at least two types routing.Predicate and routing.PredicateSpec , which are both interfaces. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the routing.PredicateSpec interface Name() string and Create([]interface{}) (routing.Predicate, error) . The actual predicate implementation has to satisfy the routing.Predicate interface Match(*http.Request) bool and returns true if the predicate matches the request. If false is returned, the routing table will be searched for another route that might match the given request. The simplest possible predicate implementation is, if routing.PredicateSpec and routing.Predicate are the same type: type myPredicate struct {} func NewMyPredicate () routing . PredicateSpec { return & myPredicate {} } func ( spec * myPredicate ) Name () string { return \"myPredicate\" } func ( spec * myPredicate ) Create ( config [] interface {}) ( routing . Predicate , error ) { return NewMyPredicate (), nil } func ( f * myPredicate ) Match ( r * http . Request ) bool { // match data in *http.Request for example return true } Predicates are quite similar to implement as Filters, so for a more complete example, find an example how to develop a filter . Dataclients \u00b6 Dataclients are the way how to integrate new route sources. Dataclients pull information from a source and create routes for skipper\u2019s routing table. You have to implement routing.DataClient , which is an interface that defines function signatures LoadAll() ([]*eskip.Route, error) and LoadUpdate() ([]*eskip.Route, []string, error) . The LoadUpdate() method can be implemented either in a way that returns immediately, or blocks until there is a change. The routing package will regularly call the LoadUpdate() method with a small delay between the calls. A complete example is the routestring implementation , which fits in less than 50 lines of code. Opentracing \u00b6 Your custom Opentracing implementations need to satisfy the opentracing.Tracer interface from https://github.com/opentracing/opentracing-go and need to be loaded as a plugin, which might change in the future. Please check the tracing package and ask for further guidance in our community channels . Core \u00b6 Non trivial changes, proposals and enhancements to the core of skipper should be discussed first in a Github issue, such that we can think about how this fits best in the project and how to achieve the most useful result. Feel also free to reach out to our community channels and discuss there your idea. Every change in core has to have tests included and should be a non breaking change. We planned since a longer time a breaking change, but we should coordinate to make it as good as possible for all skipper as library users. Most often a breaking change can be postponed to the future and a feature independently added and the old feature might be deprecated to delete it later. Use of deprecated features should be shown in logs with a log.Warning .","title":"Development"},{"location":"tutorials/development/#docs","text":"We have user documentation and developer documentation separated. In docs/ you find the user documentation in mkdocs format and rendered at https://opensource.zalando.com/skipper . Developer documentation for skipper as library users godoc format is used and rendered at https://godoc.org/github.com/zalando/skipper .","title":"Docs"},{"location":"tutorials/development/#user-documentation","text":"","title":"User documentation"},{"location":"tutorials/development/#local-preview","text":"To see rendered documentation locally you need to replace /skipper path with / to see them correctly. This you can easily do with skipper in front of mkdocs serve . The following skipper inline route will do this for you, assuming that you build skipper with make skipper : ./bin/skipper -inline-routes 'r: * -> modPath(\"/skipper\", \"\") -> \"http://127.0.0.1:8000\"' Now you should be able to see the documentation at http://127.0.0.1:9090 .","title":"local Preview"},{"location":"tutorials/development/#filters","text":"Filters allow to change arbitrary HTTP data in the Request or Response. If you need to read and write the http.Body, please make sure you discuss the use case before creating a pull request. A filter consists of at least two types a filters.Spec and a filters.Filter . Spec consists of everything that is needed and known before a user will instantiate a filter. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the filters.Spec interface Name() string and CreateFilter([]interface{}) (filters.Filter, error) . The actual filter implementation has to satisfy the filter.Filter interface Request(filters.FilterContext) and Response(filters.FilterContext) . If you need to clean up for example a goroutine you can do it in Close() , which will be called on filter shutdown. The simplest filter possible is, if filters.Spec and filters.Filter are the same type: type myFilter struct {} func NewMyFilter () filters . Spec { return & myFilter {} } func ( spec * myFilter ) Name () string { return \"myFilter\" } func ( spec * myFilter ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { return NewMyFilter (), nil } func ( f * myFilter ) Request ( ctx filters . FilterContext ) { // change data in ctx.Request() for example } func ( f * myFilter ) Response ( ctx filters . FilterContext ) { // change data in ctx.Response() for example } Find a detailed example at how to develop a filter .","title":"Filters"},{"location":"tutorials/development/#predicates","text":"Predicates allow to match a condition, that can be based on arbitrary HTTP data in the Request. There are also predicates, that use a chance Traffic() or the current local time, for example After() , to match a request and do not use the HTTP data at all. A predicate consists of at least two types routing.Predicate and routing.PredicateSpec , which are both interfaces. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the routing.PredicateSpec interface Name() string and Create([]interface{}) (routing.Predicate, error) . The actual predicate implementation has to satisfy the routing.Predicate interface Match(*http.Request) bool and returns true if the predicate matches the request. If false is returned, the routing table will be searched for another route that might match the given request. The simplest possible predicate implementation is, if routing.PredicateSpec and routing.Predicate are the same type: type myPredicate struct {} func NewMyPredicate () routing . PredicateSpec { return & myPredicate {} } func ( spec * myPredicate ) Name () string { return \"myPredicate\" } func ( spec * myPredicate ) Create ( config [] interface {}) ( routing . Predicate , error ) { return NewMyPredicate (), nil } func ( f * myPredicate ) Match ( r * http . Request ) bool { // match data in *http.Request for example return true } Predicates are quite similar to implement as Filters, so for a more complete example, find an example how to develop a filter .","title":"Predicates"},{"location":"tutorials/development/#dataclients","text":"Dataclients are the way how to integrate new route sources. Dataclients pull information from a source and create routes for skipper\u2019s routing table. You have to implement routing.DataClient , which is an interface that defines function signatures LoadAll() ([]*eskip.Route, error) and LoadUpdate() ([]*eskip.Route, []string, error) . The LoadUpdate() method can be implemented either in a way that returns immediately, or blocks until there is a change. The routing package will regularly call the LoadUpdate() method with a small delay between the calls. A complete example is the routestring implementation , which fits in less than 50 lines of code.","title":"Dataclients"},{"location":"tutorials/development/#opentracing","text":"Your custom Opentracing implementations need to satisfy the opentracing.Tracer interface from https://github.com/opentracing/opentracing-go and need to be loaded as a plugin, which might change in the future. Please check the tracing package and ask for further guidance in our community channels .","title":"Opentracing"},{"location":"tutorials/development/#core","text":"Non trivial changes, proposals and enhancements to the core of skipper should be discussed first in a Github issue, such that we can think about how this fits best in the project and how to achieve the most useful result. Feel also free to reach out to our community channels and discuss there your idea. Every change in core has to have tests included and should be a non breaking change. We planned since a longer time a breaking change, but we should coordinate to make it as good as possible for all skipper as library users. Most often a breaking change can be postponed to the future and a feature independently added and the old feature might be deprecated to delete it later. Use of deprecated features should be shown in logs with a log.Warning .","title":"Core"},{"location":"tutorials/ratelimit/","text":"Overview \u00b6 Ratelimits are calculated for a number of requests and a time.Duration for a given bucket. To enable rate limits you need to run skipper with -enable-ratelimits . A time.Duration is specified as string and can for example be \u201c10s\u201d for ten seconds, \u201c5m\u201d for five minutes or \u201c2h\u201d for two hours. As bucket skipper can use either the backend or some client information. In case of a backend ratelimit the bucket is only one global for one route. In case of a client ratelimit the buckets are created by the used ratelimit.Lookuper , which defaults to the X-Forwarded-For header, but can be also the Authorization header. So for the client ratelimit with X-Forwarded-For header, the client IP that the first proxy in the list sees will be used to lookup the bucket to count requests. Instance local Ratelimit \u00b6 Filters ratelimit() and clientRatelimit() calculate the ratelimit in a local view having no information about other skipper instances. Backend Ratelimit \u00b6 The backend ratelimit filter is ratelimit() and it is the simplest one. You can define how many requests a route allows for a given time.Duration . For example to limit the route to 10 requests per minute for each skipper instance, you can specify: ratelimit(10, \"1m\") Client Ratelimit \u00b6 The client ratelimit filter is clientRatelimit() and it uses information from the request to find the bucket which will get the increased request count. For example to limit the route to 10 requests per minute for each skipper instance for the same client selected by the X-Forwarded-For header, you can specify: clientRatelimit(10, \"1m\") There is an optional third argument that selects the same client by HTTP header value. As an example for Authorization Header you would use: clientRatelimit(10, \"1m\", \"Authorization\") Internally skipper has a clean interval to clean up old buckets to reduce the memory footprint in the long run. Cluster Ratelimit \u00b6 A cluster ratelimit computes all requests for all skipper peers. This requires, that you run skipper with -enable-swarm and select one of the two implementations: Redis SWIM Make sure all requirements, that are dependent on the implementation and your dataclient in use. Redis based Cluster Ratelimits \u00b6 This solution is independent of the dataclient being used. You have to run N number of Redis instances, where N is > 0. Specify -swarm-redis-urls , multiple instances can be separated by , , for example: -swarm-redis-urls=redis1:6379,redis2:6379 . For running skipper in Kubernetes with this, see also Running with Redis based Cluster Ratelimits The implementation use redis ring to be able to shard via client hashing and spread the load across multiple Redis instances to be able to scale out the shared storage. The ratelimit algorithm is a sliding window and makes use of the following Redis commands: ZREMRANGEBYSCORE , ZCARD , ZADD and ZRANGEBYSCORE SWIM based Cluster Ratelimits \u00b6 SWIM is a \u201cScalable Weakly-consistent Infection-style Process Group Membership Protocol\u201d, which is very interesting to use for cluster ratelimits. The implementation has some weaknesses in the algorithm, that lead sometimes to too much ratelimits or too few and therefore is not considered to be stable. For running skipper in Kubernetes with this, see also Running with SWIM based Cluster Ratelimits In case of Kubernetes you might specify additionally -swarm-label-selector-key , which defaults to \u201capplication\u201d and -swarm-label-selector-value , which defaults to \u201cskipper-ingress\u201d and -swarm-namespace , which defaults to \u201ckube-system\u201d. The following shows the setup of a SWIM based cluster ratelimit: Backend Ratelimit \u00b6 The backend ratelimit filter is clusterRatelimit() . You can define how many requests a route allows for a given time.Duration in total for all skipper instances summed up. The first parameter is the group parameter, which can be used to select the same ratelimit group across one or more routes For example rate limit \u201cgroupA\u201d limits the rate limit group to 10 requests per minute in total for the cluster, you can specify: clusterRatelimit(\"groupA\", 10, \"1m\") Client Ratelimit \u00b6 The client ratelimit filter is clusterClientRatelimit() and it uses information from the request to find the bucket which will get the increased request count. You can define how many requests a client is allowed to hit this route for a given time.Duration in total for all skipper instances summed up. The first parameter is the group parameter, which can be used to select the same ratelimit group across one or more routes For example rate limit \u201cgroupB\u201d limits the rate limit group to 10 requests per minute for the full skipper swarm for the same client selected by the X-Forwarded-For header, you can specify: clusterClientRatelimit(\"groupB\", 10, \"1m\") The same for Authorization Header you would use: clusterClientRatelimit(\"groupC\", 10, \"1m\", \"auth\") Internally skipper has a clean interval to clean up old buckets to reduce the memory footprint in the long run.","title":"Ratelimits"},{"location":"tutorials/ratelimit/#overview","text":"Ratelimits are calculated for a number of requests and a time.Duration for a given bucket. To enable rate limits you need to run skipper with -enable-ratelimits . A time.Duration is specified as string and can for example be \u201c10s\u201d for ten seconds, \u201c5m\u201d for five minutes or \u201c2h\u201d for two hours. As bucket skipper can use either the backend or some client information. In case of a backend ratelimit the bucket is only one global for one route. In case of a client ratelimit the buckets are created by the used ratelimit.Lookuper , which defaults to the X-Forwarded-For header, but can be also the Authorization header. So for the client ratelimit with X-Forwarded-For header, the client IP that the first proxy in the list sees will be used to lookup the bucket to count requests.","title":"Overview"},{"location":"tutorials/ratelimit/#instance-local-ratelimit","text":"Filters ratelimit() and clientRatelimit() calculate the ratelimit in a local view having no information about other skipper instances.","title":"Instance local Ratelimit"},{"location":"tutorials/ratelimit/#backend-ratelimit","text":"The backend ratelimit filter is ratelimit() and it is the simplest one. You can define how many requests a route allows for a given time.Duration . For example to limit the route to 10 requests per minute for each skipper instance, you can specify: ratelimit(10, \"1m\")","title":"Backend Ratelimit"},{"location":"tutorials/ratelimit/#client-ratelimit","text":"The client ratelimit filter is clientRatelimit() and it uses information from the request to find the bucket which will get the increased request count. For example to limit the route to 10 requests per minute for each skipper instance for the same client selected by the X-Forwarded-For header, you can specify: clientRatelimit(10, \"1m\") There is an optional third argument that selects the same client by HTTP header value. As an example for Authorization Header you would use: clientRatelimit(10, \"1m\", \"Authorization\") Internally skipper has a clean interval to clean up old buckets to reduce the memory footprint in the long run.","title":"Client Ratelimit"},{"location":"tutorials/ratelimit/#cluster-ratelimit","text":"A cluster ratelimit computes all requests for all skipper peers. This requires, that you run skipper with -enable-swarm and select one of the two implementations: Redis SWIM Make sure all requirements, that are dependent on the implementation and your dataclient in use.","title":"Cluster Ratelimit"},{"location":"tutorials/ratelimit/#redis-based-cluster-ratelimits","text":"This solution is independent of the dataclient being used. You have to run N number of Redis instances, where N is > 0. Specify -swarm-redis-urls , multiple instances can be separated by , , for example: -swarm-redis-urls=redis1:6379,redis2:6379 . For running skipper in Kubernetes with this, see also Running with Redis based Cluster Ratelimits The implementation use redis ring to be able to shard via client hashing and spread the load across multiple Redis instances to be able to scale out the shared storage. The ratelimit algorithm is a sliding window and makes use of the following Redis commands: ZREMRANGEBYSCORE , ZCARD , ZADD and ZRANGEBYSCORE","title":"Redis based Cluster Ratelimits"},{"location":"tutorials/ratelimit/#swim-based-cluster-ratelimits","text":"SWIM is a \u201cScalable Weakly-consistent Infection-style Process Group Membership Protocol\u201d, which is very interesting to use for cluster ratelimits. The implementation has some weaknesses in the algorithm, that lead sometimes to too much ratelimits or too few and therefore is not considered to be stable. For running skipper in Kubernetes with this, see also Running with SWIM based Cluster Ratelimits In case of Kubernetes you might specify additionally -swarm-label-selector-key , which defaults to \u201capplication\u201d and -swarm-label-selector-value , which defaults to \u201cskipper-ingress\u201d and -swarm-namespace , which defaults to \u201ckube-system\u201d. The following shows the setup of a SWIM based cluster ratelimit:","title":"SWIM based Cluster Ratelimits"},{"location":"tutorials/ratelimit/#backend-ratelimit_1","text":"The backend ratelimit filter is clusterRatelimit() . You can define how many requests a route allows for a given time.Duration in total for all skipper instances summed up. The first parameter is the group parameter, which can be used to select the same ratelimit group across one or more routes For example rate limit \u201cgroupA\u201d limits the rate limit group to 10 requests per minute in total for the cluster, you can specify: clusterRatelimit(\"groupA\", 10, \"1m\")","title":"Backend Ratelimit"},{"location":"tutorials/ratelimit/#client-ratelimit_1","text":"The client ratelimit filter is clusterClientRatelimit() and it uses information from the request to find the bucket which will get the increased request count. You can define how many requests a client is allowed to hit this route for a given time.Duration in total for all skipper instances summed up. The first parameter is the group parameter, which can be used to select the same ratelimit group across one or more routes For example rate limit \u201cgroupB\u201d limits the rate limit group to 10 requests per minute for the full skipper swarm for the same client selected by the X-Forwarded-For header, you can specify: clusterClientRatelimit(\"groupB\", 10, \"1m\") The same for Authorization Header you would use: clusterClientRatelimit(\"groupC\", 10, \"1m\", \"auth\") Internally skipper has a clean interval to clean up old buckets to reduce the memory footprint in the long run.","title":"Client Ratelimit"},{"location":"tutorials/video-howto-build/","text":"How to build Skipper \u00b6 We expect you to have Go and glide installed. How to build Skipper without plugins \u00b6 How to build Skipper with plugins \u00b6 TODO How to run Skipper \u00b6 We expect you to have already built Skipper. TODO","title":"Video - How to build"},{"location":"tutorials/video-howto-build/#how-to-build-skipper","text":"We expect you to have Go and glide installed.","title":"How to build Skipper"},{"location":"tutorials/video-howto-build/#how-to-build-skipper-without-plugins","text":"","title":"How to build Skipper without plugins"},{"location":"tutorials/video-howto-build/#how-to-build-skipper-with-plugins","text":"TODO","title":"How to build Skipper with plugins"},{"location":"tutorials/video-howto-build/#how-to-run-skipper","text":"We expect you to have already built Skipper. TODO","title":"How to run Skipper"}]}